var relearn_search_index = [
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": "This module walks you through the steps to build a Spring Boot microservice from scratch, and to deploy it into the Oracle Backend for SpringBoot and Microservices. In this lab, we will build the “Account” microservice. In the next lab, the remaining Cloud Bank microservices will be provided for you.\nEstimated Time: 20 minutes\nQuick walk through on how to build an account microservice.\nObjectives In this lab, you will:\nCreate a new Spring Boot project in your IDE Prepare objects in the Oracle Database using SQLcl Use Spring Data JPA to allow your microservice to use the data in the Oracle database Create REST services to allow clients to perform create, read, update, and delete operations on accounts Deploy your microservice into the backend (Oracle Backend for Spring Boot and Microservices) Prerequisites (Optional) This module assumes you have:\nAn Oracle Cloud account. All previous labs successfully completed. ",
    "description": "This module walks you through the steps to build a Spring Boot microservice from scratch, and to deploy it into the Oracle Backend for SpringBoot and Microservices. In this lab, we will build the “Account” microservice. In the next lab, the remaining Cloud Bank microservices will be provided for you.\nEstimated Time: 20 minutes\nQuick walk through on how to build an account microservice.\nObjectives In this lab, you will:",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/account/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "This module walks you through various features of Oracle Backend for Spring Boot and Microservices, and shows you how to use them.\nEstimated Time: 20 minutes\nQuick walk through on how to explore backend platform.\nObjectives In this module, you will:\nReview the components of the Oracle Backend for Spring Boot and Microservices Explore how microservice data is stored in the Oracle Autonomous Database Learn about the Spring Admin user interface Learn about Spring Eureka Service Registry Learn about APISIX API Gateway Learn about Spring Config Server Learn about the observability tools included in Oracle Backend for Spring Boot and Microservices Learn about the tracing tools included in Oracle Backend for Spring Boot and Microservices Prerequisites This module assumes you have:\nAn Oracle Cloud account All previous modules successfully completed Deployed the full CloudBank Application ",
    "description": "This module walks you through various features of Oracle Backend for Spring Boot and Microservices, and shows you how to use them.\nEstimated Time: 20 minutes\nQuick walk through on how to explore backend platform.\nObjectives In this module, you will:\nReview the components of the Oracle Backend for Spring Boot and Microservices Explore how microservice data is stored in the Oracle Autonomous Database Learn about the Spring Admin user interface Learn about Spring Eureka Service Registry Learn about APISIX API Gateway Learn about Spring Config Server Learn about the observability tools included in Oracle Backend for Spring Boot and Microservices Learn about the tracing tools included in Oracle Backend for Spring Boot and Microservices Prerequisites This module assumes you have:",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/backend/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "This module walks you through the steps to build Spring Boot microservices that use Java Message Service (JMS) to send and receive asynchronous messages using Transactional Event Queues in the Oracle Database. This service will also use service discovery (OpenFeign) to look up and use the previously built Account service. In this lab, we will extend the Account microservice built in the previous lab, build a new “Check Processing” microservice and another “Test Runner” microservice to help with testing.\nEstimated Time: 20 minutes\nObjectives In this lab, you will:\nCreate new Spring Boot projects in your IDE Plan your queues and message formats Use Spring JMS to allow your microservice to use JMS Transactional Event Queues in the Oracle database Use OpenFeign to allow the Check Processing service to discover and use the Account service Create a “Test Runner” service to simulate the sending of messages Deploy your microservices into the backend Prerequisites (Optional) This module assumes you have:\nAn Oracle Cloud account All previous labs successfully completed ",
    "description": "This module walks you through the steps to build Spring Boot microservices that use Java Message Service (JMS) to send and receive asynchronous messages using Transactional Event Queues in the Oracle Database. This service will also use service discovery (OpenFeign) to look up and use the previously built Account service. In this lab, we will extend the Account microservice built in the previous lab, build a new “Check Processing” microservice and another “Test Runner” microservice to help with testing.",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/check/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Cleanup",
    "content": "When you have finished this Live module you may wish to clean up the resources you created. If so, you may complete the steps in this optional module.\nEstimated module Time: 20 minutes\nQuick walk through on how to clean up the module environment.\nObjectives In this workshop, you will learn how to:\nClean up your instance of the Oracle Backend for Spring Boot and Microservices and other resources you created during this Live module Prerequisites This module assumes you have:\nAn Oracle account Have successfully or partially completed module 1 (Provision an instance of Oracle Backend for Spring Boot and Microservices) ",
    "description": "When you have finished this Live module you may wish to clean up the resources you created. If so, you may complete the steps in this optional module.\nEstimated module Time: 20 minutes\nQuick walk through on how to clean up the module environment.\nObjectives In this workshop, you will learn how to:\nClean up your instance of the Oracle Backend for Spring Boot and Microservices and other resources you created during this Live module Prerequisites This module assumes you have:",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/cleanup/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": "Now that you know how to build a Spring Boot microservice and deploy it to the Oracle Backend for Spring Boot and Microservices, this module will guide you through deploying all the CloudBank services and exploring the runtime and management capabilities of the platform. NOTE: The full CloudBank leverages more features than you have built so far such as monitoring, tracing etc. You will see those features in the module “Explore The Backend Platform”.\nEstimated module Time: 30 minutes\nQuick walk through on how to deploy full CloudBank application.\nObjectives In this module, you will:\nDeploy the full CloudBank sample application into your Oracle Backend for Spring Boot and Microservices instance Prerequisites This module assumes you have:\nAn Oracle Cloud account Have all the necessary tools installed (kubectl, git, maven, oractl, sqlcl, curl, jq). All of them should be installed during module two (Setup your Development Environment) Git version control tool installed on your computer (optional) ",
    "description": "Now that you know how to build a Spring Boot microservice and deploy it to the Oracle Backend for Spring Boot and Microservices, this module will guide you through deploying all the CloudBank services and exploring the runtime and management capabilities of the platform. NOTE: The full CloudBank leverages more features than you have built so far such as monitoring, tracing etc. You will see those features in the module “Explore The Backend Platform”.",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with an IDE",
    "content": "Deploy the full CloudBank Application using the VS Code Extension Introduction Now that you know how to build a Spring Boot microservice and deploy it to the Oracle Backend for Spring Boot and Microservices, this module will guide you through deploying the rest of the Cloud Bank services that we have already built for you and exploring the runtime and management capabilities of the platform.\nIf you already have completed the module Deploy the full CloudBank Application using the CLI You can skip Task 1 and Task 2.\nEstimated module Time: 30 minutes\nObjectives In this module, you will:\nDeploy the full CloudBank sample application into your Oracle Backend for Spring Boot for Microservices instance using the VSCode Extension. Prerequisites This module assumes you have:\nAn Oracle Cloud account Have all the necessary tools installed (kubectl, git, maven, oractl, sqlcl, curl, jq). All of them should be installed during module two (Setup your Development Environment) Installed the VS Code Extension Git version control tool installed on your computer (optional) ",
    "description": "Deploy the full CloudBank Application using the VS Code Extension Introduction Now that you know how to build a Spring Boot microservice and deploy it to the Oracle Backend for Spring Boot and Microservices, this module will guide you through deploying the rest of the Cloud Bank services that we have already built for you and exploring the runtime and management capabilities of the platform.\nIf you already have completed the module Deploy the full CloudBank Application using the CLI You can skip Task 1 and Task 2.",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/deploy-ide/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "This module walks you through setting up your development environment to work with Oracle Backend for Spring Boot and Microservices.\nEstimated time: 20 minutes\nRecommended Development Environment platforms and tools The following platforms are recommended for a development environment:\nWindows 10 or 11, preferably with Windows Subsystem for Linux 2 macOS (11 or later recommended) on Intel or Apple silicon Linux, e.g., Oracle Linux, Ubuntu, etc. The following tools are recommended for a development environment:\nIntegrated Development Environment, e.g., Visual Studio Code Java Development Kit, e.g., Oracle, OpenJDK, or GraalVM Maven or Gradle for build and testing automation If you wish to test locally or offline, the following additional tools are recommended:\nA container platform, e.g., Rancher Desktop An Oracle Database (in a container). Objectives In this module, you will:\nInstall the tools needed to develop and deploy applications using Oracle Backend for Spring Boot and Microservices Prerequisites This module assumes you have:\nOne of the recommended platforms, as listed above ",
    "description": "This module walks you through setting up your development environment to work with Oracle Backend for Spring Boot and Microservices.\nEstimated time: 20 minutes\nRecommended Development Environment platforms and tools The following platforms are recommended for a development environment:\nWindows 10 or 11, preferably with Windows Subsystem for Linux 2 macOS (11 or later recommended) on Intel or Apple silicon Linux, e.g., Oracle Linux, Ubuntu, etc. The following tools are recommended for a development environment:",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/devenv/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Provision an Instance",
    "content": "This module walks you through the steps to provision an instance of the Oracle Backend for Spring Boot and Microservices.\nEstimated Time: 30 minutes\nAbout Oracle Backend for Spring Boot and Microservices Oracle Backend for Spring Boot and Microservices allows developers to build microservices in Spring Boot and provision a backend as a service with the Oracle Database and other infrastructure components that operate on multiple clouds. This service vastly simplifies the task of building, testing, and operating microservices platforms for reliable, secure, and scalable enterprise applications.\nThis module provides three options for running the environment:\nLocally in a container - you will need a container platform like Docker Desktop, Rancher Desktop, Podman Desktop or similar. This option is recommended only if you have at least 64GB of RAM. With less memory this option will probably be too slow. In a single compute instance in either an Oracle Cloud Free Tier account or any commercial OCI Cloud tenancy. You can sign up for an Oracle Cloud Free Tier account here. This account will include enough free credits to run CloudBank. You can also use this option to run a lightweight, single compute instance environment in any Oracle Cloud tenancy. The full production-sized installation from OCI Marketplace in a commercial Oracle Cloud tenancy. If you have a commercial tenancy with sufficient capacity and privileges, you can run the full production-sized installation. This can be installed from the OCI Marketplace using the instructions in Module 1. Check the instructions for a more detailed list of requirements. Regardless of which option you choose, the remainder of the modules will be virtually identical.\nObjectives In this lab, you will:\nProvision an instance of Oracle Backend for Spring Boot and Microservices, either locally or in the cloud. Prerequisites This module assumes you have either:\nAn Oracle Cloud account in a tenancy with sufficient quota and privileges to create: An OCI Container Engine for Kubernetes cluster, plus a node pool with three worker nodes A VCN with at least two public IP’s available A public load balancer An Oracle Autonomous Database - Shared instance At least one free OCI Auth Token (note that the maximum is two per user), or An Oracle Cloud Free Tier account, or A local machine with enough memory (64GB recommended) to run the environment locally. ",
    "description": "This module walks you through the steps to provision an instance of the Oracle Backend for Spring Boot and Microservices.\nEstimated Time: 30 minutes\nAbout Oracle Backend for Spring Boot and Microservices Oracle Backend for Spring Boot and Microservices allows developers to build microservices in Spring Boot and provision a backend as a service with the Oracle Database and other infrastructure components that operate on multiple clouds. This service vastly simplifies the task of building, testing, and operating microservices platforms for reliable, secure, and scalable enterprise applications.",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/provision/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "This module walks you through implementing the Saga pattern using a Long Running Action to manage transactions across microservices.\nWatch this short introduction video to get an idea of what you will be building: Estimated Time: 30 minutes\nQuick walk through on how to manage saga transactions across microservices.\nObjectives In this module, you will:\nLearn about the Saga pattern Learn about the Long Running Action specification Add new endpoints to the Account service for deposits and withdrawals that act as LRA participants Create a Transfer service that will initiate the LRA Prerequisites This module assumes you have:\nAn Oracle Cloud account All previous modules successfully completed ",
    "description": "This module walks you through implementing the Saga pattern using a Long Running Action to manage transactions across microservices.\nWatch this short introduction video to get an idea of what you will be building: Estimated Time: 30 minutes\nQuick walk through on how to manage saga transactions across microservices.\nObjectives In this module, you will:\nLearn about the Saga pattern Learn about the Long Running Action specification Add new endpoints to the Account service for deposits and withdrawals that act as LRA participants Create a Transfer service that will initiate the LRA Prerequisites This module assumes you have:",
    "tags": [],
    "title": "Introduction",
    "uri": "/microservices-datadriven/cloudbank/saga/intro/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module guides you through provisioning an Oracle Backend for Spring Boot environment either on your local machine, in the Oracle Cloud Free Tier, or in a commercial Oracle Cloud Tenancy.",
    "description": "This module guides you through provisioning an Oracle Backend for Spring Boot environment either on your local machine, in the Oracle Cloud Free Tier, or in a commercial Oracle Cloud Tenancy.",
    "tags": [],
    "title": "Provision an Instance",
    "uri": "/microservices-datadriven/cloudbank/provision/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": "Create a project to hold your Account service. In this lab, you will use the Spring Initialzr directly from Visual Studio Code, however it is also possible to use Spring Initialzr online and download a zip file with the generated project.\nCreate the project\nIn Visual Studio Code, press Ctrl+Shift+P (Cmd+Shift+P on a Mac) to access the command window. Start typing “Spring Init” and you will see a number of options to create a Spring project, as shown in the image below. Select the option to Create a Maven Project.\nSelect the Spring Boot Version\nYou will be presented with a list of available Spring Boot versions. Choose 3.2.2 (or the latest 3.2.x version available).\nChoose Group ID.\nYou will be asked for the Maven Group ID for this new project, you can use com.example (the default value).\nChoose Artifact ID.\nYou will be asked for the Maven Artifact ID for this new project, enter account.\nSelect Packaging Type\nYou will be asked what type of packaging you want for this new project, select JAR from the list of options.\nChoose Java Version\nNext, you will be asked what version of Java to use. Select 21 from the list of options.\nAdd Spring Boot dependencies\nNow you will have the opportunity to add the Spring Boot dependencies your project needs. For now just add Spring Web, which will let us write some REST services. We will add more later as we need them. After you add Spring Web, click on the option to continue with the selected dependencies.\nContinue with the selected dependencies After you add Spring Web, click on the option to continue with the selected dependencies.\nSelect where to save the project\nYou will be asked where to save the project. Note that this needs to be an existing location. You may wish to create a directory in another terminal if you do not have a suitable location. Enter the directory to save the project in and press Enter.\nOpen the generated project\nNow the Spring Initializr will create a new project based on your selections and place it in the directory you specified. This will only take a few moments to complete. You will a message in the bottom right corner of Visual Studio Code telling you it is complete. Click on the Open button in that message to open your new project in Visual Studio Code.\nWhen asked if you want to Enable null Analysis for this project press Enable. Explore the project\nExplore the new project. You should find the main Spring Boot application class and your Spring Boot application.properties file as shown in the image below.\nRemove some files (Optional)\nIf desired, you can delete some of the generated files that you will not need. You can remove .mvn, mvnw, mvnw.cmd and HELP.md if you wish. Leaving them there will not cause any issues.\nBuild and run the service\nOpen a terminal in Visual Studio Code by selecting New Terminal from the Terminal menu (or if you prefer, just use a separate terminal application). Build and run the newly created service with this command:\n$ mvn spring-boot:runThe service will take a few seconds to start, and then you will see some messages similar to these:\n2024-02-14T14:39:52.501-06:00 INFO 83614 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port 8080 (http) with context path '' 2024-02-14T14:39:52.506-06:00 INFO 83614 --- [ main] com.example.account.AccountApplication : Started AccountApplication in 0.696 seconds (process running for 0.833)Of course, the service does not do anything yet, but you can still make a request and confirm you get a response from it. Open a new terminal and execute the following command:\n$ curl http://localhost:8080 {\"timestamp\":\"2023-02-25T17:28:23.264+00:00\",\"status\":404,\"error\":\"Not Found\",\"path\":\"/\"} ",
    "description": "Create a project to hold your Account service. In this lab, you will use the Spring Initialzr directly from Visual Studio Code, however it is also possible to use Spring Initialzr online and download a zip file with the generated project.\nCreate the project\nIn Visual Studio Code, press Ctrl+Shift+P (Cmd+Shift+P on a Mac) to access the command window. Start typing “Spring Init” and you will see a number of options to create a Spring project, as shown in the image below.",
    "tags": [],
    "title": "Create Project",
    "uri": "/microservices-datadriven/cloudbank/account/create-project/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module guides you through setting up the tools required for a Spring Boot developer.",
    "description": "This module guides you through setting up the tools required for a Spring Boot developer.",
    "tags": [],
    "title": "Developer Environment",
    "uri": "/microservices-datadriven/cloudbank/devenv/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Oracle Backend for Spring Boot and Microservices includes a number of platform services which are deployed into the Oracle Container Engine for Kubernetes cluster. You configured kubectl to access your cluster in an earlier module. In this task, you will explore the services deployed in the Kubernetes cluster. A detailed explanation of Kubernetes concepts is beyond the scope of this course.\nExplore namespaces\nKubernetes resources are grouped into namespaces. To see a list of the namespaces in your cluster, use this command, your output will be slightly different:\n$ kubectl get ns NAME STATUS AGE admin-server Active 4h56m apisix Active 4h56m application Active 4h57m azn-server Active 4h56m cert-manager Active 4h59m coherence Active 4h56m conductor-server Active 4h56m config-server Active 4h55m default Active 5h8m eureka Active 4h57m grafana Active 4h55m ingress-nginx Active 4h57m kafka Active 4h56m kaniko Active 5h1m kube-node-lease Active 5h8m kube-public Active 5h8m kube-state-metrics Active 4h57m kube-system Active 5h8m metrics-server Active 4h57m obaas-admin Active 4h55m observability Active 4h55m open-telemetry Active 4h55m oracle-database-exporter Active 4h55m oracle-database-operator-system Active 4h59m otmm Active 4h55m prometheus Active 4h57m vault Active 4h54mHere is a summary of what is in each of these namespaces:\nadmin-server contains Spring Admin which can be used to monitor and manage your services apisix contains the APISIX API Gateway and Dashboard which can be used to expose services outside the cluster application is a pre-created namespace with the Oracle Database wallet and secrets pre-configured to allow services deployed there to access the Oracle Autonomous Database instance cert-manager contains Cert Manager which is used to manage X.509 certificates for services cloudbank is the namespace where you deployed the CloudBank sample application conductor-server contains Netflix Conductor OSS which can be used to manage workflows config-server contains the Spring CLoud Config Server eureka contains the Spring Eureka Service Registry which is used for service discovery grafana contains Grafana which can be used to monitor and manage your environment ingress-nginx contains the NGINX ingress controller which is used to manage external access to the cluster kafka contains a three-node Kafka cluster that can be used by your application obaas-admin contains the Oracle Backend for Spring Boot and Microservices administration server that manages deployment of your services observability contains Jaeger tracing which is used for viewing distributed traces open-telemetry contains the Open Telemetry Collector which is used to collect distributed tracing information for your services oracle-database-operator-system contains the Oracle Database Operator for Kubernetes which can be used to manage Oracle Databases in Kubernetes environments otmm contains Oracle Transaction Manager for Microservices which is used to manage transactions across services prometheus contains Prometheus which collects metrics about your services and makes the available to Grafana for alerting and dashboards vault contains HashiCorp Vault which can be used to store secret or sensitive information for services, like credentials for example Kubernetes namespaces contain other resources like pods, services, secrets and config maps. You will explore some of these now.\nExplore pods\nKubernetes runs workloads in “pods.” Each pod can container one or more containers. There are different kinds of groupings of pods that handle scaling in different ways. Use this command to review the pods in the apisix namespace:\n$ kubectl -n apisix get pods NAME READY STATUS RESTARTS AGE apisix-558f6f64c6-ff6xf 1/1 Running 0 4h57m apisix-dashboard-6f865fcb7b-n76c7 1/1 Running 4 (4h56m ago) 4h57m apisix-etcd-0 1/1 Running 0 4h57m apisix-etcd-1 1/1 Running 0 4h57m apisix-etcd-2 1/1 Running 0 4h57mThe first pod listed is the APISIX API Gateway itself. It is part of a Kubernetes “deployment”. The next pod is running the APISIX Dashboard user interface - there is only one instance of that pod running. And the last three pods are running the etcd cluster that APISIX is using to store its state. These three pods are part of a “stateful set”.\nTo see details of the deployments and stateful set in this namespace use this command:\n$ kubectl -n apisix get deploy,statefulset NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/apisix 3/3 3 3 6d18h deployment.apps/apisix-dashboard 1/1 1 1 6d18h NAME READY AGE statefulset.apps/apisix-etcd 3/3 6d18hIf you want to view extended information about any object you can specify its name and the output format, as in this example:\n$ kubectl -n apisix get pod apisix-etcd-0 -o yaml Explore services\nKubernetes services are essentially small load balancers that sit in front of groups of pods and provide a stable network address as well as load balancing. To see the services in the apisix namespace use this command:\n$ kubectl -n apisix get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE apisix-admin ClusterIP 10.96.26.213 \u003cnone\u003e 9180/TCP 4h59m apisix-dashboard ClusterIP 10.96.123.62 \u003cnone\u003e 80/TCP 4h59m apisix-etcd ClusterIP 10.96.54.248 \u003cnone\u003e 2379/TCP,2380/TCP 4h59m apisix-etcd-headless ClusterIP None \u003cnone\u003e 2379/TCP,2380/TCP 4h59m apisix-gateway NodePort 10.96.134.86 \u003cnone\u003e 80:32130/TCP 4h59m apisix-prometheus-metrics ClusterIP 10.96.31.169 \u003cnone\u003e 9091/TCP 4h59mNotice that the services give information about the ports. You can get detailed information about a service by specifying its name and output format as you did earlier for a pod.\nExplore secrets\nSensitive information in Kubernetes is often kept in secrets that are mounted into the pods at runtime. This means that the container images do not need to have the sensitive information stored in them. It also helps with deploying to different environments where sensitive information like URLs and credentials for databases changes based on the environment.\nOracle Backend for Spring Boot and Microservices creates a number of secrets for you so that your applications can securely access the Oracle Autonomous Database instance. Review the secrets in the pre-created application namespace using this command. Note, the name of the secrets will be different in your environment depending on the application name you gave when deploying the application.\n$ kubectl -n application get secret NAME TYPE DATA AGE account-db-secrets Opaque 4 57m admin-liquibasedb-secrets Opaque 5 56m checks-db-secrets Opaque 4 57m customer-db-secrets Opaque 4 56m encryption-secret-key Opaque 1 5h1m public-key Opaque 1 5h1m registry-auth kubernetes.io/dockerconfigjson 1 5h registry-login Opaque 5 5h registry-pull-auth kubernetes.io/dockerconfigjson 1 5h registry-push-auth kubernetes.io/dockerconfigjson 1 5h testrunner-db-secrets Opaque 4 56m tls-certificate kubernetes.io/tls 5 5h zimbadb-db-secrets Opaque 5 5h zimbadb-tns-admin Opaque 9 5hWhenever you create a new application namespace with the CLI and bind it to the database, these secrets will be automatically created for you in that namespace. There will two secrets created for the database, one contains the credentials to access the Oracle Autonomous Database. The other one contains the database client configuration files (tnsadmin.ora, sqlnet.ora, the keystores, and so on). The name of the secret depends on the application name you gave (or got autogenerated) during install, in the example above the application name is zimba.\nYou can view detailed information about a secret with a command like this, you will need to provide the name of your secret which will be based on the name you chose during installation (your output will be different). Note that the values are uuencoded in this output:\n$ kubectl -n application get secret zimbadb-db-secrets -o yaml apiVersion: v1 data: db.name: xxxxxxxxxx db.password: xxxxxxxxxx db.service: xxxxxxxxxx db.username: xxxxxxxxxx secret: xxxxxxxxxx kind: Secret metadata: creationTimestamp: \"2024-05-08T16:38:06Z\" moduleels: app.kubernetes.io/version: 1.2.0 name: zimbadb-db-secrets namespace: application resourceVersion: \"3486\" uid: 66855e8d-22a5-4e24-b3df-379dd033ed1f type: OpaqueWhen you deploy a Spring Boot microservice application into Oracle Backend for Spring Boot and Microservices, the pods that are created will have the values from this secret injected as environment variables that are referenced from the application.yaml to connect to the database. The xxxxxx-tns-admin secret will be mounted in the pod to provide access to the configuration and keystores to allow your application to authenticate to the database.",
    "description": "Oracle Backend for Spring Boot and Microservices includes a number of platform services which are deployed into the Oracle Container Engine for Kubernetes cluster. You configured kubectl to access your cluster in an earlier module. In this task, you will explore the services deployed in the Kubernetes cluster. A detailed explanation of Kubernetes concepts is beyond the scope of this course.\nExplore namespaces\nKubernetes resources are grouped into namespaces. To see a list of the namespaces in your cluster, use this command, your output will be slightly different:",
    "tags": [],
    "title": "Explore Kubernetes",
    "uri": "/microservices-datadriven/cloudbank/backend/k8s/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": "Download a copy of the CloudBank sample application.\nClone the source repository\nCreate a local clone of the CloudBank source repository using this command.\ngit clone -b OBAAS-1.2.0 https://github.com/oracle/microservices-datadriven.git Note: If you do not have git installed on your machine, you can download a zip file of the source code from GitHub and unzip it on your machine instead.\nThe source code for the CloudBank application will be in the microservices-datadriven directory you just created, in the cloudbank-v32 subdirectory.\ncd microservices-datadriven/cloudbank-v32This directory will be referred to as the root directory for CloudBank in this module.",
    "description": "Download a copy of the CloudBank sample application.\nClone the source repository\nCreate a local clone of the CloudBank source repository using this command.\ngit clone -b OBAAS-1.2.0 https://github.com/oracle/microservices-datadriven.git Note: If you do not have git installed on your machine, you can download a zip file of the source code from GitHub and unzip it on your machine instead.\nThe source code for the CloudBank application will be in the microservices-datadriven directory you just created, in the cloudbank-v32 subdirectory.",
    "tags": [],
    "title": "Get the sample code",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/get-code/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with an IDE",
    "content": "Download a copy of the CloudBank sample application.\nClone the source repository\nCreate a local clone of the CloudBank source repository using this command.\n\u003ccopy\u003egit clone -b OBAAS-1.2.0 https://github.com/oracle/microservices-datadriven.git\u003c/copy\u003e Note: If you do not have git installed on your machine, you can download a zip file of the source code from GitHub and unzip it on your machine instead.\nThe source code for the CloudBank application will be in the microservices-datadriven directory you just created, in the cloudbank-v32 subdirectory.\n\u003ccopy\u003ecd microservices-datadriven/cloudbank-v32\u003c/copy\u003e ",
    "description": "Download a copy of the CloudBank sample application.\nClone the source repository\nCreate a local clone of the CloudBank source repository using this command.\n\u003ccopy\u003egit clone -b OBAAS-1.2.0 https://github.com/oracle/microservices-datadriven.git\u003c/copy\u003e Note: If you do not have git installed on your machine, you can download a zip file of the source code from GitHub and unzip it on your machine instead.\nThe source code for the CloudBank application will be in the microservices-datadriven directory you just created, in the cloudbank-v32 subdirectory.",
    "tags": [],
    "title": "Get the sample code",
    "uri": "/microservices-datadriven/cloudbank/deploy-ide/get-code/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "Oracle recommends Visual Studio Code, which you can download here, and the following extensions to make it easier to write and build your code:\nSpring Boot Extension Pack Extension Pack for Java Oracle Developer Tools Note: It is possible to use other Integrated Development Environments however all the instructions in this Livemoduleare written for and tested with Visual Studio Code, so we recommend that you use it for this Live Lab.\nDownload and install Visual Studio Code\nDownload Visual Studio Code from this website and run the installer for your operating system to install it on your machine.\nInstall the recommended extensions\nStart Visual Studio Code, and then open the extensions tab (Ctrl-Shift-X or equivalent) and use the search bar at the top to find and install each of the extensions listed above.",
    "description": "Oracle recommends Visual Studio Code, which you can download here, and the following extensions to make it easier to write and build your code:\nSpring Boot Extension Pack Extension Pack for Java Oracle Developer Tools Note: It is possible to use other Integrated Development Environments however all the instructions in this Livemoduleare written for and tested with Visual Studio Code, so we recommend that you use it for this Live Lab.",
    "tags": [],
    "title": "Install IDE",
    "uri": "/microservices-datadriven/cloudbank/devenv/ide/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Provision an Instance",
    "content": "This option allows you to run Oracle Backend for Spring Boot and Microservices in a containerized environment on your local machine. This option is recommended if you do have enough free capacity on your local machine to run the environment, a minimum of 64GB RAM and 80GB free disk are recommended. This option provides an environment with adequate resources for development and testing, but is not suitable for a production-sized deployment or performance testing.\nNote: You only need to choose one of the three deployment options - local, OCI Free Tier or OCI Marketplace.\nPrerequisites\nThe following prerequisites are required to run the local environment:\nA container runtime environment such as Docker Desktop, Rancher Desktop or Podman Desktop. The ability to run a BASH script, or to read one and run equivalent commands in your environment. 64GB RAM and 80GB free disk space. Download the required files\nIf you have not already done so, clone the Microservices Data-Driven GitHub repository:\ngit clone https://github.com/oracle/microservices-datadriven Change into the directory with the local environment files:\ncd microservices-datadriven/cloudbank-v4/local-environment Start the environment\nRun the provided script to start the environment, including a Kubernetes cluster in a container (using k3s), Oracle Backend for Spring Boot and Microservices and an Oracle Database instance inside that cluster.\n./obaas.sh It will take approximately six to ten minutes (depending on the size of your machine) for all of the containers to reach ready/running state. You can watch the progress using this command:\nwatch KUBECONFIG=$(pwd)/k3s_data/kubeconfig/kubeconfig.yaml kubectl get pod -A Note: You will need to provide the KUBECONFIG variable as shown, or export it in your shell, each time you wish to run a kubectl command to access the cluster.\nWhen the environment is fully started, the output will appear similar to this:\nVerify access to web user interfaces\nOn your local machine, open a browser and navigate to the Spring Operations Center.\nLog in using the pre-defined user obaas-admin and password Welcome-12345.\nNote: Since this is a development environment with no DNS name, it is configured with self-signed certificates. Your browser will warn you about the connection security.\nIf you are using Chrome, click on the Advanced link and then the Proceed to localhost (unsafe) link. If you are using a different browser, perform the equivalent actions.\nThe Spring Operations Center main dashboard will appear similar to this:",
    "description": "This option allows you to run Oracle Backend for Spring Boot and Microservices in a containerized environment on your local machine. This option is recommended if you do have enough free capacity on your local machine to run the environment, a minimum of 64GB RAM and 80GB free disk are recommended. This option provides an environment with adequate resources for development and testing, but is not suitable for a production-sized deployment or performance testing.",
    "tags": [],
    "title": "Install locally",
    "uri": "/microservices-datadriven/cloudbank/provision/install-local/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "When you adopt microservices architecture and start to apply the patterns, you rapidly run into a situation where you have a business transaction that spans across multiple services.\nDatabase per service The Database per service pattern is a generally accepted best practice which dictates that each service must have its own “database” and that the only way other services can access its data is through its public API. This helps to create loose coupling between services, which in turn makes it easier to evolve them independently and prevents the creation of a web of dependencies that make application changes increasingly difficult over time. In reality, this pattern may be implemented with database containers, or even schema within one database with strong security isolation, to prevent the proliferation of database instances and the associated management and maintenance cost explosion.\nTransactions that span services The obvious challenge with the Database per service pattern is that a database transaction cannot span databases, or services. So if you have a scenario where you need to perform operations in more than one service’s database, you need a solution for this challenge.\nA saga is a sequence of local transactions. Each service performs local transactions and then triggers the next step in the saga. If there is a failure due to violating a business rule (e.g. trying to withdraw more money than is in an account) then the saga executes a series of compensating transactions to undo the changes that were already made.\nSaga coordination There are two ways to coordinate sagas:\nChoreography - each local transaction publishes domain events that trigger local transactions in other services Orchestration - an orchestrator (object) tells the participants what local transactions to execute You will use the orchestration approach in this module.\nNote: You can learn more about the saga pattern at microservices.io.\nThe Cloud Cash Transfer Saga In this module you will implement a saga that will manage transferring funds from one user to another.\nWhen the user submits their request, a microservice will pick up the request and invoke the Transfer service (which you will write in this module) to process the transfer.",
    "description": "When you adopt microservices architecture and start to apply the patterns, you rapidly run into a situation where you have a business transaction that spans across multiple services.\nDatabase per service The Database per service pattern is a generally accepted best practice which dictates that each service must have its own “database” and that the only way other services can access its data is through its public API. This helps to create loose coupling between services, which in turn makes it easier to evolve them independently and prevents the creation of a web of dependencies that make application changes increasingly difficult over time.",
    "tags": [],
    "title": "Learn about the Saga pattern",
    "uri": "/microservices-datadriven/cloudbank/saga/learn/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "In the previous lab, you created an Account service that includes endpoints to create and query accounts, lookup accounts for a given customer, and so on. In this module you will extend that service to add some new endpoints to allow recording bank transactions, in this case check deposits, in the account journal.\nIn this lab, we will assume that customers can deposit a check at an Automated Teller Machine (ATM) by typing in the check amount, placing the check into a deposit envelope and then inserting that envelope into the ATM. When this occurs, the ATM will send a “deposit” message with details of the check deposit. You will record this as a “pending” deposit in the account journal.\nLater, imagine that the deposit envelop arrives at a back office check processing facility where a person checks the details are correct, and then “clears” the check. When this occurs, a “clearance” message will be sent. Upon receiving this message, you will change the “pending” transaction to a finalized “deposit” in the account journal.\nYou will implement this using three microservices:\nThe Account service you created in the previous module will have the endpoints to manipulate journal entries A new “Check Processing” service will listen for messages and process them by calling the appropriate endpoints on the Account service A “Test Runner” service will simulate the ATM and the back office and allow you to send the “deposit” and “clearance” messages to test your other services ",
    "description": "In the previous lab, you created an Account service that includes endpoints to create and query accounts, lookup accounts for a given customer, and so on. In this module you will extend that service to add some new endpoints to allow recording bank transactions, in this case check deposits, in the account journal.\nIn this lab, we will assume that customers can deposit a check at an Automated Teller Machine (ATM) by typing in the check amount, placing the check into a deposit envelope and then inserting that envelope into the ATM.",
    "tags": [],
    "title": "Learn about the scenario",
    "uri": "/microservices-datadriven/cloudbank/check/learn/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Cleanup",
    "content": " Note: These steps apply only if you chose the option to install in a local container.\nStop the local container using this command:\ndocker stop obaas Note: If you want to use the environment again later, stop at this step. You can restart it later with the command docker start obaas.\nRemove the local container using this command:\ndocker rm obaas ",
    "description": " Note: These steps apply only if you chose the option to install in a local container.\nStop the local container using this command:\ndocker stop obaas Note: If you want to use the environment again later, stop at this step. You can restart it later with the command docker start obaas.\nRemove the local container using this command:\ndocker rm obaas ",
    "tags": [],
    "title": "Local cleanup",
    "uri": "/microservices-datadriven/cloudbank/cleanup/uninstall-local/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module walks you through building your very first microservice using Spring Boot. It assumes no prior knowledge of Spring Boot, so its a great place to start if you have not used Spring Boot before. This module demonstrates how to build a service with a synchronous API implemented as REST endpoints using Spring Web MVC, and how to store data in Oracle Database using Spring Data JPA.",
    "description": "This module walks you through building your very first microservice using Spring Boot. It assumes no prior knowledge of Spring Boot, so its a great place to start if you have not used Spring Boot before. This module demonstrates how to build a service with a synchronous API implemented as REST endpoints using Spring Web MVC, and how to store data in Oracle Database using Spring Data JPA.",
    "tags": [],
    "title": "Account Microservice",
    "uri": "/microservices-datadriven/cloudbank/account/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "Starting with the account service that you built in the previous lab, you will the JPA model and repository for the journal and some new endpoints.\nCreate the Journal model Create a new Java file in src/main/java/com/example/accounts/model called Journal.java. In this class you can define the fields that make up the journal. Note that you created the Journal table in the previous lab. You will not use the lraId and lraState fields until a later lab. To simplify this lab, create an additional constructor that defaults those fields to suitable values. Your new class should look like this:\n```java package com.example.account.model; import jakarta.persistence.Column; import jakarta.persistence.Entity; import jakarta.persistence.GeneratedValue; import jakarta.persistence.GenerationType; import jakarta.persistence.Id; import jakarta.persistence.Table; import lombok.Data; import lombok.NoArgsConstructor; @Entity @Table(name = \"JOURNAL\") @Data @NoArgsConstructor public class Journal { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"JOURNAL_ID\") private long journalId; // type is withdraw or deposit @Column(name = \"JOURNAL_TYPE\") private String journalType; @Column(name = \"ACCOUNT_ID\") private long accountId; @Column(name = \"LRA_ID\") private String lraId; @Column(name = \"LRA_STATE\") private String lraState; @Column(name = \"JOURNAL_AMOUNT\") private long journalAmount; public Journal(String journalType, long accountId, long journalAmount) { this.journalType = journalType; this.accountId = accountId; this.journalAmount = journalAmount; } public Journal(String journalType, long accountId, long journalAmount, String lraId, String lraState) { this.journalType = journalType; this.accountId = accountId; this.lraId = lraId; this.lraState = lraState; this.journalAmount = journalAmount; } } ``` Create the Journal repository Create a new Java file in src/main/java/com/example/account/repository called JournalRepository.java. This should be an interface that extends JpaRepository and you will need to define a method to find journal entries by accountId. Your interface should look like this:\n```java package com.example.account.repository; import java.util.List; import org.springframework.data.jpa.repository.JpaRepository; import com.example.account.model.Journal; public interface JournalRepository extends JpaRepository\u003cJournal, Long\u003e { List\u003cJournal\u003e findJournalByAccountId(long accountId); } ``` Update the AccountController constructor Update the constructor for AccountController so that both the repositories are injected. You will need to create a variable to hold each. Your updated constructor should look like this:\n```java import com.example.repository.JournalRepository; // ... final AccountRepository accountRepository; final JournalRepository journalRepository; public AccountController(AccountRepository accountRepository, JournalRepository journalRepository) { this.accountRepository = accountRepository; this.journalRepository = journalRepository; } ``` Add new method to POST entries to the journal Add a new HTTP POST endpoint in the AccountController.java class. The method accepts a journal entry in the request body and saves it into the database. Your new method should look like this:\n```java import com.example.model.Journal; // ... @PostMapping(\"/account/journal\") public ResponseEntity\u003cJournal\u003e postSimpleJournalEntry(@RequestBody Journal journalEntry) { try { Journal _journalEntry = journalRepository.saveAndFlush(journalEntry); return new ResponseEntity\u003c\u003e(_journalEntry, HttpStatus.CREATED); } catch (Exception e) { return new ResponseEntity\u003c\u003e(null, HttpStatus.INTERNAL_SERVER_ERROR); } } ``` Add new method to get journal entries Add a new HTTP GET endpoint in the AccountController.java class to get a list of journal entries for a given accountId. Your new method should look like this:\n```java import com.example.account.repository.JournalRepository; @GetMapping(\"/account/{accountId}/journal\") public List\u003cJournal\u003e getJournalEntriesForAccount(@PathVariable(\"accountId\") long accountId) { return journalRepository.findJournalByAccountId(accountId); } ``` Add new method to update an existing journal entry Add a new HTTP POST endpoint to update and existing journal entry to a cleared deposit. To do this, you set the journalType field to DEPOSIT. Your method should accept the journalId as a path variable. If the specified journal entry does not exist, return a 202 (Accepted) to indicate the message was received but there was nothing to do. Returning a 404 (Not found) would cause an error and the message would get requeued and reprocessed, which we don’t want. Your new method should look like this:\n```java @PostMapping(\"/account/journal/{journalId}/clear\") public ResponseEntity\u003cJournal\u003e clearJournalEntry(@PathVariable long journalId) { try { Optional\u003cJournal\u003e data = journalRepository.findById(journalId); if (data.isPresent()) { Journal _journalEntry = data.get(); _journalEntry.setJournalType(\"DEPOSIT\"); journalRepository.saveAndFlush(_journalEntry); return new ResponseEntity\u003cJournal\u003e(_journalEntry, HttpStatus.OK); } else { return new ResponseEntity\u003cJournal\u003e(new Journal(), HttpStatus.ACCEPTED); } } catch (Exception e) { return new ResponseEntity\u003c\u003e(null, HttpStatus.INTERNAL_SERVER_ERROR); } } ``` Build a JAR file for deployment Run the following command to build the JAR file. Note that you will need to skip tests now, since you updated the application.yaml and it no longer points to your local test database instance.\n```shell $ mvn clean package -DskipTests ``` The service is now ready to deploy to the backend.\nGet the password for the obaas-admin user. The obaas-admin user is the equivalent of the admin or root user in the Oracle Backend for Spring Boot and Microservices backend. Execute the following command to get the password:\n```shell $ kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d ``` Prepare the backend for deployment The Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel (unless you already have the tunnel running from previous labs) using this command:\n```shell $ kubectl -n obaas-admin port-forward svc/obaas-admin 8080 ``` Start the Oracle Backend for Spring Boot and Microservices CLI (oractl) using this command:\n```shell $ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e ``` Connect to the Oracle Backend for Spring Boot and Microservices admin service using the connect command. Enter obaas-admin and the username and use the password you collected earlier.\n```shell oractl:\u003econnect ? username obaas-admin ? password ************* Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e ``` Deploy the account service You will now deploy your account service to the Oracle Backend for Spring Boot and Microservices using the CLI. Run this command to redeploy your service, make sure you provide the correct path to your JAR file. Note that this command may take 1-3 minutes to complete:\n```shell oractl:\u003e deploy --app-name application --service-name account --artifact-path /path/to/account-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: account/target/account-0.0.1-SNAPSHOT.jarbuilding and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` Verify the new endpoints in the account service In the next three commands, you need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n```shell $ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13d ``` Test the create journal entry endpoint (make sure you use an accountId that exits in your database) with this command, use the IP address for your API Gateway.\n```shell $ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"journalType\": \"PENDING\", \"accountId\": 2, \"journalAmount\": 100.00, \"lraId\": \"0\", \"lraState\": \"\"}' \\ http://[EXTERNAL-IP]/api/v1/account/journal HTTP/1.1 201 Date: Wed, 31 May 2023 13:02:10 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"journalId\":1,\"journalType\":\"PENDING\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":\"\",\"journalAmount\":100} ``` Notice that the response contains a journalId which you will need in a later command, and that the journalType is PENDING.\nTest the get journal entries endpoint with this command, use the IP address for your API Gateway and the same accountId as in the previous step. Your output may be different:\n```shell $ curl -i http://[EXTERNAL-IP]/api/v1/account/[accountId]/journal HTTP/1.1 200 Date: Wed, 31 May 2023 13:03:22 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive [{\"journalId\":1,\"journalType\":\"PENDING\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":100}] ``` Test the update/clear journal entry endpoint with this command, use the IP address for your API Gateway and the journalId from the first command’s response:\n```shell $ curl -i -X POST http://[EXTERNAL-IP]/api/v1/account/journal/[journalId]/clear HTTP/1.1 200 Date: Wed, 31 May 2023 13:04:36 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"journalId\":1,\"journalType\":\"DEPOSIT\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":100} ``` That completes the updates for the Account service.",
    "description": "Starting with the account service that you built in the previous lab, you will the JPA model and repository for the journal and some new endpoints.\nCreate the Journal model Create a new Java file in src/main/java/com/example/accounts/model called Journal.java. In this class you can define the fields that make up the journal. Note that you created the Journal table in the previous lab. You will not use the lraId and lraState fields until a later lab.",
    "tags": [],
    "title": "Add Journal to the Account service",
    "uri": "/microservices-datadriven/cloudbank/check/update-account/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": " Create application JAR files\nIn the directory (root) where you cloned (or unzipped) the application and build the application JARs using the following command:\nmvn clean packageThe output should be similar to this:\n[INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for CloudBank 0.0.1-SNAPSHOT: [INFO] [INFO] CloudBank .......................................... SUCCESS [ 0.916 s] [INFO] account ............................................ SUCCESS [ 2.900 s] [INFO] checks ............................................. SUCCESS [ 1.127 s] [INFO] customer ........................................... SUCCESS [ 1.106 s] [INFO] creditscore ........................................ SUCCESS [ 0.908 s] [INFO] transfer ........................................... SUCCESS [ 0.455 s] [INFO] testrunner ......................................... SUCCESS [ 0.942 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 9.700 s [INFO] Finished at: 2024-01-18T15:52:56-06:00 [INFO] ------------------------------------------------------------------------ ",
    "description": "Create application JAR files\nIn the directory (root) where you cloned (or unzipped) the application and build the application JARs using the following command:\nmvn clean packageThe output should be similar to this:\n[INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for CloudBank 0.0.1-SNAPSHOT: [INFO] [INFO] CloudBank .......................................... SUCCESS [ 0.916 s] [INFO] account ............................................ SUCCESS [ 2.900 s] [INFO] checks ............................................. SUCCESS [ 1.127 s] [INFO] customer ........................................... SUCCESS [ 1.106 s] [INFO] creditscore .",
    "tags": [],
    "title": "Build CloudBank",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/build/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with an IDE",
    "content": " Create application JAR files\nIn the directory where you cloned (or unzipped) the application and build the application JARs using the following command:\n\u003ccopy\u003emvn clean package\u003c/copy\u003eThe output should be similar to this:\n[INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for cloudbank 0.0.1-SNAPSHOT: [INFO] [INFO] cloudbank .......................................... SUCCESS [ 0.972 s] [INFO] account ............................................ SUCCESS [ 2.877 s] [INFO] customer ........................................... SUCCESS [ 1.064 s] [INFO] creditscore ........................................ SUCCESS [ 0.922 s] [INFO] transfer ........................................... SUCCESS [ 0.465 s] [INFO] testrunner ......................................... SUCCESS [ 0.931 s] [INFO] checks ............................................. SUCCESS [ 0.948 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 8.480 s [INFO] Finished at: 2023-11-06T12:35:17-06:00 [INFO] ------------------------------------------------------------------------ ",
    "description": "Create application JAR files\nIn the directory where you cloned (or unzipped) the application and build the application JARs using the following command:\n\u003ccopy\u003emvn clean package\u003c/copy\u003eThe output should be similar to this:\n[INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary for cloudbank 0.0.1-SNAPSHOT: [INFO] [INFO] cloudbank .......................................... SUCCESS [ 0.972 s] [INFO] account ............................................ SUCCESS [ 2.877 s] [INFO] customer ........................................... SUCCESS [ 1.064 s] [INFO] creditscore ........................................ SUCCESS [ 0.922 s] [INFO] transfer .",
    "tags": [],
    "title": "Build CloudBank",
    "uri": "/microservices-datadriven/cloudbank/deploy-ide/build/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Oracle Backend for Spring Boot and Microservices includes an Oracle Autonomous Database instance. You can manage and access the database from the OCI Console.\nView details of the Oracle Autonomous Database\nIn the OCI Console, in the main (“hamburger”) menu navigate to the Oracle Database category and then Oracle Autonomous Database. Make sure you have the correct region selected (in the top right corner) and the compartment where you installed Oracle Backend for Spring Boot and Microservices (on the left hand side pull down list). You will a list of Oracle Autonomous Database instances (you will probably only have one):\nClick on the database name link to view more information about that instance. ON this page, you can see important information about your Oracle Autonomous Database instance, and you can manage backups, access and so on. You can also click on the Performance Hub button to access information about the performance of your database instance.\nYou can manage scaling from here by clicking on the Manage resource allocation button which will open this form where you can adjust the ECPU and storage for the Autonomous Database instance.\nExplore Oracle Backend for Spring Boot and Microservices database objects\nClick on the Database Actions button and select SQL to open a SQL Worksheet.\nDepending on choices you made during installation, you may go straight to SQL Worksheet, or you may need to enter credentials first. If you are prompted to login, use the username ADMIN and obtain the password from Kubernetes with this command (make sure to change the secret name to match the name you chose during installation):\n$ kubectl -n application get secret obaasdevdb-db-secrets -o jsonpath='{.data.db\\.password}' | base64 -d In the SQL Worksheet, you can the first pull down list in the Navigator on the left hand side to see the users and schema in the database. Choose the CONFIGSERVER user to view tables (or other objects) for that user. This is the user associated with the Spring Config Server.\nExecute this query to view tables associated with various Spring Boot services and the CloudBank:\nselect owner, table_name from dba_tables where owner in ('ACCOUNT', 'CUSTOMER', 'CONFIGSERVER', 'AZNSERVER') Feel free to explore some of these tables to see the data.",
    "description": "Oracle Backend for Spring Boot and Microservices includes an Oracle Autonomous Database instance. You can manage and access the database from the OCI Console.\nView details of the Oracle Autonomous Database\nIn the OCI Console, in the main (“hamburger”) menu navigate to the Oracle Database category and then Oracle Autonomous Database. Make sure you have the correct region selected (in the top right corner) and the compartment where you installed Oracle Backend for Spring Boot and Microservices (on the left hand side pull down list).",
    "tags": [],
    "title": "Explore Oracle Autonomous Database",
    "uri": "/microservices-datadriven/cloudbank/backend/database/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Provision an Instance",
    "content": "This option allows you to run Oracle Backend for Spring Boot and Microservices in a containerized environment inside a single OCI Compute Instance. This option is good if you do not have enough free capacity on your local machine to run the environment, and if you do not have or want to use the resources required for a full production-sized deployment. This option provides an environment with adequate resources for development and testing, but minimizes the resource usage and costs.\nNote: You only need to choose one of the three deployment options - local, OCI Free Tier or OCI Marketplace.\nYou can also use this approach in any regular commercial Oracle Cloud Tenancy - just skip the first step and start at step 2!\nGet an Oracle Cloud Free Tier account\nIf you do not already have one, you can obtain an Oracle Cloud Free Tier account as follows:\nOpen a browser and navigate to the Oracle Cloud Free Tier signup page. Complete the requested details and click on the Verify email button. You will receive an email from “Oracle Cloud” with instructions on how to verify your email address. On the Account Information page, enter the requested details. When completed, click on the Start my free trial button. You will need to wait a few minutes while your account is created and set up. When the set up is completed, you will see the login page. You will also receive an email confirmation. Log in to your new account. You may be asked to configured secure verification. Copy the custom compute image\nChoose a compartment in the drop down box on the left hand side of the OCI Console.\nNote: If you use or plan to use this OCI Cloud account for other purposes as well, Oracle recommends creating compartments to simplify management. You can create a compartment by navigating to the Compartments page in the Identity section of OCI Console. You can use the root compartment if you wish, but it is not generally recommended.\nNavigate to the Custom Instances page by opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “image”:\nClick on the Import image button.\nChoose the option to Import from an Object Storage URL and provide the following URL in the Object Storage URL field:\nhttps://objectstorage.us-ashburn-1.oraclecloud.com/p/oSwRpU_9v5NGzkJ-P0qKzT1ZN-Y9lJZu1aXO_2N-rkGdJs-hKJt10bRk9TxsCceF/n/maacloud/b/cloudbank-public/o/obaas-1.3.0-2 (Important) Under Image type choose the OCI option.\nClick on the Import image button to start the import.\nNote: that it might take approximately 10 to 15 minutes to complete the import. You can see the progress on the Custom image details page that will be displayed.\nCreate a compute instance\nChoose a compartment in the drop down box on the left hand side of the OCI Console.\nNote: If you use or plan to use this OCI Cloud account for other purposes as well, Oracle recommends creating compartments to simplify management. You can create a compartment by navigating to the Compartments page in the Identity section of OCI Console. You can use the root compartment if you wish, but it is not generally recommended.\nNavigate to the Compute Instances page by clicking on the link on the home page of the OCI Console or opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “instance”:\nCreate a Compute Instance by clicking on the Create instance button.\nEnter a name for the instance, for example obaas-instance.\nScroll down to the Image and shape section and click on the Change Image button to edit the details.\nIn the image source, choose the option for My ../images and choose the image the you imported in the previous step.\nNote: The image will not show up until the import is completed.\nClick on the Select image button to confirm your choice.\nClick on the Change shape button to choose the shape of your instance. Oracle recommends 2 OCPUs and 32 GB of memory to run this CloudBank environment.\nClick on the Select shape button to confirm your choice.\nLeave the default values in the Primary VNIC Section. By doing so a virtual network and subnets will be created for you.\nIn the SSH Keys section, make sure you provide SSH keys so you can log into your instance. You may provide an existing public key if you have one, or generate new keys.\nClick on the Create button to create the instance. The instance and the virtual network will be started, this will take a few moments.\nStart Oracle Backend for Spring Boot and Microservices\nNote the Public IP Address of your newly created instance in the Instance access section of the Instance details page that is displayed.\nLog into the compute instance using SSH, for example:\nssh -i \u003cpath and filename of private key\u003e -L 1443:localhost:443 ubuntu@207.211.186.88 You will need to use the IP address of your instance in this command. Note that the example command also creates a port forward so that you will be able to access various Web UI’s from your local machine.\nYou will be asked to confirm the authenticity of your SSH keys, enter yes.\nThe environment will start automatically, including a Kubernetes cluster in a container (using k3s), Oracle Backend for Spring Boot and Microservices and an Oracle Database instance inside that cluster. It will take approximately six minutes for all of the containers to reach ready/running state. You can watch the progress using this command:\nwatch kubectl get pod -A Note: Should you require access to it, the kubeconfig file for your cluster is located at this location:\n/home/ubuntu/obaas/k3s_data/kubeconfig/kubeconfig.yamlWhen the environment is fully started, the output will appear similar to this:\nVerify access to web user interfaces\nOn your local machine, open a browser and navigate to the Spring Operations Center.\nLog in using the pre-defined user obaas-admin and password Welcome-12345.\nNote: Since this is a development environment with no DNS name, it is configured with self-signed certificates. Your browser will warn you about the connection security.\nIf you are using Chrome, click on the Advanced link and then the Proceed to localhost (unsafe) link. If you are using a different browser, perform the equivalent actions.\nThe Spring Operations Center main dashboard will appear similar to this:",
    "description": "This option allows you to run Oracle Backend for Spring Boot and Microservices in a containerized environment inside a single OCI Compute Instance. This option is good if you do not have enough free capacity on your local machine to run the environment, and if you do not have or want to use the resources required for a full production-sized deployment. This option provides an environment with adequate resources for development and testing, but minimizes the resource usage and costs.",
    "tags": [],
    "title": "Install in OCI Free Tier",
    "uri": "/microservices-datadriven/cloudbank/provision/install-free-trial/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "Oracle recommends the Java SE Development Kit. Themoduleis using Spring Boot 3.3.x so Java 21 is required.\nDownload and install the Java Development Kit\nDownload the latest x64 Java 21 Development Kit from Java SE Development Kit.\nDecompress the archive in your chosen location, e.g., your home directory and then add it to your path (the exact version of Java might differ in your environment):\nexport JAVA_HOME=$HOME/jdk-21.0.3 export PATH=$JAVA_HOME/bin:$PATH Verify the installation\nVerify the Java Development Kit is installed with this command (the exact version of Java might differ in your environment):\n$ java -version java version \"21.0.3\" 2022-04-19 LTS Java(TM) SE Runtime Environment (build 21.0.3+8-LTS-111) Java HotSpot(TM) 64-Bit Server VM (build 21.0.3+8-LTS-111, mixed mode, sharing) Note: Native Images: If you want to compile your Spring Boot microservices into native images, you must use GraalVM, which can be downloaded from here.",
    "description": "Oracle recommends the Java SE Development Kit. Themoduleis using Spring Boot 3.3.x so Java 21 is required.\nDownload and install the Java Development Kit\nDownload the latest x64 Java 21 Development Kit from Java SE Development Kit.\nDecompress the archive in your chosen location, e.g., your home directory and then add it to your path (the exact version of Java might differ in your environment):\nexport JAVA_HOME=$HOME/jdk-21.0.3 export PATH=$JAVA_HOME/bin:$PATH Verify the installation",
    "tags": [],
    "title": "Install JDK",
    "uri": "/microservices-datadriven/cloudbank/devenv/jdk/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "There are different models that can be used to coordinate transactions across services. Three of the most common are XA (Extended Architecture) which focuses on strong consistency, LRA (Long Running Action) which provides eventual consistency, and TCC (Try-Confirm/Cancel) which uses a reservation model. Oracle Backend for Spring Boot and Microservices includes Oracle Transaction Manager for Microservices which supports all three of these options.\nIn this module, you will explore the Long Running Action model. In this model there is a logical coordinator and a number of participants. Each participant is responsible for performing work and being able to compensate if necessary. The coordinator essentially manages the lifecycle of the LRA, for example by telling participants when to cancel or complete.\nYou will create the Transfer service in the diagram above, and the participant endpoints in the Account service (deposit and withdraw). Oracle Transaction Manager for Microservices (also known as “MicroTx”) will coordinate the LRA.\nYou will implement the LRA using the Eclipse Microprofile LRA library which provides an annotation-based approach to managing the LRA, which is very familiar for Spring Boot developers.\nThe main annotations used in an LRA application are as follows:\n@LRA - Controls the life cycle of an LRA. @Compensate - Indicates that the method should be invoked if the LRA is cancelled. @Complete - Indicates that the method should be invoked if the LRA is closed. @Forget - Indicates that the method may release any resources that were allocated for this LRA. @Leave - Indicates that this class is no longer interested in this LRA. @Status - When the annotated method is invoked it should report the status. If you would like to learn more, there is a lot of detail in the Long Running Action specification.\nKeeping track of local transactions made in an LRA Microservices are often designed to be stateless, to push all the state into the datastore. This makes it easier to scale by running more instances of services, and it makes it easier to debug issues because there is no state stored in process memory. It also means you need a way to correlate transactions with the LRA they were performed by.\nYou will add a JOURNAL table to the account microservice’s database. This table will contain the “bank account transactions” (deposits, withdrawals, interest payments, etc.) for this account (not to be confused with “database transactions” as in the two-phase commit protocol). The account service will track LRA’s associated with each journal entry (bank account transaction) in a column in the journal table.\nAs LRA is an eventual consistency model, the approach you will take in the account service will be to store bank account transactions as “pending” in the journal table. Pending transactions will not be considered when calculating the account balance until they are finalized (“completed”). When the LRA reaches the “complete” phase, the pending transactions will be considered finalized and the account balance will be updated to reflect those transactions.\nNote: Unlike Java Transaction Architecture (JTA) where “in-doubt” tables are created automatically to keep track of pending transactions, LRA is only concerned with the orchestration of the API calls, so participants need to track transactions themselves. In this module you will use the journal table both to store the transactions and to track the lRA. Of course, this could also be done with separate tables if desired.\nYou will now start implementing the Cloud Cash Payment LRA.",
    "description": "There are different models that can be used to coordinate transactions across services. Three of the most common are XA (Extended Architecture) which focuses on strong consistency, LRA (Long Running Action) which provides eventual consistency, and TCC (Try-Confirm/Cancel) which uses a reservation model. Oracle Backend for Spring Boot and Microservices includes Oracle Transaction Manager for Microservices which supports all three of these options.\nIn this module, you will explore the Long Running Action model.",
    "tags": [],
    "title": "Learn about Long Running Actions",
    "uri": "/microservices-datadriven/cloudbank/saga/learn-lra/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Cleanup",
    "content": " Note: These steps apply only if you chose the option to install in OCI Free Tier.\nLogin into your OCI Free Trail account.\nDelete the Compute Instance.\nSelect the compartment where you installed the Compute instance in the drop down box on the left hand side of the OCI Console.\nNavigate to the Compute Instances page by clicking on the link on the home page of the OCI Console or opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “instance”:\nClick on the compute instance name. The name of your instance will be different than the example below.\nClick on the Terminate button.\nIn the Terminate Instance dialog box it is VERY important that you select Permanently delete the attached boot volume.\nThe instance will now be terminated. This process will take a few minutes. When the status of the instance changes to terminated you can move on to the next step.\nDelete the Custom Image.\nSelect the compartment where you created the Custom image in the drop down box on the left hand side of the OCI Console.\nNavigate to the Custom Instances page by opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “image”:\nClock in the three little dots on the right hand side of table and select Delete. And confirm by clicking the Delete button in the dialog box.\nThe custom image you created is now deleted.\nDelete the Virtual Cloud Network.\nSelect the compartment where you installed the Compute instance in the drop down box on the left hand side of the OCI Console.\nNavigate to the Virtual cloud networks page by clicking on the link on the home page of the OCI Console or opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “instance”:\nClick on the network name.\nClick on the Delete button.\nIn the Delete Virtual Cloud Network dialog box, it is important that you select Specific Compartment and the compartment where you installed the VCN. Otherwise the scan will can all the compartments in the tenancy. Click on the Scan button.\nWhen the scan is complete, click on the Delete All button. Click the Close button when the deletion is complete.\nThe VCN you created is now deleted.",
    "description": "Note: These steps apply only if you chose the option to install in OCI Free Tier.\nLogin into your OCI Free Trail account.\nDelete the Compute Instance.\nSelect the compartment where you installed the Compute instance in the drop down box on the left hand side of the OCI Console.\nNavigate to the Compute Instances page by clicking on the link on the home page of the OCI Console or opening the main menu using the “hamburger” icon ( ) in the top left corner of the console and searching for “instance”:",
    "tags": [],
    "title": "OCI Free Tier Cleanup",
    "uri": "/microservices-datadriven/cloudbank/cleanup/uninstall-free-trial/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with an IDE",
    "content": " If you have done the optional Task 11 of Lab. 2, you could proceed doing the activities from Task 3 to Task 5 using Oracle Backend for Spring Boot VS Code plugin. If you don’t see the plugin in the left bar, with the Oracle logo, as shown here:\nclick on Additional Views menu to select the Oracle Backend fo Spring Boot and Microservices.\nThe Oracle Backend fo Spring Boot and Microservices VS Code plugin will ask to specify the Kubernetes config file full path as shown here:\nBy default, it’s shown the path in the user’s Home directory .kube/config in which normally kubectl stores all the information regarding the K8S clusters configured. You could set the full path of another Kubernetes config file. If the file is correctly loaded, the plugin will show the list of contexts available in which select one:\nIn positive case, you should see a tree view with one node and the context chosen:\nIf the file path it hasn’t been correctly set, it will show an error message:\nTo restart the plugin and proceed again in Kubernetes config file setting, in command palette execute a Reload Window command:\nHow to access to cluster\nUntil you create a dedicated ssh tunnel to the Kubernetes cluster, and you don’t connect to Oracle Backend for Spring Boot admin services, you will not be able to browse resources included into the Oracle Backend for Spring Boot deployment. To do this, follow these steps:\nObtain the obaas-admin password by executing the following command in a terminal window to get the obaas-admin password:\n$ \u003ccopy\u003ekubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d\u003c/copy\u003e Right-click on the cluster name and select Set UID/PWD:\nEnter the username obaas-admin for the Oracle Backend for Spring Boot.\nFollowed by the password you obtained in an earlier step:\nTwo message boxes will confirm credentials have been set correctly:\nWARNING: if you don’t execute this steps and try to expand the kubernetes context, you will receive a message:\nSelect again the cluster and click the right mouse button and choose Create Admin tunnel menu item.\nVS Code will open a new terminal that will try to open a tunnel to the Kubernetes cluster on a local port, starting from 8081:\nBefore proceed to connection, please wait until the tunnel is established and the terminal shows a message like this:\nNOTE: if the K8s cluster it’s not related to an Oracle Backend for Spring Boot deployment, the tunnel creation will fail. In this case in command palette execute a window reload too chose another cluster. If you have any problem in connection, you could start another tunnel: the plugin will try on another local port to connect to the cluster.\nAgain select the cluster and by clicking the right mouse button choose Connect menu item. This will create a session with credentials set at the first step.\nExplore resources\nAs soon as completed the steps to create tunnel, and you get connected to the backend, it’s possible to expand or refresh the tree related to the deployment.\nYou’ll see four top classes of resources that can be exploded in underlying items:\napplications: the list of applications deployed and the services holding Oracle DB: in this release we have one Database in which are stored configuration and schema related to services deployed platformServices: the list of Oracle Backend for Spring Boot deployed services, like Grafana, Spring, Apisix, Eureka and Jaeger. oBaasConf: the list of keys defined by application, stored in the ADB provisioned and available to share configuration information among services in each application. Let’s go to show the operations you can do on each item of browse tree.\nOpen the list clicking on the arrow at the left of applications, and then expand the application about you want to know which services includes:\nit should be empty. If not, proceed to delete the full application and re-create it through the plug-in:\nFirst, select the default application and with right-click on mouse, select Delete application:\nWait a moment and refresh the content of applications leaf. When empty, select applications and with right-click on mouse, select Add application:\nFill in the command palette the (application name) with application:\nThe four Spring Boot microservices deployment\nFirst it must be bind the service if the case. For account service you have to:\nSelect applications leaf and with right click select Bind a service item menu:\nand the input following values:\nService Name: account DB User (optional): DB User Password: Welcome1234## Spring Binding Prefix (optional): spring.datasource Update: False you’ll get the message:\nRepeat the same for:\nchecks service you have to:\nService Name: checks DB User (optional): account DB User Password: Welcome1234## Spring Binding Prefix (optional): spring.datasource Update: False customer service you have to:\nService Name: customer DB User (optional): DB User Password: Welcome1234## Spring Binding Prefix (optional): spring.datasource Update: False testrunner service you have to:\nService Name: testrunner DB User (optional): account DB User Password: Welcome1234## Spring Binding Prefix (optional): spring.datasource Update: False Ensure to get the message like this for all previous binding:\nLet’s start with the first service deployment:\nSelect application under applications and Right-click on mouse to select Add service -\u003e upload .jar:\nLook for the accounts-0.0.1-SNAPSHOT.jar file built previously:\nIn the command palette will be asked all the parameters needed to upload the services:\nService Name : account\nBind [jms] : ``\nImage Version: 0.0.1\nJava Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0\nAdd Health probe?: False\nService Port: leave default 8080\nService Profile: leave default obaas\nInitial Replicas : 1\nInform the database name for Liquibase: admin\nYou will see messages that confirm the deployment is started:\nFinally, you’ll receive the message “Service deployed successfully”:\nRefreshing the application leaf, you should see now:\nRepeat the same for:\nchecks service deployment:\nLook for the checks-0.0.1-SNAPSHOT.jar file built previously Service Name : checks Bind [jms] : `` Image Version: 0.0.1 Java Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0 Add Health probe?: False Service Port: leave default 8080 Service Profile: leave default obaas Initial Replicas : 1 Inform the database name for Liquibase: admin customer service deployment:\nLook for the customer-0.0.1-SNAPSHOT.jar file built previously Service Name : customer Bind [jms] : `` Image Version: 0.0.1 Java Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0 Add Health probe?: False Service Port: leave default 8080 Service Profile: leave default obaas Initial Replicas : 1 Inform the database name for Liquibase: admin creditscore service deployment:\nLook for the creditscore-0.0.1-SNAPSHOT.jar file built previously Service Name : creditscore Bind [jms] : `` Image Version: 0.0.1 Java Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0 Add Health probe?: False Service Port: leave default 8080 Service Profile: leave default obaas Initial Replicas : 1 Inform the database name for Liquibase: `` testrunner service deployment:\nLook for the testrunner-0.0.1-SNAPSHOT.jar file built previously Service Name : testrunner Bind [jms] : `` Image Version: 0.0.1 Java Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0 Add Health probe?: False Service Port: leave default 8080 Service Profile: leave default obaas Initial Replicas : 1 Inform the database name for Liquibase: `` transfer service deployment:\nLook for the transfer-0.0.1-SNAPSHOT.jar file built previously Service Name : transfer Bind [jms] : `` Image Version: 0.0.1 Java Image: leave default ghcr.io/graalvm/jdk:ol7-java17-22.2.0 Add Health probe?: False Service Port: leave default 8080 Service Profile: leave default obaas Initial Replicas : 1 Inform the database name for Liquibase: `` Be sure to receive for all the deployments a message that confirms the deployment is started and finally “Service deployed successfully”.\nNow we have the three services up \u0026 running as you should see from VS Code plug-in:\nVerify that the services are running properly by executing this command:\n$ \u003ccopy\u003ekubectl get all -n application\u003c/copy\u003eThe output should be similar to this, all applications must have STATUS as Running\n(base) cdebari@cdebari-mac ~ % kubectl get all -n application NAME READY STATUS RESTARTS AGE pod/account-777c6b57dc-mgnq9 1/1 Running 0 17m pod/checks-65cf5f77f9-nfqt4 1/1 Running 0 15m pod/creditscore-648fd868ff-twjsl 1/1 Running 0 9m43s pod/customer-5dc57bc575-2n6mf 1/1 Running 0 13m pod/testrunner-7df6f8f4c5-6t6gf 1/1 Running 0 8m50s pod/transfer-59d9c55df5-llppn 1/1 Running 0 7m57s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/account ClusterIP 10.96.140.242 \u003cnone\u003e 8080/TCP 17m service/checks ClusterIP 10.96.61.226 \u003cnone\u003e 8080/TCP 15m service/creditscore ClusterIP 10.96.97.155 \u003cnone\u003e 8080/TCP 9m44s service/customer ClusterIP 10.96.118.193 \u003cnone\u003e 8080/TCP 13m service/testrunner ClusterIP 10.96.235.62 \u003cnone\u003e 8080/TCP 8m51s service/transfer ClusterIP 10.96.98.16 \u003cnone\u003e 8080/TCP 7m58s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/account 1/1 1 1 17m deployment.apps/checks 1/1 1 1 15m deployment.apps/creditscore 1/1 1 1 9m44s deployment.apps/customer 1/1 1 1 13m deployment.apps/testrunner 1/1 1 1 8m51s deployment.apps/transfer 1/1 1 1 7m58s NAME DESIRED CURRENT READY AGE replicaset.apps/account-777c6b57dc 1 1 1 17m replicaset.apps/checks-65cf5f77f9 1 1 1 15m replicaset.apps/creditscore-648fd868ff 1 1 1 9m44s replicaset.apps/customer-5dc57bc575 1 1 1 13m replicaset.apps/testrunner-7df6f8f4c5 1 1 1 8m51s replicaset.apps/transfer-59d9c55df5 1 1 1 7m58s Expose the services using APISIX Gateway\nExecute the same actions as described in Lab. 5, Task 5 except for the step 4., that it could be executed in the following alternative way, accessing comfortably to the APISIX admin console straight from VS Code.\nSelect under platformServices the leaf apisix and, with a right-click on mouse, select Open Apisix console:\nIt will open a terminal window in which it will be started a tunneling to that service, that will end opening a message box with a button you can click to open the APISIX admin console in a new browser:",
    "description": "If you have done the optional Task 11 of Lab. 2, you could proceed doing the activities from Task 3 to Task 5 using Oracle Backend for Spring Boot VS Code plugin. If you don’t see the plugin in the left bar, with the Oracle logo, as shown here:\nclick on Additional Views menu to select the Oracle Backend fo Spring Boot and Microservices.\nThe Oracle Backend fo Spring Boot and Microservices VS Code plugin will ask to specify the Kubernetes config file full path as shown here:",
    "tags": [],
    "title": "Using the VS Code plugin",
    "uri": "/microservices-datadriven/cloudbank/deploy-ide/using-vscode/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "In this module, you will build microservices that use asynchronous messaging to communicate using Spring JMS and Oracle Transactional Event Queues. It introduces service discovery using Eureka Service Registry (part of Spring Cloud Netflix) and Spring Cloud OpenFeign.",
    "description": "In this module, you will build microservices that use asynchronous messaging to communicate using Spring JMS and Oracle Transactional Event Queues. It introduces service discovery using Eureka Service Registry (part of Spring Cloud Netflix) and Spring Cloud OpenFeign.",
    "tags": [],
    "title": "Check Processing",
    "uri": "/microservices-datadriven/cloudbank/check/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": " Create the queues Connect to the database as the ADMIN user and execute the following statements to give the account user the necessary permissions to use queues. Note: module 2, Task 9 provided details on how to connect to the database.\n```sql grant execute on dbms_aq to account; grant execute on dbms_aqadm to account; grant execute on dbms_aqin to account; commit; ``` Now connect as the account user and create the queues by executing these statements (replace [TNS-ENTRY] with your environment information). You can get the TNS Entries by executing SHOW TNS in the sql shell:\n```sql connect account/Welcome1234##@[TNS-ENTRY]; begin -- deposits dbms_aqadm.create_queue_table( queue_table =\u003e 'deposits_qt', queue_payload_type =\u003e 'SYS.AQ$_JMS_TEXT_MESSAGE'); dbms_aqadm.create_queue( queue_name =\u003e 'deposits', queue_table =\u003e 'deposits_qt'); dbms_aqadm.start_queue( queue_name =\u003e 'deposits'); -- clearances dbms_aqadm.create_queue_table( queue_table =\u003e 'clearances_qt', queue_payload_type =\u003e 'SYS.AQ$_JMS_TEXT_MESSAGE'); dbms_aqadm.create_queue( queue_name =\u003e 'clearances', queue_table =\u003e 'clearances_qt'); dbms_aqadm.start_queue( queue_name =\u003e 'clearances'); end; / ``` You have created two queues named deposits and clearances. Both of them use the JMS TextMessage format for the payload.",
    "description": "Create the queues Connect to the database as the ADMIN user and execute the following statements to give the account user the necessary permissions to use queues. Note: module 2, Task 9 provided details on how to connect to the database.\n```sql grant execute on dbms_aq to account; grant execute on dbms_aqadm to account; grant execute on dbms_aqin to account; commit; ``` Now connect as the account user and create the queues by executing these statements (replace [TNS-ENTRY] with your environment information).",
    "tags": [],
    "title": "Create Queues in the Database",
    "uri": "/microservices-datadriven/cloudbank/check/create-queues/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": " Obtain the obaas-admin password.\nExecute the following command to get the obaas-admin password:\nkubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d Start a tunnel to the backend service.\nThe Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Use kubectl to start a port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command:\n$ kubectl -n obaas-admin port-forward svc/obaas-admin 8080:8080 Forwarding from 127.0.0.1:8080 -\u003e 8080 Forwarding from [::1]:8080 -\u003e 8080 Start the Oracle Backend for Spring Boot and Microservices CLI oractl\nOpen a new terminal Window or Tab and start the Oracle Backend for Spring Boot and Microservices CLI (oractl) using this command:\n$ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e Connect to the Oracle Backend for Spring Boot and Microservices admin service called obaas-admin\nConnect to the Oracle Backend for Spring Boot and Microservices admin service using this command. Use thr password you obtained is Step 1.\noractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e Deploy CloudBank\nCloudBank will be deployed using a script into the namespace application. The script does the following:\nExecutes the bind command for the services that requires database access. Deploys the CloudBank services. What happens when you use the oractl CLI bind command? When you run the bind command, the oractl tool does several things for you:\nAsks for Database user credentials. Creates or updates a k8s secret with the provided user credentials. Creates a Database Schema with the provided user credentials. What happens when you use the Oracle Backend for Spring Boot and Microservices CLI (oractl) deploy command? When you run the deploy command, oractl does several things for you:\nUploads the JAR file to server side Builds a container image and push it to the OCI Registry Inspects the JAR file and looks for bind resources (JMS) Create the microservices deployment descriptor (k8s) with the resources supplied Applies the k8s deployment and create k8s object service to microservice The services are using Liquibase. Liquibase is an open-source database schema change management solution which enables you to manage revisions of your database changes easily. When the service gets deployed the tables and sample data will be created and inserted by Liquibase. The SQL executed can be found in the source code directories of CloudBank.\nRun the following command to deploy CloudBank. When asked for Database/Service Password: enter the password Welcome1234##. You need to do this multiple times. NOTE: The deployment of CloudBank will take a few minutes.\noractl:\u003escript --file deploy-cmds/deploy-cb-java21.txtThe output should look similar to this:\nDatabase/Service Password: ************* Schema {account} was successfully Created and Kubernetes Secret {application/account} was successfully Created. Database/Service Password: ************* Schema {account} was successfully Not_Modified and Kubernetes Secret {application/checks} was successfully Created. Database/Service Password: ************* Schema {customer} was successfully Created and Kubernetes Secret {application/customer} was successfully Created. Database/Service Password: ************* Schema {account} was successfully Not_Modified and Kubernetes Secret {application/testrunner} was successfully Created. uploading: account/target/account-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S uploading: checks/target/checks-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S uploading: customer/target/customer-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S uploading: creditscore/target/creditscore-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S uploading: testrunner/target/testrunner-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S uploading: transfer/target/transfer-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed. NOTICE: service not accessible outside K8S ",
    "description": "Obtain the obaas-admin password.\nExecute the following command to get the obaas-admin password:\nkubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d Start a tunnel to the backend service.\nThe Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Use kubectl to start a port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command:",
    "tags": [],
    "title": "Deploy CloudBank",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/deploy/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Oracle Backend for Spring Boot and Microservices includes Spring Admin which provides a web user interface for managing and monitoring Spring applications.\nConnect to Spring Admin\nOracle Backend for Spring Boot and Microservices does not expose management interfaces outside the Kubernetes cluster for improved security. Oracle recommends you access these interfaces using kubectl port forwarding, which creates an encrypted tunnel from your client machine to the cluster to access a specific service in the cluster.\nOpen a tunnel to the Spring Admin server using this command:\nkubectl -n admin-server port-forward svc/admin-server 8989Open a web browser to http://localhost:8989 to view the Spring Admin web user interface.\nClick on the Wallboard link in the top menu to view the “wallboard” which shows all the discovered services. Spring Admin discovers services from the Spring Eureka Service Registry.\nEach hexagon represents a service. Notice that this display gives you a quick overview of the health of your system. Green services are healthy, grey services have reduced availability and red services are not healthy. You can also see information about how many instances (i.e. pods) are available for each service.\nView information about a service\nClick on the Customer service. You will see a detail page like this:\nOn this page, you can see detailed information about service’s health, and you can scroll down to see information about resource usage. The menu on the left hand side lets you view additional information about the service including its environment variables, the Spring beans loaded, its Spring configuration properties and so on. You can also access metrics from this interface.\nView endpoints\nClick on the Mappings link on the left hand side menu. This page shows you information about the URL Path mappings (or endpoints) exposed by this service. You will notice several endpoints exposed by Spring Actuator, which enables this management and monitoring to be possible. And you will see your service’s own endpoints, in this example the ones that start with /api/v1/...:",
    "description": "Oracle Backend for Spring Boot and Microservices includes Spring Admin which provides a web user interface for managing and monitoring Spring applications.\nConnect to Spring Admin\nOracle Backend for Spring Boot and Microservices does not expose management interfaces outside the Kubernetes cluster for improved security. Oracle recommends you access these interfaces using kubectl port forwarding, which creates an encrypted tunnel from your client machine to the cluster to access a specific service in the cluster.",
    "tags": [],
    "title": "Explore Spring Admin",
    "uri": "/microservices-datadriven/cloudbank/backend/admin/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": " Implement the first simple endpoint\nCreate AccountController.java Create a new directory in the directory src/main/java/com/example/accounts called controller. In that new directory, create a new Java file called AccountController.java. When prompted for the type, choose class.\nYour new file should look like this:\npackage com.example.accounts.controller; public class AccountController { } Add the RestController annotation Add the RestController annotation to this class to tell Spring Boot that we want this class to expose REST services. You can just start typing @RestController before the public class statement and Visual Studio Code will offer code completion for you. When you select from the pop-up, Visual Studio Code will also add the import statement for you. The list of suggestions is based on the dependencies you added to your project.\nAdd the RequestMapping annotation to this class as well, and set the URL path to /api/v1. Your class should now look like this:\npackage com.example.accounts.controller; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/api/v1\") public class AccountController { } Add ping method Add a method to this class called ping which returns a String with a helpful message. Add the GetMapping annotation to this method and set the URL path to /hello. Your class should now look like this:\npackage com.example.accounts.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/api/v1\") public class AccountController { @GetMapping(\"/hello\") public String ping() { return \"Hello from Spring Boot\"; } }You have just implemented your first REST service in Spring Boot! This service will be available on http://localhost:8080/api/v1/hello. And the GetMapping annotation tells Spring Boot that this service will respond to the HTTP GET method.\nYou can test your service now by building and running again. Make sure you save the file. If you still have the application running from before, hit Ctrl+C (or equivalent) to stop it, and then build and run with this command:\n$ mvn spring-boot:runThen try to call your service with this command:\n$ curl -i http://localhost:8080/api/v1/hello HTTP/1.1 200 Content-Type: text/plain;charset=UTF-8 Content-Length: 22 Date: Sat, 25 Feb 2023 17:59:52 GMT Hello from Spring BootGreat, it works! Notice it returned HTTP Status Code 200 (OK) and some HTTP Headers along with the body which contained your message. Later we will see how to return JSON and to set the status code appropriately.",
    "description": "Implement the first simple endpoint\nCreate AccountController.java Create a new directory in the directory src/main/java/com/example/accounts called controller. In that new directory, create a new Java file called AccountController.java. When prompted for the type, choose class.\nYour new file should look like this:\npackage com.example.accounts.controller; public class AccountController { } Add the RestController annotation Add the RestController annotation to this class to tell Spring Boot that we want this class to expose REST services.",
    "tags": [],
    "title": "Implement First Service",
    "uri": "/microservices-datadriven/cloudbank/account/first-service/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Provision an Instance",
    "content": "The Oracle Backend for Spring Boot and Microservices can be installed from OCI Marketplace.\nNote: You only need to choose one of the three deployment options - local, OCI Free Tier or OCI Marketplace.\nThis option installs a “production-sized” environment which includes an Oracle Compute Engine for Kubernetes (“OKE”) cluster and an Oracle Autonomous Database instance. If you want to use a smaller, development/test-sized environment that only requires a single OCI Compute Instance, please use the “Free Tier” option instead.\nAccess the Oracle Cloud Infrastructure Marketplace listing\nOpen the OCI Marketplace listing, as shown in the image below:\nClick on the Get App button.\nLog into your Oracle Cloud Infrastructure account\nYou will be taken to a Sign-In page. Choose they type of account you have and click on the Sign In button. If you did not create an account in the Get Started lab, you can do so now using the Sign Up button.\nSign in to your account as you normally do, using Single Sign-On or Direct Sign-In.\nChoose the region and compartment\nIn the next screen you can choose the region using the pull down in the top right hand corner, and then choose the compartment you want to install into.\nReview the terms and restrictions, and then click on the checkbox to accept them. Then, click on Launch Stack,\nNote: This version of CloudBank is tested with version 1.3.0. Earlier versions may not contain all features used and you may see errors.\nReview the Create Stack page\nReview the details on the Create Stack page. You may wish to update the Name or add tags. When you are ready, click on Next.\nIn the Backend as A Service Section, fill in the following configuration variables as needed and select Next:\nCompartment : Select the compartment where you want to install Oracle Backend for Spring Boot and Microservices. Application Name (optional) : A random pet name that will be used as the application name if left empty. Edition : Select COMMUNITY Edition. Standard edition will give more options for the installation but those are not required or used in this LiveLab. Existing Authorization Token : Leave blank. If you check the checkbox Set Administrator Passwords in the Administrator Passwords section you have the option to fill in the following passwords (if not they are autogenerated):\nAPISIX Administrator Password (optional) : Leave blank to auto-generate. Grafana Administrator Password (optional) : Leave blank to auto-generate. ORACTL Administrator Password (optional) : Leave blank to auto-generate. This is the password for the obaas-admin user. ORACTL User Password (optional) : Leave blank to auto-generate. This is the password for the obaas-user user. In the Kubernetes Cluster Options. fill in the following for the OKE Clusters Options:\nPublic API Endpoint? : For the Live Lba you must check the checkbox Public API Endpoint API Endpoint Access Control : Enter the CIDR block you want to give access to the Control Plane API. Leave the default value 0.0.0.0/0. Node Pool Workers : The number of Kubernetes worker nodes (virtual machines) attached to the OKE cluster. Leave the default value of 3. Node Pool Worker Shape : The shape of the node pool workers. Leave the default Shape value. Node Workers OCPU : The initial number of Oracle Compute Units (OCPUs) for the node pool workers. Leave the default value of 2. NOTE: Oracle recommends that you set Control Plane Access Control to be as restrictive as possible\nIn the Load Balancers Options section, leave the default values.\nEnable Public Load Balancer : This option allows access to the load balancer from the internet (public IP). If not selected, access can only be from a private VCN. Public Load Balancer Access Control : Enter the CIDR block you want to give access to the Load Balancer. Default (and not recommended) is 0.0.0.0/0. Public Load Balancer Ports Exposed : The ports exposed from the load balancer. Minimum bandwidth : The minimum bandwidth that the load balancer can achieve. Maximum bandwidth : The maximum bandwidth that the load balancer can achieve. NOTE: Oracle recommends that you set Public Load Balancer Access Control to be as restrictive as possible.\nIn the Database Options section, leave the default values.\nAutonomous Database Compute Model : Choose either ECPU (default) or OCPU compute model for the ADB. Leave the default value of ECPU Autonomous Database Network Access : Choose the Autonomous Database network access. Leave the default value of SECURE_ACCESS ADB Access Control : Comma separated list of CIDR blocks from which the ADB can be accessed. This only applies if SECURE_ACCESS was chosen. Leave default value of 0.0.0.0/0. Autonomous Database ECPU Core Count : Choose how many ECPU cores will be elastically allocated. Leave default value of 2. Allow Autonomous Database OCPU Auto Scaling : Enable auto-scaling for the ADB ECPU core count (x3 ADB ECPU). Leave the default value of un-checked. Autonomous Database Data Storage Size : Choose ADB Database Data Storage Size in gigabytes. Leave the default value of 20GB. Autonomous Database License Model : The Autonomous Database license model. Leave the default value of LICENSE_INCLUDED. Create an Object Storage Bucket for ADB? : Leave the default value of un-checked. NOTE: Oracle recommends that you restrict by IP or CIDR addresses to be as restrictive as possible.\nClick Next to review your choices.\nComplete the Review page\nReview the details on the Review page. Check the box next to Run Apply. When you are ready, click on Create.\nReview the apply screen\nThe stack will now be applied. On the Apply screen (see below) you can monitor the progress of the installation in the Logs box. The installation should take about 30 minutes to complete. This includes the time needed to create your Oracle Autonomous Database instance, your Oracle Container Engine for Kubernetes cluster and install the various components of the stack into the Kubernetes cluster.\nNote: While you are waiting for the installation to complete is a great time to start setting up your development environment (see the next lab). You can come back here where you are done to check the installation completed successfully.\nVerify the installation Check the logs for errors\nScroll down to the bottom of the log to see the outcome. If there was an error during installation, details will be included at the end of the log. The most common errors are due to insufficient quota for some resource. If you get an error about insufficient quota, you may need to clean up unused resources or request a quota increase for the affected resource. Once you have done that, navigate back to the stack details (for example, using the breadcrumbs) and click on the Apply to try again.\nWhen the installation completes normally, the end of the log should look something like this:\nApply complete! Resources: 77 added, 0 changed, 0 destroyed. Outputs: adb_ip = \"Secured Access\" adb_name = \"KATYDIDDB\" apisix_admin_password = \u003csensitive\u003e grafana_admin_password = \u003csensitive\u003e kubeconfig_cmd = \"oci ce cluster create-kubeconfig --cluster-id ocid1.cluster.oc1... --region us-ashburn-1 --token-version 2.0.0 --kube-endpoint PUBLIC_ENDPOINT --file $HOME/.kube/config\" oractl_admin_password = \u003csensitive\u003e oractl_user_password = \u003csensitive\u003eTo get the sensitive information you need to click on the Application Information tab, and click on unlock or show to display the values:\nNote: Keep a copy of the values, you will need these in later labs.\nVerify you can access the Kubernetes cluster\nIn later labs, you will look at various resources in Kubernetes. You will need a Kubernetes configuration file to access the cluster. For now, accessing the cluster from OCI Cloud Shell will be sufficient to verify the installation.\nOpen the OCI Cloud Shell by clicking on the icon next to the region in the top right corner of the console and then clicking on Cloud Shell.\nRun the command provided at the end of your installation log or the information from the Application Information tab,to obtain the Kubernetes configuration file. The command will be similar to this:\noci ce cluster create-kubeconfig --cluster-id ocid1.cluster.oc1.i..... --region us-ashburn-1 --token-version 2.0.0 --kube-endpoint PUBLIC_ENDPOINT --file $HOME/.kube/configCheck that you can access the cluster using this command:\n$ kubectl get pods -n obaas-admin NAME READY STATUS RESTARTS AGE graalvm-compiler-79988b886c-hgw68 1/1 Running 0 10m obaas-admin-66599b65-vb662 1/1 Running 0 10m soc-ui-5dbd6f9cb4-kjdj8 0/1 Running 0 10mYour output will be slightly different, but you should see one pod listed in the output. This is enough to confirm that you have correctly configured access to the Kubernetes cluster.\nVerify you can connect to the APISIX API Gateway\nYou will need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n$ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 EXTERNAL-IP 80:30389/TCP,443:30458/TCP 13dNow use this command (with your IP address in the column EXTERNAL-IP) to make a request to the API Gateway. You should receive a response with an HTTP Status Code 404 (Not Found) and an error message in JSON format as shown below. Don’t worry about the 404, you will deploy some services soon, but this test is enough to know the API Gateway started up successfully:\n$ curl -i http://\u003cEXTERNAL-IP\u003e\u003e HTTP/1.1 404 Date: Wed, 01 Mar 2023 19:21:08 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive Vary: Origin Vary: Access-Control-Request-Method Vary: Access-Control-Request-Headers {\"timestamp\":\"2023-03-01T19:21:08.031+00:00\",\"status\":404,\"error\":\"Not Found\",\"path\":\"/\"} ",
    "description": "The Oracle Backend for Spring Boot and Microservices can be installed from OCI Marketplace.\nNote: You only need to choose one of the three deployment options - local, OCI Free Tier or OCI Marketplace.\nThis option installs a “production-sized” environment which includes an Oracle Compute Engine for Kubernetes (“OKE”) cluster and an Oracle Autonomous Database instance. If you want to use a smaller, development/test-sized environment that only requires a single OCI Compute Instance, please use the “Free Tier” option instead.",
    "tags": [],
    "title": "Install from OCI Marketplace",
    "uri": "/microservices-datadriven/cloudbank/provision/install-mp/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "You can use either Maven or Gradle to build your Spring Boot applications. If you prefer Maven, follow the steps in this task. If you prefer Gradle, skip to the next task instead.\nDownload Maven\nDownload Maven from the Apache Maven website.\nInstall Maven\nDecompress the archive in your chosen location, e.g., your home directory and then add it to your path (the exact version of maven might differ in your environment):\n$ export PATH=$HOME/apache-maven-3.8.6/bin:$PATH Verify installation\nYou can verify it is installed with this command (note that your version may give slightly different output):\n$ mvn -v Apache Maven 3.8.6 (84538c9988a25aec085021c365c560670ad80f63) Maven home: /home/mark/apache-maven-3.8.6 Java version: 21.0.3, vendor: Oracle Corporation, runtime: /home/mark/jdk-21.0.3 Default locale: en, platform encoding: UTF-8 OS name: \"linux\", version: \"5.10.102.1-microsoft-standard-wsl2\", arch: \"amd64\", family: \"unix\" ",
    "description": "You can use either Maven or Gradle to build your Spring Boot applications. If you prefer Maven, follow the steps in this task. If you prefer Gradle, skip to the next task instead.\nDownload Maven\nDownload Maven from the Apache Maven website.\nInstall Maven\nDecompress the archive in your chosen location, e.g., your home directory and then add it to your path (the exact version of maven might differ in your environment):",
    "tags": [],
    "title": "Install Maven",
    "uri": "/microservices-datadriven/cloudbank/devenv/maven/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Cleanup",
    "content": " Note: These steps apply only if you chose the option to install the full stack from OCI Marketplace.\nThe Oracle Backend for Spring Boot and Microservices environment was deployed using ORM and Terraform. The uninstall will use OCI Resource Manager (ORM) to Destroy the stack.\nNavigate to OCI Resource Manager Stacks\nMake sure you choose the Compartment where you installed Oracle Backend for Spring Boot and Microservices. Click on the Stack Name (which will be different from the screenshot)\nAfter picking the stack. Click destroy. NOTE This will stop all resources and remove the Oracle Backend for Spring Boot and Microservices environment. The only way to get it back is to re-deploy the stack\nConfirm that you want to shut down and destroy the resources\nIf the Terraform Destroy job fails, re-run the Destroy job again after a few minutes.\nLeft over resources Even after the Destroy job has finished there will be one resource left in the tenancy/compartment and that is an OCI Vault. The Vault is on PENDING DELETION mode.",
    "description": "Note: These steps apply only if you chose the option to install the full stack from OCI Marketplace.\nThe Oracle Backend for Spring Boot and Microservices environment was deployed using ORM and Terraform. The uninstall will use OCI Resource Manager (ORM) to Destroy the stack.\nNavigate to OCI Resource Manager Stacks\nMake sure you choose the Compartment where you installed Oracle Backend for Spring Boot and Microservices. Click on the Stack Name (which will be different from the screenshot)",
    "tags": [],
    "title": "OCI Marketplace Uninstall",
    "uri": "/microservices-datadriven/cloudbank/cleanup/uninstall-mp/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "You will update the Account service that you built in the previous module to add some new endpoints to perform deposits and withdrawals. These new endpoints will be LRA participants.\nAdd new dependencies to the Maven POM Open the pom.xml in your accounts project and add these new dependency to the list. It will add support for the LRA client libraries.\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.microtx.lra\u003c/groupId\u003e \u003cartifactId\u003emicrotx-lra-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e23.4.2\u003c/version\u003e \u003c/dependency\u003e ``` Update the Spring Boot application configuration file Update your Account service’s Spring Boot configuration file, application.yaml in src/main/resources. Add a new lra section with the URL for the LRA coordinator. The URL shown here is for the Oracle Transaction Manager for Microservices that was installed as part of the Oracle Backend for Spring Boot and Microservices. Note: This URL is from the point of view of a service running it the same Kubernetes cluster.\n```yaml microtx: lra: coordinator-url: ${MP_LRA_COORDINATOR_URL} propagation-active: true headers-propagation-prefix: \"{x-b3-, oracle-tmm-, authorization, refresh-}\" ``` Check the Journal repository and model Create a new Java file called Journal.java in src/main/com/example/accounts/model to define the model for the journal table. There are no new concepts in this class, so here is the code:\n```java package com.example.accounts.model; import jakarta.persistence.Column; import jakarta.persistence.Entity; import jakarta.persistence.GeneratedValue; import jakarta.persistence.GenerationType; import jakarta.persistence.Id; import jakarta.persistence.Table; import lombok.Data; import lombok.NoArgsConstructor; @Entity @Table(name = \"JOURNAL\") @Data @NoArgsConstructor public class Journal { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"JOURNAL_ID\") private long journalId; // type is withdraw or deposit @Column(name = \"JOURNAL_TYPE\") private String journalType; @Column(name = \"ACCOUNT_ID\") private long accountId; @Column(name = \"LRA_ID\") private String lraId; @Column(name = \"LRA_STATE\") private String lraState; @Column(name = \"JOURNAL_AMOUNT\") private long journalAmount; public Journal(String journalType, long accountId, long journalAmount) { this.journalType = journalType; this.accountId = accountId; this.journalAmount = journalAmount; } public Journal(String journalType, long accountId, long journalAmount, String lraId, String lraState) { this.journalType = journalType; this.accountId = accountId; this.lraId = lraId; this.lraState = lraState; this.journalAmount = journalAmount; } } ``` Open the file called JournalRepository.java in src/main/java/com/example/accounts/repository and add one JPA method findJournalByLraIdAndJournalType() to the interface. Here is the code:\n```java package com.example.accounts.repository; import java.util.List; import org.springframework.data.jpa.repository.JpaRepository; import com.example.accounts.model.Journal; public interface JournalRepository extends JpaRepository\u003cJournal, Long\u003e { List\u003cJournal\u003e findJournalByAccountId(long accountId); Journal findJournalByLraIdAndJournalType(String lraId, String journalType); } ``` That completes the JPA configuration.",
    "description": "You will update the Account service that you built in the previous module to add some new endpoints to perform deposits and withdrawals. These new endpoints will be LRA participants.\nAdd new dependencies to the Maven POM Open the pom.xml in your accounts project and add these new dependency to the list. It will add support for the LRA client libraries.\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.microtx.lra\u003c/groupId\u003e \u003cartifactId\u003emicrotx-lra-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e23.4.2\u003c/version\u003e \u003c/dependency\u003e ``` Update the Spring Boot application configuration file Update your Account service’s Spring Boot configuration file, application.",
    "tags": [],
    "title": "Prepare the Account service",
    "uri": "/microservices-datadriven/cloudbank/saga/prepare/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": "To be able to access the CLoudBank services from the public internet we need expose the services via the Apache APISIX gateway. We’re going to do that using scripts.\nGet APISIX Gateway Admin Key\nYou are going to need the Admin Key for the APISIX Gateway to configure the route. It is stored in a k8s ConfigMap. Run the command and make a note of the admin key.\nkubectl -n apisix get configmap apisix -o yamlLook for the key: information in the admin_key section and save it. You’ll be needing it later in this module.\nadmin_key: # admin: can everything for configuration data - name: \"admin\" key: edd1c9f03........... role: admin Create tunnel to APISIX\nkubectl port-forward -n apisix svc/apisix-admin 9180 Create the routes\nIn the root directory run the following command. NOTE, you must add your API-KEY to the command:\n(cd apisix-routes; source ./create-all-routes.sh \u003cYOUR-API-KEY\u003e)The script will create the following routes:\nCloudBank Service URI ACCOUNT /api/v1/account* CREDITSCORE /api/v1/creditscore* CUSTOMER /api/v1/customer* TESTRUNNER /api/v1/testrunner* TRANSFER /transfer* Verify the routes in the APISIX Dashboard\nGet the password for the APISIX dashboard.\nRetrieve the password for the APISIX dashboard using this command:\nkubectl get secret apisix-dashboard -n apisix -o jsonpath='{.data.conf\\.yaml}' | base64 --decode Start the tunnel in a new terminal window using this command.\n$ kubectl -n apisix port-forward svc/apisix-dashboard 7070:80 Forwarding from 127.0.0.1:7070 -\u003e 9000 Forwarding from [::1]:7070 -\u003e 9000Open a web browser to http://localhost:7070 to view the APISIX Dashboard web user interface. It will appear similar to the image below.\nIf prompted to login, login with username admin and the password you got from the k8s secret earlier. Note that Oracle strongly recommends that you change the password, even though this interface is not accessible outside the cluster without a tunnel.\nClick the routes menu item to see the routes you created in step three.\nVerify that you have three routes created",
    "description": "To be able to access the CLoudBank services from the public internet we need expose the services via the Apache APISIX gateway. We’re going to do that using scripts.\nGet APISIX Gateway Admin Key\nYou are going to need the Admin Key for the APISIX Gateway to configure the route. It is stored in a k8s ConfigMap. Run the command and make a note of the admin key.\nkubectl -n apisix get configmap apisix -o yamlLook for the key: information in the admin_key section and save it.",
    "tags": [],
    "title": "Create APISIX routes",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/create-routes/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "The Deposit service will process deposits into bank accounts. In this task, you will create the basic structure for this service and learn about the endpoints required for an LRA participant, what HTTP Methods they process, the annotations used to define them and so on. You will implement the actual business logic in a later task.\nCreate the Deposit service and scaffold methods Create a new directory in src/main/java/com/example/accounts called services and in that directory create a new Java file called DepositService.java. This will be a Spring Boot component where you will implement the deposit operations. Since the LRA library we are using only works with JAX-RS, you will be using JAX-RS annotations in this service, as opposed to the Spring Boot “web” REST annotations that you used in the previous module. You can mix and match these styles in a single Spring Boot microservice application.\nStart by setting up endpoints and methods with the appropriate annotations. You will implement the logic for each of these methods shortly. Here is the class definition and all the imports you will need in this section, plus the logger and a constant DEPOSIT you will use later. Notice that the class has the @RequestScoped annotation which tells Spring to create an instance of this class for each HTTP request (as opposed to for a whole session for example), the Spring Boot @Component annotation which marks this class as a bean that Spring can inject as a dependency when needed, and the @Path annotation to set the URL path for these endpoints.\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_ENDED_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_PARENT_CONTEXT_HEADER; @RestController @RequestMapping(\"/deposit\") @Slf4j public class DepositService { private final static String DEPOSIT = \"DEPOSIT\"; } ``` Create the LRA entry point The first method you need will be the main entry point, the deposit() method. This will have the @POST annotation so that it will respond to the HTTP POST method. And, it has the @LRA annotation.\nIn the @LRA annotation, which marks this as an LRA participant, the value property is set to LRA.Type.MANDATORY which means that this method will refuse to perform any work unless it is part of an LRA. The end property is set to false which means that successful completion of this method does not in and of itself constitute successful completion of the LRA, in other words, this method expects that it will not be the only participant in the LRA.\nThe LRA coordinator will pass the LRA ID to this method (and any other participants) in an HTTP header. Notice that the first argument of the method extracts that header and maps it to lraId. The other two arguments are mapped to HTTP Query parameters which identify the account and amount to deposit. For now, this method will just return a response with the HTTP Status Code set to 200 (OK). You will implement the actual business logic shortly.\n```java /** * Write journal entry re deposit amount. * Do not increase actual bank account amount */ @PostMapping @LRA(value = LRA.Type.MANDATORY, end = false) public ResponseEntity\u003cString\u003e deposit(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestParam(\"accountId\") long accountId, @RequestParam(\"amount\") long depositAmount) { log.info(\"...deposit \" + depositAmount + \" in account:\" + accountId + \" (lraId:\" + lraId + \") finished (in pending state)\"); return null; } ``` Create the LRA complete endpoint Each LRA participant needs a “complete” endpoint. This completeWork method implements that endpoint, as declared by the @Complete annotation. Note that this response to the HTTP PUT method and extracts the lraId from an HTTP header as in the previous method.\n```java /** * Increase balance amount as recorded in journal during deposit call. * Update LRA state to ParticipantStatus.Completed. */ @PutMapping(\"/complete\") @Complete public ResponseEntity\u003cString\u003e completeWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit complete called for LRA : \" + lraId); return null; } ``` Create the LRA compensate endpoint Next, you need a compensation endpoint. This compensateWork method is similar to the previous methods and is marked with the @Compensate annotation to mark it as the compensation handler for this participant. Note that this response to the HTTP PUT method and extracts the lraId from an HTTP header as in the previous method.\n```java /** * Update LRA state to ParticipantStatus.Compensated. */ @PutMapping(\"/compensate\") @Compensate public ResponseEntity\u003cString\u003e compensateWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit compensate called for LRA : \" + lraId); return null; } ``` Create the LRA status endpoint Next, you need to provide a status endpoint. This must respond to the HTTP GET method and extracts the lraId from an HTTP header as in the previous method. You can ignore the error AccountTransferDAO for now, we build that class in the next section.\n```java /** * Return status. */ @GetMapping(value = \"/status\", produces = \"text/plain\") @Status public ResponseEntity\u003cParticipantStatus\u003e status(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestHeader(LRA_HTTP_PARENT_CONTEXT_HEADER) String parentLRA) throws Exception { log.info(\"status called for LRA : \" + lraId); return AccountTransferDAO.instance().status(lraId, DEPOSIT); } ``` Create the “after” LRA endpoint Finally, you need an “after LRA” endpoint that implements any clean up logic that needs to be run after the completion of the LRA. This method is called regardless of the outcome of the LRA and must respond to the HTTP PUT method and is marked with the @AfterLRA annotation. IS THIS TRUE consumes = “text/plain”\n```java /** * Delete journal entry for LRA. */ @PutMapping(value = \"/after\", consumes = \"text/plain\") @AfterLRA public ResponseEntity\u003cString\u003e afterLRA(@RequestHeader(LRA_HTTP_ENDED_CONTEXT_HEADER) String lraId, String status) throws Exception { log.info(\"After LRA Called : \" + lraId); AccountTransferDAO.instance().afterLRA(lraId, status, DEPOSIT); return ResponseEntity.ok(\"\"); } ``` Task 5: Create an Account/Transfer Data Access Object The Data Access Object pattern is considered a best practice, and it allows separation of business logic from the persistence layer. In this task, you will create an Account Data Access Object (DAO) that hides the complexity of the persistence layer logic from the business layer services. Additionally, it establishes methods that can be reused by each business layer service that needs to operate on accounts - in this module there will be two such services - deposit and withdraw.\nCreate the DAO class Create a new Java file called AccountTransferDAO.java in src/main/java/com/example/accounts/services. This class will contain common data access methods that are needed by multiple participants. You will implement this class using the singleton pattern so that there will only be one instance of this class.\nHere is the code to set up the class and implement the singleton pattern:\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import com.example.accounts.repository.AccountRepository; import com.example.accounts.repository.JournalRepository; import com.oracle.microtx.springboot.lra.annotation.ParticipantStatus; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Component; @Component public class AccountTransferDAO { private static AccountTransferDAO singleton; final AccountRepository accountRepository; final JournalRepository journalRepository; /** * Initialize account and journal repository. * @param accountRepository Account Repository * @param journalRepository Journal Repository */ public AccountTransferDAO(AccountRepository accountRepository, JournalRepository journalRepository) { this.accountRepository = accountRepository; this.journalRepository = journalRepository; singleton = this; log.info(\"AccountTransferDAO accountsRepository = \" + accountRepository + \", journalRepository = \" + journalRepository); } public static AccountTransferDAO instance() { return singleton; } } ``` Create a method to get the LRA status as a String Create a getStatusString method which can be used to get a String representation of the LRA participant status.\n```java /** * Get status od LRA participant. * @param status Status code * @return Returns status code */ public static String getStatusString(ParticipantStatus status) { return switch (status) { case Compensated -\u003e \"Compensated\"; case Completed -\u003e \"Completed\"; case FailedToCompensate -\u003e \"Failed to Compensate\"; case FailedToComplete -\u003e \"Failed to Complete\"; case Active -\u003e \"Active\"; case Compensating -\u003e \"Compensating\"; case Completing -\u003e \"Completing\"; default -\u003e \"Unknown\"; }; } ``` Create a method to get the LRA status from a String Create a getStatusFromString method to convert back from the String to the enum.\n```java /** * Get LRA Status from a string. * @param statusString Status * @return Participant Status */ public static ParticipantStatus getStatusFromString(String statusString) { return switch (statusString) { case \"Compensated\" -\u003e ParticipantStatus.Compensated; case \"Completed\" -\u003e ParticipantStatus.Completed; case \"Failed to Compensate\" -\u003e ParticipantStatus.FailedToCompensate; case \"Failed to Complete\" -\u003e ParticipantStatus.FailedToComplete; case \"Active\" -\u003e ParticipantStatus.Active; case \"Compensating\" -\u003e ParticipantStatus.Compensating; case \"Completing\" -\u003e ParticipantStatus.Completing; default -\u003e null; }; } ``` Create a method to save an account Create a method to save an account in the account repository.\n```java public void saveAccount(Account account) { log.info(\"saveAccount account\" + account.getAccountId() + \" account\" + account.getAccountBalance()); accountRepository.save(account); } ``` Create a method to return the correct HTTP Status Code for an LRA status.\n```java /** * Return the correct HTTP Status Code for an LRA status * @param lraId LRA Id * @param journalType Journal Type * @return Participant Status * @throws Exception Exception */ public ResponseEntity\u003cParticipantStatus\u003e status(String lraId, String journalType) throws Exception { Journal journal = getJournalForLRAid(lraId, journalType); if (AccountTransferDAO.getStatusFromString(journal.getLraState()).equals(ParticipantStatus.Compensated)) { return ResponseEntity.ok(ParticipantStatus.Compensated); } else { return ResponseEntity.ok(ParticipantStatus.Completed); } } ``` Create a method to update the LRA status in the journal Create a method to update the LRA status in the journal table during the “after LRA” phase.\n```java /** * Update the LRA status in the journal table during the \"after LRA\" phase. * @param lraId LRA Id * @param status Status * @param journalType Journal Type * @throws Exception Exception */ public void afterLRA(String lraId, String status, String journalType) throws Exception { Journal journal = getJournalForLRAid(lraId, journalType); journal.setLraState(status); journalRepository.save(journal); } ``` Create methods to manage accounts Create a method to get the account for a given account ID.\n```java Account getAccountForAccountId(long accountId) { Account account = accountRepository.findByAccountId(accountId); if (account == null) return null; return account; } ``` Create a method to get the account that is related to a journal entry.\n```java Account getAccountForJournal(Journal journal) throws Exception { Account account = accountRepository.findByAccountId(journal.getAccountId()); if (account == null) throw new Exception(\"Invalid accountName:\" + journal.getAccountId()); return account; } ``` Update AccountRepository.java in src/main/java/com/example/accounts/repositories to add these extra JPA methods. Your updated file should look like this:\n```java package com.example.accounts.repository; import java.util.List; import org.springframework.data.jpa.repository.JpaRepository; import com.example.accounts.model.Account; public interface AccountRepository extends JpaRepository\u003cAccount, Long\u003e { List\u003cAccount\u003e findByAccountCustomerId(String customerId); List\u003cAccount\u003e findAccountsByAccountNameContains (String accountName); Account findByAccountId(long accountId); } ``` Create methods to manage the journal Back in the AccountTransferDAO, create a method to get the journal entry for a given LRA.\n```java Journal getJournalForLRAid(String lraId, String journalType) throws Exception { Journal journal = journalRepository.findJournalByLraIdAndJournalType(lraId, journalType); if (journal == null) { journalRepository.save(new Journal(\"unknown\", -1, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.FailedToComplete))); throw new Exception(\"Journal entry does not exist for lraId:\" + lraId); } return journal; } ``` Create a method to save a journal entry.\n```java public void saveJournal(Journal journal) { journalRepository.save(journal); } ``` This completes the Data Access Object, now you can start implementing the actual business logic for the services.\nTask 6: Implement the deposit service’s business logic The deposit service will be responsible for depositing funds into accounts. It will be an LRA participant, and so it will need to implement the LRA lifecycle actions like complete, compensate, and so on. A significant amount of the logic will be shared with the withdrawal service, so you will also create a separate class for that shared logic, following the Data Access Object pattern, to keep the business layer separate from the persistence layer.\nImplement the business logic for the deposit method. This method should write a journal entry for the deposit, but should not update the account balance. Here is the code for this method:\n```java /** * Write journal entry re deposit amount. * Do not increase actual bank account amount */ @PostMapping @LRA(value = LRA.Type.MANDATORY, end = false) public ResponseEntity\u003cString\u003e deposit(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestParam(\"accountId\") long accountId, @RequestParam(\"amount\") long depositAmount) { log.info(\"...deposit \" + depositAmount + \" in account:\" + accountId + \" (lraId:\" + lraId + \") finished (in pending state)\"); Account account = AccountTransferDAO.instance().getAccountForAccountId(accountId); if (account == null) { log.info(\"deposit failed: account does not exist\"); AccountTransferDAO.instance().saveJournal( new Journal( DEPOSIT, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active) ) ); return ResponseEntity.ok(\"deposit failed: account does not exist\"); } AccountTransferDAO.instance().saveJournal( new Journal( DEPOSIT, accountId, depositAmount, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active) ) ); return ResponseEntity.ok(\"deposit succeeded\"); } ``` Implement the complete method This method should update the LRA status to completing, update the account balance, change the bank transaction (journal entry) status from pending to completed and the set the LRA status too completed. Here is the code for this method:\n```java /** * Increase balance amount as recorded in journal during deposit call. * Update LRA state to ParticipantStatus.Completed. */ @PutMapping(\"/complete\") @Complete public ResponseEntity\u003cString\u003e completeWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit complete called for LRA : \" + lraId); // get the journal and account... Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, DEPOSIT); Account account = AccountTransferDAO.instance().getAccountForJournal(journal); // set this LRA participant's status to completing... journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completing)); // update the account balance and journal entry... account.setAccountBalance(account.getAccountBalance() + journal.getJournalAmount()); AccountTransferDAO.instance().saveAccount(account); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completed)); AccountTransferDAO.instance().saveJournal(journal); // set this LRA participant's status to complete... return ResponseEntity.ok(ParticipantStatus.Completed.name()); } ``` Implement the compensate method This method should update both the deposit record in the journal and the LRA status too compensated. Here is the code for this method:\n```java /** * Update LRA state to ParticipantStatus.Compensated. */ @PutMapping(\"/compensate\") @Compensate public ResponseEntity\u003cString\u003e compensateWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit compensate called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, DEPOSIT); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensated)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Compensated.name()); } ``` Implement the status method This method returns the LRA status. Here is the code for this method:\n```java /** * Return status. */ @GetMapping(value = \"/status\", produces = \"text/plain\") @Status public ResponseEntity\u003cParticipantStatus\u003e status(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestHeader(LRA_HTTP_PARENT_CONTEXT_HEADER) String parentLRA) throws Exception { log.info(\"status called for LRA : \" + lraId); return AccountTransferDAO.instance().status(lraId, DEPOSIT); } ``` Implement the after LRA method This method should perform any steps necessary to finalize or clean up after the LRA. In this case, all you need to do is update the status of the deposit entry in the journal. Here is the code for this method:\n```java /** * Delete journal entry for LRA. */ @PutMapping(value = \"/after\", consumes = \"text/plain\") @AfterLRA public ResponseEntity\u003cString\u003e afterLRA(@RequestHeader(LRA_HTTP_ENDED_CONTEXT_HEADER) String lraId, String status) throws Exception { log.info(\"After LRA Called : \" + lraId); AccountTransferDAO.instance().afterLRA(lraId, status, DEPOSIT); return ResponseEntity.ok(\"\"); } ``` That completes the implementation of the deposit service.\nTask 7: Create the Withdraw service Next, you need to implement the withdraw service, which will be the second participant in the transfer LRA.\nImplement the withdraw service Create a new Java file called WithdrawService.java in src/main/java/com/example/accounts/services. This service is very similar to the deposit service, and no new concepts are introduced here. Here is the code for this service:\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import com.oracle.microtx.springboot.lra.annotation.AfterLRA; import com.oracle.microtx.springboot.lra.annotation.Compensate; import com.oracle.microtx.springboot.lra.annotation.Complete; import com.oracle.microtx.springboot.lra.annotation.LRA; import com.oracle.microtx.springboot.lra.annotation.ParticipantStatus; import com.oracle.microtx.springboot.lra.annotation.Status; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.PutMapping; import org.springframework.web.bind.annotation.RequestHeader; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_ENDED_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_PARENT_CONTEXT_HEADER; @RestController @RequestMapping(\"/withdraw\") @Slf4j public class WithdrawService { public static final String WITHDRAW = \"WITHDRAW\"; /** * Reduce account balance by given amount and write journal entry re the same. * Both actions in same local tx */ @PostMapping @LRA(value = LRA.Type.MANDATORY, end = false) public ResponseEntity\u003cString\u003e withdraw(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestParam(\"accountId\") long accountId, @RequestParam(\"amount\") long withdrawAmount) { log.info(\"withdraw \" + withdrawAmount + \" in account:\" + accountId + \" (lraId:\" + lraId + \")...\"); Account account = AccountTransferDAO.instance().getAccountForAccountId(accountId); if (account == null) { log.info(\"withdraw failed: account does not exist\"); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw failed: account does not exist\"); } if (account.getAccountBalance() \u003c withdrawAmount) { log.info(\"withdraw failed: insufficient funds\"); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw failed: insufficient funds\"); } log.info(\"withdraw current balance:\" + account.getAccountBalance() + \" new balance:\" + (account.getAccountBalance() - withdrawAmount)); account.setAccountBalance(account.getAccountBalance() - withdrawAmount); AccountTransferDAO.instance().saveAccount(account); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, withdrawAmount, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw succeeded\"); } /** * Update LRA state. Do nothing else. */ @PutMapping(\"/complete\") @Complete public ResponseEntity\u003cString\u003e completeWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"withdraw complete called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, WITHDRAW); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completed)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Completed.name()); } /** * Read the journal and increase the balance by the previous withdraw amount. * before the LRA */ @PutMapping(\"/compensate\") @Compensate public ResponseEntity\u003cString\u003e compensateWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"Account withdraw compensate() called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, WITHDRAW); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensating)); Account account = AccountTransferDAO.instance().getAccountForAccountId(journal.getAccountId()); if (account != null) { account.setAccountBalance(account.getAccountBalance() + journal.getJournalAmount()); AccountTransferDAO.instance().saveAccount(account); } journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensated)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Compensated.name()); } @Status public ResponseEntity\u003cParticipantStatus\u003e status(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestHeader(LRA_HTTP_PARENT_CONTEXT_HEADER) String parentLRA) throws Exception { return AccountTransferDAO.instance().status(lraId, WITHDRAW); } /** * Delete journal entry for LRA. */ @PutMapping(value = \"/after\", consumes = \"text/plain\") @AfterLRA public ResponseEntity\u003cString\u003e afterLRA(@RequestHeader(LRA_HTTP_ENDED_CONTEXT_HEADER) String lraId, String status) throws Exception { log.info(\"After LRA Called : \" + lraId); AccountTransferDAO.instance().afterLRA(lraId, status, WITHDRAW); return ResponseEntity.ok(\"\"); } } ``` That completes the implementation of the deposit service, and with that you are also done with the modifications for the Account Spring Boot microservice application to allow it to participate int he LRA. Next, you will create the Transfer Spring Boot microservice application.\nTask 8: Create the Transfer Service Now, you will create another new Spring Boot microservice application and implement the Transfer Service. This service will initiate the LRA and act as the logical coordinator - it will call the deposit and withdraw services you just implemented to effect the transfer to process the Cloud Cash Payment.\nCreate a new Java Project for the transfer service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.\nSelect Spring Boot Project.\nSelect Maven Project.\nSpecify 3.3.1 as the Spring Boot version.\nUse com.example as the Group Id.\nEnter transfer as the Artifact Id.\nUse JAR as the Packaging Type.\nSelect Java version 21.\nSearch for Spring Web and press Enter\nPress Enter to continue and create the Java Project\nSelect the root location for your project e.g. side by side with the checks, testrunner and accounts projects.\nWhen the project opens click Add to Workspace\nAdd MicroTX and Lombok to the pom.xml file Open the pom.xml file in the transfer project. Add the following to the pom.xml:\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.microtx.lra\u003c/groupId\u003e \u003cartifactId\u003emicrotx-lra-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e23.4.2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e ``` Create the Spring Boot application configuration In the transfer project, rename the file called application.properties to application.yaml located in the src/main/resources. This will be the Spring Boot application configuration file. In this file you need to configure the endpoints for the LRA participants and coordinator.\n```yaml spring: application: name: transfer mvc: enforced-prefixes: - /actuator - /rest url-mappings: - \"/rest/*\" - \"/actuator/*\" - \"/error/*\" microtx: lra: coordinator-url: ${MP_LRA_COORDINATOR_URL} propagation-active: true headers-propagation-prefix: \"{x-b3-, oracle-tmm-, authorization, refresh-}\" account: deposit: url: http://account.application:8080/deposit withdraw: url: http://account.application:8080/withdraw transfer: cancel: url: http://transfer.application:8080/cancel process: url: http://transfer.application:8080/processcancel confirm: url: http://transfer.application:8080/confirm process: url: http://transfer.application:8080/processconfirm ``` Create the Transfer service You are now ready to implement the main logic for the Cloud Cash Payment/transfer LRA. You will implement this in a new Java file called TransferService.java in src/main/java/com/example/transfer. Here are the imports you will need for this class and the member variables. Note that this class has the @RestController and @RequestMapping annotations, as you saw previously in the Account project, to set up the URL context root for the service.\n```java package com.example.transfer; import java.net.URI; import com.oracle.microtx.springboot.lra.annotation.Compensate; import com.oracle.microtx.springboot.lra.annotation.Complete; import com.oracle.microtx.springboot.lra.annotation.LRA; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Value; import org.springframework.http.HttpEntity; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestHeader; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import org.springframework.web.util.UriComponentsBuilder; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_CONTEXT_HEADER; @RestController @RequestMapping(\"/\") @Slf4j public class TransferService { public static final String TRANSFER_ID = \"TRANSFER_ID\"; @Value(\"${account.withdraw.url}\") URI withdrawUri; @Value(\"${account.deposit.url}\") URI depositUri; @Value(\"${transfer.cancel.url}\") URI transferCancelUri; @Value(\"${transfer.cancel.process.url}\") URI transferProcessCancelUri; @Value(\"${transfer.confirm.url}\") URI transferConfirmUri; @Value(\"${transfer.confirm.process.url}\") URI transferProcessConfirmUri; } ``` Create the transfer endpoint This is the main entry point for the LRA. When a client calls this method, a new LRA will be started. The @LRA annotation with the value property set to LRA.Type.REQUIRES_NEW instructs the interceptors/filters to contact Oracle Transaction Manager for Microservices to start a new LRA instance and obtain the LRA ID, which will be injected into the LRA_HTTP_CONTEXT_HEADER HTTP header. Note that the end property is set to false which means there will be other actions and participants before the LRA is completed.\nThis method will accept three parameters from the caller, in JSON format in the HTTP body: fromAccount is the account from which the funds are to be withdrawn, toAccount is the account into which the funds are to be deposited, and amount is the amount to transfer.\nIn the method body, you should first check if the lraId was set. If it is null, that indicates that there was some error trying to create the new LRA instance, and you should return an error response and stop.\nAfter that, you want to perform the withdrawal, check if it worked, and if so, perform the deposit, and then check if that worked, and if so “complete” the LRA. If there were any failures, compensate the LRA.\n```java /** * Transfer amount between two accounts. * @param fromAccount From an account * @param toAccount To an account * @param amount Amount to transfer * @param lraId LRA Id * @return TO-DO */ @PostMapping(\"/transfer\") @LRA(value = LRA.Type.REQUIRES_NEW, end = false) public ResponseEntity\u003cString\u003e transfer(@RequestParam(\"fromAccount\") long fromAccount, @RequestParam(\"toAccount\") long toAccount, @RequestParam(\"amount\") long amount, @RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { if (lraId == null) { return new ResponseEntity\u003c\u003e(\"Failed to create LRA\", HttpStatus.INTERNAL_SERVER_ERROR); } log.info(\"Started new LRA/transfer Id: \" + lraId); boolean isCompensate = false; String returnString = \"\"; // perform the withdrawal returnString += withdraw(lraId, fromAccount, amount); log.info(returnString); if (returnString.contains(\"succeeded\")) { // if it worked, perform the deposit returnString += \" \" + deposit(lraId, toAccount, amount); log.info(returnString); if (returnString.contains(\"failed\")) { isCompensate = true; // deposit failed } } else { isCompensate = true; // withdraw failed } log.info(\"LRA/transfer action will be \" + (isCompensate ? \"cancel\" : \"confirm\")); // call complete or cancel based on outcome of previous actions RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(TRANSFER_ID, lraId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( (isCompensate ? transferCancelUri : transferConfirmUri).toString(), request, String.class); returnString += response.getBody(); // return status return ResponseEntity.ok(\"transfer status:\" + returnString); } ``` Create a method to perform the withdrawal This method should perform the withdrawal by calling the Withdraw service in the Account Spring Boot application. The lraId, accountId and amount need to be passed to the service, and you must set the LRA_HTTP_CONTEXT_HEADER to the LRA ID.\n```java private String withdraw(String lraId, long accountId, long amount) { log.info(\"withdraw accountId = \" + accountId + \", amount = \" + amount); log.info(\"withdraw lraId = \" + lraId); UriComponentsBuilder builder = UriComponentsBuilder.fromUri(withdrawUri) .queryParam(\"accountId\", accountId) .queryParam(\"amount\", amount); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, lraId.toString()); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( builder.buildAndExpand().toUri(), request, String.class); return response.getBody(); } ``` Create a method to perform the deposit This method is similar the previous one, no new concepts are introduced here.\n```java private String deposit(String lraId, long accountId, long amount) { log.info(\"deposit accountId = \" + accountId + \", amount = \" + amount); log.info(\"deposit lraId = \" + lraId); UriComponentsBuilder builder = UriComponentsBuilder.fromUri(depositUri) .queryParam(\"accountId\", accountId) .queryParam(\"amount\", amount); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, lraId.toString()); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( builder.buildAndExpand().toUri(), request, String.class); return response.getBody(); } ``` Create a method to process the confirm action for this participant This participant does not need to take any actions for the confirm action, so just return a successful response.\n```java @PostMapping(\"/processconfirm\") @LRA(value = LRA.Type.MANDATORY) public ResponseEntity\u003cString\u003e processconfirm(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { log.info(\"Process confirm for transfer : \" + lraId); return ResponseEntity.ok(\"\"); } ``` Create a method to process the cancel action for this participant This participant does not need to take any actions for the cancel action, so just return a successful response.\n```java @PostMapping(\"/processcancel\") @LRA(value = LRA.Type.MANDATORY, cancelOn = HttpStatus.OK) public ResponseEntity\u003cString\u003e processcancel(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { log.info(\"Process cancel for transfer : \" + lraId); return ResponseEntity.ok(\"\"); } ``` Create the confirm and cancel methods The logic demonstrated in these two methods would probably be in a client in a real-life LRA, but is included here for instructional purposes and convenience.\nThe transfer method makes a REST call to confirm (or cancel) at the end of its processing. The confirm or cancel method suspends the LRA (using the NOT_SUPPORTED value in the @LRA annotation). Then the confirm or cancel method will make a REST call to processconfirm or processcancel which import the LRA with their MANDATORY annotation and then implicitly end the LRA accordingly upon returning.\n```java /** * Confirm a transfer. * @param transferId Transfer Id * @return TO-DO */ @PostMapping(\"/confirm\") @Complete @LRA(value = LRA.Type.NOT_SUPPORTED) public ResponseEntity\u003cString\u003e confirm(@RequestHeader(TRANSFER_ID) String transferId) { log.info(\"Received confirm for transfer : \" + transferId); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, transferId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( transferProcessConfirmUri, request, String.class); return ResponseEntity.ok(response.getBody()); } /** * Cancel a transfer. * @param transferId Transfer Id * @return TO-DO */ @PostMapping(\"/cancel\") @Compensate @LRA(value = LRA.Type.NOT_SUPPORTED, cancelOn = HttpStatus.OK) public ResponseEntity\u003cString\u003e cancel(@RequestHeader(TRANSFER_ID) String transferId) { log.info(\"Received cancel for transfer : \" + transferId); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, transferId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( transferProcessCancelUri, request, String.class); return ResponseEntity.ok(response.getBody()); } ``` That completes the Transfer service and application.\nTask 9: Deploy the Account and Transfer services to the backend The services are now completed, and you are ready to deploy them to the Oracle Backend for Spring Boot and Microservices.\nNote: You already created the Kubernetes secrets necessary for the account service to access the Oracle Autonomous Database in a previous module, and the transfer service does not need access to the database. You also created the journal table that is needed by the update account application in the previous module.\nBuild the Account and Transfer applications into JAR files To build a JAR file from the Account application, issue this command in the account directory. Then issue the same command from the transfer directory to build the Transfer application into a JAR file too.\n```shell $ mvn clean package -DskipTests ``` You will now have a JAR file for each application, as can be seen with this command (the command needs to be executed in the parent directory for the Account and Transfer applications):\n```shell $ find . -name \\*SNAPSHOT.jar ./testrunner/target/testrunner-0.0.1-SNAPSHOT.jar ./checks/target/checks-0.0.1-SNAPSHOT.jar ./transfer/target/transfer-0.0.1-SNAPSHOT.jar ./accounts/target/accounts-0.0.1-SNAPSHOT.jar ``` Deploy the Account and Transfer applications You will now deploy your updated account application and new transfer application to the Oracle Backend for Spring Boot and Microservices using the CLI. You will deploy into the application namespace, and the service names will be account and transfer respectively.\nThe Oracle Backend for Spring Boot and Microservices admin service is not exposed outside of the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command:\n```shell $ kubectl -n obaas-admin port-forward svc/obaas-admin 8080:8080 ``` Start the Oracle Backend for Spring Boot and Microservices CLI (oractl) in the parent directory using this command:\n```shell $ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e ``` Obtain the obaas-admin password by executing this command:\n```shell kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d ``` Connect to the Oracle Backend for Spring Boot and Microservices admin service using this command. Use obaas-admin as the username and the password you obtained in the previous step.\n```shell oractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e ``` Run this command to deploy your account service, make sure you provide the correct path to your JAR files.\n```shell oractl:\u003e deploy --app-name application --service-name account --artifact-path /path/to/accounts-0.0.1-SNAPSHOT.jar --image-version 0.0.1 --liquibase-db admin uploading: account/target/accounts-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` Run this command to deploy the transfer service, make sure you provide the correct path to your JAR files.\n```shell oractl:\u003e deploy --app-name application --service-name transfer --artifact-path /path/to/transfer-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: transfer/target/transfer-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` Your applications are now deployed in the backend.\nTask 10: Run LRA test cases Now you can test your LRA to verify it performs correctly under various circumstances.\nStart a tunnel to access the transfer service Since the transfer service is not exposed outside the Kubernetes cluster, you will need to start a kubectl port forwarding tunnel to access its endpoints.\n\u003e **Note**: If you prefer, you can create a route in the APISIX API Gateway to expose the service. The service will normally only be invoked from within the cluster, so you did not create a route for it. However, you have learned how to create routes, so you may do that if you prefer. Run this command to start the tunnel: ```shell $ kubectl -n application port-forward svc/transfer 7000:8080 ``` Now the transfer service will be accessible at http://localhost:7000/api/v1/transfer.\nCheck the starting account balances In several of the next few commands, you need to provide the correct IP address for the API Gateway in your backend environment. Not the ones that use localhost, just those where the example uses 100.20.30.40 as the address. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n```shell $ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13d ``` Before you start, check the balances of the two accounts that you will be transferring money between using this command (make sure you are using the EXTERNAL-IP of your environment). Note that these accounts were created in an earlier step.\n```shell $ curl -s http://100.20.30.40/api/v1/account/1 | jq ; curl -s http://100.20.30.40/api/v1/account/2 | jq { \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"abcDe7ged\", \"accountOpenedDate\": \"2023-03-06T13:56:43.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": -20 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-03-06T13:56:44.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 } ``` Note that account 1 has -$20 in this example, and account 2 has $1,000. Your results may be different.\nPerform a transfer that should succeed Run this command to perform a transfer that should succeed. Note that both accounts exist and the amount of the transfer is less than the balance of the source account.\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=1\u0026amount=100\" transfer status:withdraw succeeded deposit succeeded ``` Check the two accounts again to confirm the transfer behaved as expected:\n```shell $ curl -s http://100.20.30.40/api/v1/account/1 | jq ; curl -s http://100.20.30.40/api/v1/account/2 | jq { \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"abcDe7ged\", \"accountOpenedDate\": \"2023-03-06T13:56:43.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": 80 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-03-06T13:56:44.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 900 } ``` Notice that account 2 now has only $900 and account 1 has $80. So the $100 was successfully transferred as expected.\nPerform a transfer that should fail due to insufficient funds in the source account Run this command to attempt to transfer $100,000 from account 2 to account 1. This should fail because account 2 does not have enough funds.\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=1\u0026amount=100000\" transfer status:withdraw failed: insufficient funds ``` Perform a transfer that should fail due to the destination account not existing. Execute the following command to perform a failed transfer:\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=6799999\u0026amount=100\" transfer status:withdraw succeeded deposit failed: account does not exist% ``` Access the applications logs to verify what happened in each case Access the Transfer application log with this command. Your output will be different:\n```shell $ kubectl -n application logs svc/transfer 2023-03-04 21:52:12.421 INFO 1 --- [nio-8080-exec-3] TransferService : Started new LRA/transfer Id: http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.422 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw accountId = 2, amount = 100 2023-03-04 21:52:12.426 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw lraId = http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.615 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw succeeded 2023-03-04 21:52:12.616 INFO 1 --- [nio-8080-exec-3] TransferService : deposit accountId = 6799999, amount = 100 2023-03-04 21:52:12.619 INFO 1 --- [nio-8080-exec-3] TransferService : deposit lraId = http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.726 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw succeeded deposit failed: account does not exist 2023-03-04 21:52:12.726 INFO 1 --- [nio-8080-exec-3] TransferService : LRA/transfer action will be cancel 2023-03-04 21:52:12.757 INFO 1 --- [nio-8080-exec-1] TransferService : Received cancel for transfer : http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.817 INFO 1 --- [nio-8080-exec-2] TransferService : Process cancel for transfer : http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 ``` In the example output above you can see one what happened during that last test you ran a moment ago. Notice that the LRA started, the withdrawal succeeded, then the deposit failed because the account did not exist. Then you can see that the next action is cancel, and then the LRA being canceled/compensated.\nIn this module you have learned about the Saga pattern by implementing an account transfer scenarios. You did this by implementing the long running activity, including transfer and account services that connect to a coordinator, according to the Long Running Action specification.\nLearn More Oracle Backend for Spring Boot and Microservices Oracle Transaction Manager for Microservices Saga pattern Long Running Action Acknowledgements Author - Paul Parkinson, Mark Nelson, Andy Tael, Developer Evangelists, Oracle Database Contributors - Last Updated By/Date - Andy Tael, July 2024 ",
    "description": "The Deposit service will process deposits into bank accounts. In this task, you will create the basic structure for this service and learn about the endpoints required for an LRA participant, what HTTP Methods they process, the annotations used to define them and so on. You will implement the actual business logic in a later task.\nCreate the Deposit service and scaffold methods Create a new directory in src/main/java/com/example/accounts called services and in that directory create a new Java file called DepositService.",
    "tags": [],
    "title": "Create the Deposit service",
    "uri": "/microservices-datadriven/cloudbank/saga/deposit/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "Next, you will create the “Test Runner” microservice which you will use to simulate the ATM and Back Office. This service will send messages to the queues that you just created.\nCreate a new Java Project for the transfer service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.\nSelect Spring Boot Project.\nSelect Maven Project.\nSpecify 3.3.1 as the Spring Boot version.\nUse com.example as the Group Id.\nEnter testrunner as the Artifact Id.\nUse JAR as the Packaging Type.\nSelect Java version 21.\nSearch for Spring Web and press Enter\nPress Enter to continue and create the Java Project\nSelect the root location for your project e.g. side by side with the account project.\nWhen the project opens click Add to Workspace\nModify the pom.xml file Open the pom.xml file in the testrunner project. This service will use the “Web” Spring Boot Starter which will allow it to expose REST endpoints and make REST calls to other services. It also uses the two Oracle Spring Boot Starters for UCP and Wallet to access the database: Add the following to the pom.xml:\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-aqjms\u003c/artifactId\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-wallet\u003c/artifactId\u003e \u003ctype\u003epom\u003c/type\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e ``` Create the Spring Boot application YAML file In the testrunner project, rename the file called application.properties to application.yaml located in the src/main/resources. This will be the Spring Boot application configuration file:\n```yaml spring: application: name: testrunner datasource: url: ${spring.datasource.url} username: ${spring.datasource.username} password: ${spring.datasource.password} ``` This is the Spring Boot application YAML file, which contains the configuration information for this service. In this case, you only need to provide the application name and the connection details for the database hosting the queues.\nCreate the main Spring Application class In the testrunner directory, open the Java file called TestrunnerApplication.java and add this content. This is a standard Spring Boot main class, notice the @SpringBootApplication annotation on the class. It also has the @EnableJms annotation which tells Spring Boot to enable JMS functionality in this application. The main method is a normal Spring Boot main method:\n```java package com.example.testrunner; import jakarta.jms.ConnectionFactory; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.jms.annotation.EnableJms; import org.springframework.jms.core.JmsTemplate; import org.springframework.jms.support.converter.MappingJackson2MessageConverter; import org.springframework.jms.support.converter.MessageConverter; import org.springframework.jms.support.converter.MessageType; @SpringBootApplication @EnableJms public class TestrunnerApplication { public static void main(String[] args) { SpringApplication.run(TestrunnerApplication.class, args); } // Serialize message content to json using TextMessage @Bean public MessageConverter jacksonJmsMessageConverter() { MappingJackson2MessageConverter converter = new MappingJackson2MessageConverter(); converter.setTargetType(MessageType.TEXT); converter.setTypeIdPropertyName(\"_type\"); return converter; } @Bean public JmsTemplate jmsTemplate(ConnectionFactory connectionFactory) { JmsTemplate jmsTemplate = new JmsTemplate(); jmsTemplate.setConnectionFactory(connectionFactory); jmsTemplate.setMessageConverter(jacksonJmsMessageConverter()); return jmsTemplate; } } ``` In addition to the standard parts of a Spring Boot application class, you will add two beans that will be needed in this service. First, you need a MessageConverter bean so that you can convert a Java object (POJO) into JSON format, and vice versa. This bean will be used to serialize and deserialize the objects you need to write onto the queues.\nThe second bean you need is a JmsTemplate. This is a standard Spring JMS bean that is used to access JMS functionality. You will use this bean to enqueue messages. Notice that this bean is configured to use the MessageConverter bean and that the JMS ConnectionFactory is injected. The Oracle Spring Boot Starter for AQ/JMS will create the JMS ConnectionFactory for you.\nNote: The Oracle Spring Boot Starter for AQ/JMS will also inject a JDBC Connection bean which shares the same database transaction with the JMS ConnectionFactory. This is not needed in this lab. The shared transaction enables you to write methods which can perform both JMS and JPA operations in an atomic transaction, which can be very helpful in some use cases and can dramatically reduce the amount of code needed to handle situations like duplicate message delivery or lost messages.\nCreate the model classes Create a new directory called src/main/java/com/example/testrunner/model and in this directory create two Java files. First, CheckDeposit.java with this content. This class will be used to simulate the ATM sending the “deposit” notification:\n```java package com.example.testrunner.model; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class CheckDeposit { private long accountId; private long amount; } ``` Next, Clearance.java with this content. This class will be used to simulate the Back Office sending the “clearance” notification:\n```java package com.example.testrunner.model; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class Clearance { private long journalId; } ``` Create the controller Create a new directory called src/main/java/com/example/testrunner/controller and in this directory create a new Java file called TestRunnerController.java with the following content. This class will have the RestController annotation so that it can expose REST APIs that you can call to trigger the simulation of the ATM and Back Office notifications. It will need the JmsTemplate to access JMS functionality, this can be injected with the AutoWired annotation. Create two methods, one to send each notification:\n```java package com.example.testrunner.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.jms.core.JmsTemplate; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import com.example.testrunner.model.CheckDeposit; import com.example.testrunner.model.Clearance; @RestController @RequestMapping(\"/api/v1/testrunner\") public class TestRunnerController { @Autowired private JmsTemplate jmsTemplate; @PostMapping(\"/deposit\") public ResponseEntity\u003cCheckDeposit\u003e depositCheck(@RequestBody CheckDeposit deposit) { jmsTemplate.convertAndSend(\"deposits\", deposit); return new ResponseEntity\u003cCheckDeposit\u003e(deposit, HttpStatus.CREATED); } @PostMapping(\"/clear\") public ResponseEntity\u003cClearance\u003e clearCheck(@RequestBody Clearance clearance) { jmsTemplate.convertAndSend(\"clearances\", clearance); return new ResponseEntity\u003cClearance\u003e(clearance, HttpStatus.CREATED); } } ``` Build a JAR file for deployment Run the following command to build the JAR file.\n```shell $ mvn clean package -DskipTests ``` The service is now ready to deploy to the backend.\nPrepare the backend for deployment The Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command in a new terminal window: ```shell $ kubectl -n obaas-admin port-forward svc/obaas-admin 8080 ``` Get the password for the obaas-admin user. The obaas-admin user is the equivalent of the admin or root user in the Oracle Backend for Spring Boot and Microservices backend.\n```shell $ kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d ``` Start the Oracle Backend for Spring Boot and Microservices CLI (oractl) in a new terminal window using this command:\n```shell $ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e ``` Connect to the Oracle Backend for Spring Boot and Microservices admin service using the `connect` command. Enter `obaas-admin` and the username and use the password you collected earlier. ```shell oractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e ``` Create a binding for the Test Runner service Create a binding so the Test Runner service can access the Oracle Autonomous Database as the account user. Run this command to create the binding, and type in the password for the account user when prompted. The password is Welcome1234##:\n```shell oractl:\u003e bind --app-name application --service-name testrunner --username account ``` Deploy the Test Runner service You will now deploy your Test Runner service to the Oracle Backend for Spring Boot and Microservices using the CLI. Run this command to deploy your service, make sure you provide the correct path to your JAR file. Note that this command may take 1-3 minutes to complete:\n```shell oractl:\u003e deploy --app-name application --service-name testrunner --artifact-path /path/to/testrunner-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: testrunner/target/testrunner-0.0.1-SNAPSHOT.jarbuilding and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` You can close the port forwarding session for the CLI now (just type a Ctrl+C in its console window). Check that the testrunner service is running Verify that the testrunner application is up and running by running this command:\n```shell $ kubectl logs -n application svc/testrunner ``` The output should be similar to this, look for Started TestrunnerApplication\n```text 2023-06-02 15:18:39.620 INFO 1 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1806 ms 2023-06-02 15:18:40.915 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2023-06-02 15:18:40.938 INFO 1 --- [ main] c.e.testrunner.TestrunnerApplication : Started TestrunnerApplication in 4.174 seconds (JVM running for 5.237) ``` Test the endpoints The Test Runner service is not exposed outside your Kubernetes cluster, so you must create a port-forwarding tunnel to access it. Create a tunnel using this command:\n```shell $ kubectl -n application port-forward svc/testrunner 8084:8080 ``` Call the deposit endpoint to send a deposit notification using this command:\n```shell $ curl -i -X POST -H 'Content-Type: application/json' -d '{\"accountId\": 2, \"amount\": 200}' http://localhost:8084/api/v1/testrunner/deposit HTTP/1.1 201 Date: Wed, 31 May 2023 15:11:55 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"accountId\":2,\"amount\":200} ``` Call the clear endpoint to send a clearance notification using this command. Note that you can use any journalId since there is nothing receiving and processing these messages yet:\n```shell $ curl -i -X POST -H 'Content-Type: application/json' -d '{\"journalId\": 4}' http://localhost:8084/api/v1/testrunner/clear HTTP/1.1 201 Date: Wed, 31 May 2023 15:12:54 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"journalId\":4} ``` Verify the expected messages are on the queues Connect to the database as the account (password Welcome12343##) and issue this SQL statement to check the payloads of the messages on the deposits queue:\n```sql SQL\u003e select qt.user_data.text_vc from deposits_qt qt; USER_DATA.TEXT_VC _______________________________ {\"accountId\":2,\"amount\":200} ``` Issue this SQL statement to check the payloads of the messages on the clearances queue:\n```sql SQL\u003e select qt.user_data.text_vc from clearances_qt qt; USER_DATA.TEXT_VC ____________________ {\"journalId\":4} ``` hat completes the Test Runner service. Next, you will build the Check Processing service which will receive these messages and process them.",
    "description": "Next, you will create the “Test Runner” microservice which you will use to simulate the ATM and Back Office. This service will send messages to the queues that you just created.\nCreate a new Java Project for the transfer service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.\nSelect Spring Boot Project.\nSelect Maven Project.\nSpecify 3.",
    "tags": [],
    "title": "Create the Test Runner Microservice",
    "uri": "/microservices-datadriven/cloudbank/check/create-testrunner/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Spring Eureka Service Registry is an application that holds information about what microservices are running in your environment, how many instances of each are running, and on which addresses and ports. Spring Boot microservices register with Eureka at startup, and it regularly checks the health of all registered services. Services can use Eureka to make calls to other services, thereby eliminating the need to hard code service addresses into other services.\nStart a port-forward tunnel to access the Eureka web user interface\nStart the tunnel using this command. You can run this in the background if you prefer.\n$ kubectl -n eureka port-forward svc/eureka 8761:8761Open a web browser to http://localhost:8761 to view the Eureka web user interface. It will appear similar to the image below.\nNotice that you can see your own services like the Accounts, Credit Score and Customer services from the CloudBank sample application, as well as platform services like Spring Admin, the Spring Config server and Conductor.",
    "description": "Spring Eureka Service Registry is an application that holds information about what microservices are running in your environment, how many instances of each are running, and on which addresses and ports. Spring Boot microservices register with Eureka at startup, and it regularly checks the health of all registered services. Services can use Eureka to make calls to other services, thereby eliminating the need to hard code service addresses into other services.",
    "tags": [],
    "title": "Explore Eureka Service Registry",
    "uri": "/microservices-datadriven/cloudbank/backend/eureka/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "The Oracle Backend for Spring Boot CLI (oractl) is used to configure your backend and to deploy your Spring Boot applications to the backend.\nDownload the Oracle Backend for Spring Boot and Microservices CLI\nDownload the CLI from here\nInstall the Oracle Backend for Spring Boot and Microservices CLI\nTo install the CLI, you just need to make sure it is executable and add it to your PATH environment variable.\nchmod +x oractl export PATH=/path/to/oractl:$PATHNOTE: If environment is a Mac you need run the following command sudo xattr -r -d com.apple.quarantine \u003cdownloaded-file\u003e otherwise will you get a security warning and the CLI will not work.\nVerify the installation\nVerify the CLI is installed using this command:\n$ oractl version _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ =================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C06L9CDGR6Z - email: obaas_ww@oracle.com Build Version: 1.2.0 ",
    "description": "The Oracle Backend for Spring Boot CLI (oractl) is used to configure your backend and to deploy your Spring Boot applications to the backend.\nDownload the Oracle Backend for Spring Boot and Microservices CLI\nDownload the CLI from here\nInstall the Oracle Backend for Spring Boot and Microservices CLI\nTo install the CLI, you just need to make sure it is executable and add it to your PATH environment variable.",
    "tags": [],
    "title": "Install CLI",
    "uri": "/microservices-datadriven/cloudbank/devenv/oractl/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module introduces the Saga pattern, a very important pattern that helps us manage data consistency across microservices. We will explore the Long Running Action specification, one implementation of the Saga pattern, and then build a Transfer microservice that will manage funds transfers using a saga.",
    "description": "This module introduces the Saga pattern, a very important pattern that helps us manage data consistency across microservices. We will explore the Long Running Action specification, one implementation of the Saga pattern, and then build a Transfer microservice that will manage funds transfers using a saga.",
    "tags": [],
    "title": "Manage Sagas",
    "uri": "/microservices-datadriven/cloudbank/saga/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": " Get the database user ADMIN password\nThe ADMIN password can be retrieved from a k8s secret using this command. Replace the DBNAME with the name of your database. Save the password as it will be needed in later steps.\n$ kubectl -n application get secret DBNAME-db-secrets -o jsonpath='{.data.db\\.password}' | base64 -dIf you don’t know the name of the database, execute the following command and look for the line DBNAME-db-secrets.\n$ kubectl -n application get secrets Start SQLcl and load the Wallet\nThe Accounts service is going to have two main objects - an account and a journal. Here are the necessary steps to create the objects in the database\nIf you installed SQLcl as recommended, you can connect to your database using this SQLcl (or use the SQLcl session created during module two, Setup). Start SQLcl in a new terminal window.\n$ sql /nolog SQLcl: Release 22.4 Production on Fri Mar 03 12:25:24 2023 Copyright (c) 1982, 2023, Oracle. All rights reserved. SQL\u003e Load the Wallet\nWhen you are connected, run the following command to load the Wallet you downloaded during the Setup lab. Replace the name of the waller and location of the Wallet to match your environment.\nSQL\u003e set cloudconfig /path/to/wallet/wallet-name.zip Connect to the Database\nIf you need to see what TNS Entries you have run the show tns command. For example:\nSQL\u003e show tns CLOUD CONFIG set to: /Users/atael/tmp/wallet/Wallet_CBANKDB.zip TNS Lookup Locations -------------------- TNS Locations Used ------------------ 1. /Users/atael/tmp/wallet/Wallet_CBANKDB.zip 2. /Users/atael Available TNS Entries --------------------- CBANKDB_HIGH CBANKDB_LOW CBANKDB_MEDIUM CBANKDB_TP CBANKDB_TPURGENTConnect to the database using the ADMIN user, the password you retrieved earlier and the TNS name DBNAME_tp.\nSQL\u003e connect ADMIN/your-ADMIN-password@your-TNS-entry Connected. Create Database Objects\nRun the SQL statements below to create the database objects:\n-- create a database user for the account service create user account identified by \"Welcome1234##\"; -- add roles and quota grant connect to account; grant resource to account; alter user account default role connect, resource; alter user account quota unlimited on users; -- create accounts table create table account.accounts ( account_id number generated always as identity (start with 1 cache 20), account_name varchar2(40) not null, account_type varchar2(2) check (account_type in ('CH', 'SA', 'CC', 'LO')), customer_id varchar2 (20), account_opened_date date default sysdate not null, account_other_details varchar2(4000), account_balance number ) logging; alter table account.accounts add constraint accounts_pk primary key (account_id) using index logging; comment on table account.accounts is 'CloudBank accounts table'; -- create journal table create table account.journal ( journal_id number generated always as identity (start with 1 cache 20), journal_type varchar2(20), account_id number, lra_id varchar2(1024) not null, lra_state varchar2(40), journal_amount number ) logging; alter table account.journal add constraint journal_pk primary key (journal_id) using index logging; comment on table account.journal is 'CloudBank accounts journal table'; / Now that the database objects are created, you can configure Spring Data JPA to use them in your microservice.",
    "description": "Get the database user ADMIN password\nThe ADMIN password can be retrieved from a k8s secret using this command. Replace the DBNAME with the name of your database. Save the password as it will be needed in later steps.\n$ kubectl -n application get secret DBNAME-db-secrets -o jsonpath='{.data.db\\.password}' | base64 -dIf you don’t know the name of the database, execute the following command and look for the line DBNAME-db-secrets.",
    "tags": [],
    "title": "Prepare Database Objects",
    "uri": "/microservices-datadriven/cloudbank/account/prepare-database/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This modules introduces Spring AI and explores how it can be used to build a CloudBank AI Assistant (chatbot) that will allow users to interact with CloudBank using a chat-based interface. In this module, you will learn about Retrieval Augmented Generation, Vector Database and AI Agents.",
    "description": "This modules introduces Spring AI and explores how it can be used to build a CloudBank AI Assistant (chatbot) that will allow users to interact with CloudBank using a chat-based interface. In this module, you will learn about Retrieval Augmented Generation, Vector Database and AI Agents.",
    "tags": [],
    "title": "CloudBank AI Assistant",
    "uri": "/microservices-datadriven/cloudbank/springai/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "The Data Access Object pattern is considered a best practice, and it allows separation of business logic from the persistence layer. In this task, you will create an Account Data Access Object (DAO) that hides the complexity of the persistence layer logic from the business layer services. Additionally, it establishes methods that can be reused by each business layer service that needs to operate on accounts - in this module there will be two such services - deposit and withdraw.\nCreate the DAO class Create a new Java file called AccountTransferDAO.java in src/main/java/com/example/accounts/services. This class will contain common data access methods that are needed by multiple participants. You will implement this class using the singleton pattern so that there will only be one instance of this class.\nHere is the code to set up the class and implement the singleton pattern:\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import com.example.accounts.repository.AccountRepository; import com.example.accounts.repository.JournalRepository; import com.oracle.microtx.springboot.lra.annotation.ParticipantStatus; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Component; @Component public class AccountTransferDAO { private static AccountTransferDAO singleton; final AccountRepository accountRepository; final JournalRepository journalRepository; /** * Initialize account and journal repository. * @param accountRepository Account Repository * @param journalRepository Journal Repository */ public AccountTransferDAO(AccountRepository accountRepository, JournalRepository journalRepository) { this.accountRepository = accountRepository; this.journalRepository = journalRepository; singleton = this; log.info(\"AccountTransferDAO accountsRepository = \" + accountRepository + \", journalRepository = \" + journalRepository); } public static AccountTransferDAO instance() { return singleton; } } ``` Create a method to get the LRA status as a String Create a getStatusString method which can be used to get a String representation of the LRA participant status.\n```java /** * Get status od LRA participant. * @param status Status code * @return Returns status code */ public static String getStatusString(ParticipantStatus status) { return switch (status) { case Compensated -\u003e \"Compensated\"; case Completed -\u003e \"Completed\"; case FailedToCompensate -\u003e \"Failed to Compensate\"; case FailedToComplete -\u003e \"Failed to Complete\"; case Active -\u003e \"Active\"; case Compensating -\u003e \"Compensating\"; case Completing -\u003e \"Completing\"; default -\u003e \"Unknown\"; }; } ``` Create a method to get the LRA status from a String Create a getStatusFromString method to convert back from the String to the enum.\n```java /** * Get LRA Status from a string. * @param statusString Status * @return Participant Status */ public static ParticipantStatus getStatusFromString(String statusString) { return switch (statusString) { case \"Compensated\" -\u003e ParticipantStatus.Compensated; case \"Completed\" -\u003e ParticipantStatus.Completed; case \"Failed to Compensate\" -\u003e ParticipantStatus.FailedToCompensate; case \"Failed to Complete\" -\u003e ParticipantStatus.FailedToComplete; case \"Active\" -\u003e ParticipantStatus.Active; case \"Compensating\" -\u003e ParticipantStatus.Compensating; case \"Completing\" -\u003e ParticipantStatus.Completing; default -\u003e null; }; } ``` Create a method to save an account Create a method to save an account in the account repository.\n```java public void saveAccount(Account account) { log.info(\"saveAccount account\" + account.getAccountId() + \" account\" + account.getAccountBalance()); accountRepository.save(account); } ``` Create a method to return the correct HTTP Status Code for an LRA status.\n```java /** * Return the correct HTTP Status Code for an LRA status * @param lraId LRA Id * @param journalType Journal Type * @return Participant Status * @throws Exception Exception */ public ResponseEntity\u003cParticipantStatus\u003e status(String lraId, String journalType) throws Exception { Journal journal = getJournalForLRAid(lraId, journalType); if (AccountTransferDAO.getStatusFromString(journal.getLraState()).equals(ParticipantStatus.Compensated)) { return ResponseEntity.ok(ParticipantStatus.Compensated); } else { return ResponseEntity.ok(ParticipantStatus.Completed); } } ``` Create a method to update the LRA status in the journal Create a method to update the LRA status in the journal table during the “after LRA” phase.\n```java /** * Update the LRA status in the journal table during the \"after LRA\" phase. * @param lraId LRA Id * @param status Status * @param journalType Journal Type * @throws Exception Exception */ public void afterLRA(String lraId, String status, String journalType) throws Exception { Journal journal = getJournalForLRAid(lraId, journalType); journal.setLraState(status); journalRepository.save(journal); } ``` Create methods to manage accounts Create a method to get the account for a given account ID.\n```java Account getAccountForAccountId(long accountId) { Account account = accountRepository.findByAccountId(accountId); if (account == null) return null; return account; } ``` Create a method to get the account that is related to a journal entry.\n```java Account getAccountForJournal(Journal journal) throws Exception { Account account = accountRepository.findByAccountId(journal.getAccountId()); if (account == null) throw new Exception(\"Invalid accountName:\" + journal.getAccountId()); return account; } ``` Update AccountRepository.java in src/main/java/com/example/accounts/repositories to add these extra JPA methods. Your updated file should look like this:\n```java package com.example.accounts.repository; import java.util.List; import org.springframework.data.jpa.repository.JpaRepository; import com.example.accounts.model.Account; public interface AccountRepository extends JpaRepository\u003cAccount, Long\u003e { List\u003cAccount\u003e findByAccountCustomerId(String customerId); List\u003cAccount\u003e findAccountsByAccountNameContains (String accountName); Account findByAccountId(long accountId); } ``` Create methods to manage the journal Back in the AccountTransferDAO, create a method to get the journal entry for a given LRA.\n```java Journal getJournalForLRAid(String lraId, String journalType) throws Exception { Journal journal = journalRepository.findJournalByLraIdAndJournalType(lraId, journalType); if (journal == null) { journalRepository.save(new Journal(\"unknown\", -1, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.FailedToComplete))); throw new Exception(\"Journal entry does not exist for lraId:\" + lraId); } return journal; } ``` Create a method to save a journal entry.\n```java public void saveJournal(Journal journal) { journalRepository.save(journal); } ``` This completes the Data Access Object, now you can start implementing the actual business logic for the services.",
    "description": "The Data Access Object pattern is considered a best practice, and it allows separation of business logic from the persistence layer. In this task, you will create an Account Data Access Object (DAO) that hides the complexity of the persistence layer logic from the business layer services. Additionally, it establishes methods that can be reused by each business layer service that needs to operate on accounts - in this module there will be two such services - deposit and withdraw.",
    "tags": [],
    "title": "Create a Data Access Object",
    "uri": "/microservices-datadriven/cloudbank/saga/dao/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "Next, you will create the “Check Processing” microservice which you will receive messages from the ATM and Back Office and process them by calling the appropriate endpoints on the Account service. This service will also introduce the use of service discovery using OpenFeign clients.\nCreate a new Java Project for the checks service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.\nSelect Spring Boot Project.\nSelect Maven Project.\nSpecify 3.3.1 as the Spring Boot version.\nUse com.example as the Group Id.\nEnter checks as the Artifact Id.\nUse JAR as the Packaging Type.\nSelect Java version 21.\nSearch for Spring Web, Lombok, Feign and Eureka Client. When all are selected press Enter.\nPress Enter to continue and create the Java Project\nSelect the root location for your project e.g. side by side with the checks, testrunner and account projects.\nWhen the project opens click Add to Workspace\nUpdate the pom.xml file for Oracle Spring Boot Starters It is very similar to the POM for the account and test runner services, however the dependencies are slightly different. This service will use the “Web” Spring Boot Starter which will allow it to expose REST endpoints and make REST calls to other services. It also uses the two Oracle Spring Boot Starters for UCP and Wallet to access the database. You will also add the Eureka client and OpenFeign dependencies to allow service discovery and client side load balancing. Open the pom.xml and add the following to the pom.xml:\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-aqjms\u003c/artifactId\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-wallet\u003c/artifactId\u003e \u003ctype\u003epom\u003c/type\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e ``` Create the Spring Boot application YAML file In the checks project, rename the file called application.properties to application.yaml located in the src/main/resources. This will be the Spring Boot application configuration file. Add the following content:\n```yaml spring: application: name: checks datasource: url: ${spring.datasource.url} username: ${spring.datasource.username} password: ${spring.datasource.password} eureka: instance: hostname: ${spring.application.name} preferIpAddress: true client: service-url: defaultZone: ${eureka.service-url} fetch-registry: true register-with-eureka: true enabled: true ``` This is the Spring Boot application YAML file, which contains the configuration information for this service. In this case, you need to provide the application name and the connection details for the database hosting the queues and the information for the Eureka server as the checks application will use a Feign client.\nCreate the main Spring Application class In the checks directory, create a new directory called src/main/java/com/example/checks and in that directory, create a new Java file called ChecksApplication.java with this content. This is a standard Spring Boot main class, notice the SpringBootApplication annotation on the class. It also has the EnableJms annotation which tells Spring Boot to enable JMS functionality in this application. The main method is a normal Spring Boot main method:\n```java package com.example.checks; import jakarta.jms.ConnectionFactory; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jms.DefaultJmsListenerContainerFactoryConfigurer; import org.springframework.cloud.openfeign.EnableFeignClients; import org.springframework.context.annotation.Bean; import org.springframework.jms.annotation.EnableJms; import org.springframework.jms.config.DefaultJmsListenerContainerFactory; import org.springframework.jms.config.JmsListenerContainerFactory; import org.springframework.jms.core.JmsTemplate; import org.springframework.jms.support.converter.MappingJackson2MessageConverter; import org.springframework.jms.support.converter.MessageConverter; import org.springframework.jms.support.converter.MessageType; @SpringBootApplication @EnableFeignClients @EnableJms public class ChecksApplication { public static void main(String[] args) { SpringApplication.run(ChecksApplication.class, args); } @Bean // Serialize message content to json using TextMessage public MessageConverter jacksonJmsMessageConverter() { MappingJackson2MessageConverter converter = new MappingJackson2MessageConverter(); converter.setTargetType(MessageType.TEXT); converter.setTypeIdPropertyName(\"_type\"); return converter; } @Bean public JmsTemplate jmsTemplate(ConnectionFactory connectionFactory) { JmsTemplate jmsTemplate = new JmsTemplate(); jmsTemplate.setConnectionFactory(connectionFactory); jmsTemplate.setMessageConverter(jacksonJmsMessageConverter()); return jmsTemplate; } @Bean public JmsListenerContainerFactory\u003c?\u003e factory(ConnectionFactory connectionFactory, DefaultJmsListenerContainerFactoryConfigurer configurer) { DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); // This provides all boot's default to this factory, including the message converter configurer.configure(factory, connectionFactory); // You could still override some of Boot's default if necessary. return factory; } } ``` As in the Test Runner service, you will also need the MessageConverter and JmsTemplate beans. You will also need an additional bean in this service, the JmsListenerConnectionFactory. This bean will be used to create listeners that receive messages from JMS queues. Note that the JMS ConnectionFactory is injected as in the Test Runner service.\nCreate the model classes Create a directory called src/main/java/com/example/testrunner/model and in that directory create the two model classes.\nNote: These are in the testrunner package, not the checks package! The classes used for serialization and deserialization of the messages need to be the same so that the MessageConverter knows what to do.\nFirst, CheckDeposit.java with this content:\n```java package com.example.testrunner.model; import lombok.AllArgsConstructor; import lombok.Data; import lombok.Getter; import lombok.NoArgsConstructor; import lombok.Setter; import lombok.ToString; @Data @AllArgsConstructor @NoArgsConstructor @Getter @Setter @ToString public class CheckDeposit { private long accountId; private long amount; } ``` And then, Clearance.java with this content:\n```java package com.example.testrunner.model; import lombok.AllArgsConstructor; import lombok.Data; import lombok.Getter; import lombok.NoArgsConstructor; import lombok.Setter; import lombok.ToString; @Data @AllArgsConstructor @NoArgsConstructor @Getter @Setter @ToString public class Clearance { private long journalId; } ``` Create the OpenFeign clients OpenFeign In this step you will use OpenFeign to create a client. OpenFeign allows you to look up an instance of a service from the Spring Eureka Service Registry using its key/identifier, and will create a client for you to call endpoints on that service. It also provides client-side load balancing. This allows you to easily create REST clients without needing to know the address of the service or how many instances are running.\nCreate a directory called src/main/java/com/example/checks/clients and in this directory create a new Java interface called AccountClient.java to define the OpenFeign client for the account service. Here is the content:\n```java package com.example.checks.clients; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; @FeignClient(\"account\") public interface AccountClient { @PostMapping(\"/api/v1/account/journal\") void journal(@RequestBody Journal journal); @PostMapping(\"/api/v1/account/journal/{journalId}/clear\") void clear(@PathVariable long journalId); } ``` In the interface, you define methods for each of the endpoints you want to be able to call. As you see, you specify the request type with an annotation, the endpoint path, and you can specify path variables and the body type. You will need to define the Journal class.\nIn the same directory, create a Java class called Journal.java with the following content:\n```java package com.example.checks.clients; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class Journal { private long journalId; private String journalType; private long accountId; private String lraId; private String lraState; private long journalAmount; public Journal(String journalType, long accountId, long journalAmount) { this.journalType = journalType; this.accountId = accountId; this.journalAmount = journalAmount; this.lraId = \"0\"; this.lraState = \"\"; } } ``` Note: The lraId and lraState field are set to reasonable default values, since we are not going to be using those fields in this lab.\nCreate the services Next, you will create a service to implement the methods defined in the OpenFeign client interface. Create a directory called src/main/java/com/example/checks/service and in that directory create a Java class called AccountService.java with this content. The services are very simple, you just need to use the accountClient to call the appropriate endpoint on the Account service and pass through the data. Note the AccountClient will be injected by Spring Boot because of the RequiredArgsConstructor annotation, which saves some boilerplate constructor code:\n```java package com.example.checks.service; import org.springframework.stereotype.Service; import com.example.checks.clients.AccountClient; import com.example.checks.clients.Journal; import com.example.testrunner.model.Clearance; import lombok.RequiredArgsConstructor; @Service @RequiredArgsConstructor public class AccountService { private final AccountClient accountClient; public void journal(Journal journal) { accountClient.journal(journal); } public void clear(Clearance clearance) { accountClient.clear(clearance.getJournalId()); } } ``` Create the Check Receiver controller This controller will receive messages on the deposits JMS queue and process them by calling the journal method in the AccountService that you just created, which will make a REST POST to the Account service, which in turn will write the journal entry into the accounts’ database.\nCreate a directory called src/main/java/com/example/checks/controller and in that directory, create a new Java class called CheckReceiver.java with the following content. You will need to inject an instance of the AccountService (in this example the constructor is provided, so you can compare to the annotation used previously). Implement a method to receive and process the messages. To receive messages from the queues, use the JmsListener annotation and provide the queue and factory names. This method should call the journal method on the AccountService and pass through the necessary data. Also, notice that you need to add the Component annotation to the class so that Spring Boot will load an instance of it into the application:\n```java package com.example.checks.controller; import org.springframework.jms.annotation.JmsListener; import org.springframework.stereotype.Component; import com.example.checks.clients.Journal; import com.example.checks.service.AccountService; import com.example.testrunner.model.CheckDeposit; import lombok.extern.slf4j.Slf4j; @Slf4j @Component public class CheckReceiver { private AccountService accountService; public CheckReceiver(AccountService accountService) { this.accountService = accountService; } @JmsListener(destination = \"deposits\", containerFactory = \"factory\") public void receiveMessage(CheckDeposit deposit) { log.info(\"Received deposit \u003c\" + deposit + \"\u003e\"); accountService.journal(new Journal(\"PENDING\", deposit.getAccountId(), deposit.getAmount())); } } ``` Create the Clearance Receiver controller In the same directory, create another Java class called ClearanceReceiver.java with the following content. This is very similar to the previous controller, but listens to the clearances queue instead, and calls the clear method on the AccountService:\n```java package com.example.checks.controller; import org.springframework.jms.annotation.JmsListener; import org.springframework.stereotype.Component; import com.example.checks.service.AccountService; import com.example.testrunner.model.Clearance; import lombok.extern.slf4j.Slf4j; @Slf4j @Component public class ClearanceReceiver { private AccountService accountService; public ClearanceReceiver(AccountService accountService) { this.accountService = accountService; } @JmsListener(destination = \"clearances\", containerFactory = \"factory\") public void receiveMessage(Clearance clearance) { log.info(\"Received clearance \u003c\" + clearance + \"\u003e\"); accountService.clear(clearance); } } ``` That completes the Check Processing service. Now you can deploy and test it.\nBuild a JAR file for deployment Run the following command to build the JAR file.\n```shell $ mvn clean package -DskipTests ``` The service is now ready to deploy to the backend.\nPrepare the backend for deployment The Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command in a new terminal window:\n```shell $ kubectl -n obaas-admin port-forward svc/obaas-admin 8080 ``` Get the password for the obaas-admin user. The obaas-admin user is the equivalent of the admin or root user in the Oracle Backend for Spring Boot and Microservices backend.\n```shell $ kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d ``` Start the Oracle Backend for Spring Boot and Microservices CLI (oractl) in a new terminal window using this command:\n```shell $ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e ``` Connect to the Oracle Backend for Spring Boot and Microservices admin service using the connect command. Enter obaas-admin and the username and use the password you collected earlier.\n```shell oractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e ``` Create a binding for the Check service Create a binding so the Check service can access the Oracle Autonomous Database as the account user. Run this command to create the binding, and type in the password for the account user when prompted. The password is Welcome1234##:\n```shell oractl:\u003e bind --app-name application --service-name checks --username account ``` Deploy the Check service You will now deploy your Check service to the Oracle Backend for Spring Boot and Microservices using the CLI. Run this command to deploy your service, make sure you provide the correct path to your JAR file. Note that this command may take 1-3 minutes to complete:\n```shell oractl:\u003e deploy --app-name application --service-name checks --artifact-path /path/to/checks-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: testrunner/target/testrunner-0.0.1-SNAPSHOT.jarbuilding and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` You can close the port forwarding session for the CLI now (just type a Ctrl+C in its console window).\nTesting the service Since you had messages already sitting on the queues, the service should process those as soon as it starts. You can check the service logs to see the log messages indicating this happened using this command:\n```shell $ kubectl -n application logs svc/checks ( ... lines omitted ...) Received deposit \u003cCheckDeposit(accountId=2, amount=200)\u003e Received clearance \u003cClearance(journalId=4)\u003e ( ... lines omitted ...) ``` You can also look at the journal table in the database to see the results.",
    "description": "Next, you will create the “Check Processing” microservice which you will receive messages from the ATM and Back Office and process them by calling the appropriate endpoints on the Account service. This service will also introduce the use of service discovery using OpenFeign clients.\nCreate a new Java Project for the checks service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.",
    "tags": [],
    "title": "Create the Check Processing Microservice",
    "uri": "/microservices-datadriven/cloudbank/check/check-processing/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Oracle Backend for Spring Boot and Microservices includes APISIX API Gateway to manage which services are made available outside the Kubernetes cluster. APISIX allows you to manage many aspects of the services’ APIs including authentication, logging, which HTTP methods are accepted, what URL paths are exposed, and also includes capabilities like rewriting, filtering, traffic management and has a rich plugin ecosystem to enhance it with additional capabilities. You can manage the APISIX API Gateway using the APISIX Dashboard.\nAccess the APISIX Dashboard\nStart the tunnel using this command. You can run this in the background if you prefer.\n$ kubectl -n apisix port-forward svc/apisix-dashboard 8081:80Open a web browser to http://localhost:8081 to view the APISIX Dashboard web user interface. It will appear similar to the image below.\nIf prompted to login, login with username admin and password admin. Note that Oracle strongly recommends that you change the password, even though this interface is not accessible outside the cluster without a tunnel.\nOpen the routes page from the left hand side menu. You will see the routes that you defined in earlier modules:\nView details of a route\nClick on the Configure button next to the account route. The first page shows information about the route definition. Scroll down to the Request Basic Define section. Notice how you can set the host, port, paths, HTTP Methods and other information for the API.\nClick on the Next button to move to the Define API Backend Server page where you can set the routing/load balancing algorithm, retries, timeout and so on. On this page you will notice that the upstream service is defined using Service Discovery and the discovery type is Eureka. The Service Name specified here is the key used to look up the service in the Spring Eureka Service Registry. APISIX will route to any available instance of the service registered in Eureka.\nClick on the Next button to move to the Plugin Config page. The routes in the CloudBank sample do not use any of the plugins, however you can scroll through this page to get an idea of what plugins are available for your services.\nNote: You can find detailed information about the available plugins and how to configure them in the APISIX documentation in the Plugins section.",
    "description": "Oracle Backend for Spring Boot and Microservices includes APISIX API Gateway to manage which services are made available outside the Kubernetes cluster. APISIX allows you to manage many aspects of the services’ APIs including authentication, logging, which HTTP methods are accepted, what URL paths are exposed, and also includes capabilities like rewriting, filtering, traffic management and has a rich plugin ecosystem to enhance it with additional capabilities. You can manage the APISIX API Gateway using the APISIX Dashboard.",
    "tags": [],
    "title": "Explore APISIX API Gateway",
    "uri": "/microservices-datadriven/cloudbank/backend/apisix/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "In later labs, you will look various resources in the Kubernetes cluster and access some of them using port forwarding (tunneling). To do this, you will need to install kubectl on your machine, and since Oracle Container Engine for Kubernetes uses token based authentication for kubectl access, you will also need to install the OCI CLI so that kubectl can obtain the necessary token.\nInstall kubectl\nInstall kubectl from the Kubernetes website. Click on the link for your operating system and follow the instructions to complete the installation. As mentioned in the instructions, you can use this command to verify the installation, and you can ignore the warning since we are just checking the installation was successful (your output may be slightly different):\n$ kubectl version --client I0223 08:40:30.072493 26355 versioner.go:56] Remote kubernetes server unreachable WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short. Use --output=yaml|json to get the full version. Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.1\", GitCommit:\"3ddd0f45aa91e2f30c70734b175631bec5b5825a\", GitTreeState:\"clean\", BuildDate:\"2022-05-24T12:26:19Z\", GoVersion:\"go1.18.2\", Compiler:\"gc\", Platform:\"linux/amd64\"} Kustomize Version: v4.5.4 Install the OCI CLI\nInstall the OCI CLI from the Quickstart documentation. Click on the link for your operating system and follow the instructions to complete the installation. After installation is complete, use this command to verify the installation (your output might be slightly different):\n$ oci --version 3.23.2 Configure the OCI CLI\nReview the instructions in the documentation for configuring the OCI CLI. The simplest way to configure the CLI is to use the guided setup by running this command:\n$ oci setup configThis will guide you through the process of creating your configuration file. Once you are done, check that the configuration is good by running this command (note that you would have obtained the tenancy OCID during the previous step, and your output might look slightly different):\n$ oci iam tenancy get --tenancy-id ocid1.tenancy.oc1..xxxxx { \"data\": { \"description\": \"mytenancy\", \"freeform-tags\": {}, \"home-region-key\": \"IAD\", \"id\": \"ocid1.tenancy.oc1..xxxxx\", \"name\": \"mytenancy\", \"upi-idcs-compatibility-layer-endpoint\": null } } ",
    "description": "In later labs, you will look various resources in the Kubernetes cluster and access some of them using port forwarding (tunneling). To do this, you will need to install kubectl on your machine, and since Oracle Container Engine for Kubernetes uses token based authentication for kubectl access, you will also need to install the OCI CLI so that kubectl can obtain the necessary token.\nInstall kubectl\nInstall kubectl from the Kubernetes website.",
    "tags": [],
    "title": "Install Kubectl and OCI CLI",
    "uri": "/microservices-datadriven/cloudbank/devenv/kubectl/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": " Add Spring Data JPA to the Account service and configure it to access the database Spring Data JPA allows our Spring Boot application to easily use the database. It uses simple Java POJOs to represent the data model and provides a lot of out-of-the-box features which means there is a lot less boilerplate code to be written.\nTo add Spring Data JPA and the Oracle Database drivers to your project, open the Maven POM (pom.xml) and add these extra dependencies for Spring Data JPA, Oracle Spring Boot Starters for Oracle Database UCP (Universal Connection Pool) and Wallet:\n```xml \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-jpa\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-ucp\u003c/artifactId\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.database.spring\u003c/groupId\u003e \u003cartifactId\u003eoracle-spring-boot-starter-wallet\u003c/artifactId\u003e \u003cversion\u003e23.4.0\u003c/version\u003e \u003c/dependency\u003e ``` Visual Studio code will display a notification in the bottom right corner and ask if it should update the project based on the change you just made. You should select Yes or Always to this notification. Doing so will ensure that the auto-completion will have access to the classes in the new dependency that you just added.\nConfigure JPA Datasource\nTo configure Spring Data JPA access to the database, you will add some configuration information to the Spring Boot application properties (or YAML) file. Access to the database you need to unzip the Wallet and get information from those files.\nUnzip the Wallet you downloaded in the Setup module (Lab 2) $ unzip /path/to/wallet/wallet_name.zip Edit the sqlnet.ora file so that the section (DIRECTORY=\"?/network/admin\") matches the full path to the directory where you unzipped the Wallet, for example: WALLET_LOCATION = (SOURCE = (METHOD = file) (METHOD_DATA = (DIRECTORY=\"/path/to/unzipped/wallet\"))) Get the TNS Entry connection string using this command. Remember the name of the entry as you’ll need it in the next steps. In the sample below it is cbankdb_tp. $ grep \"_tp =\" /path/to/unzipped/wallet/tnsnames.ora | cut -d\"=\" -f 1 cbankdb_tpYou will find a file called application.properties in the src/main/resources directory in your project. You can use either properties format or YAML format for this file. In this lab, you will use YAML. Rename the file to application.yaml and then add this content to the file. Make sure that you modify the url to contain the path to the wallet and the name of the TNS entry you collected earlier.\nspring: application: name: account jpa: hibernate: ddl-auto: validate properties: hibernate: dialect: org.hibernate.dialect.OracleDialect format_sql: true show-sql: true datasource: url: jdbc:oracle:thin:@tns_entry_from_above?TNS_ADMIN=/path/to/Wallet username: account password: Welcome1234## driver-class-name: oracle.jdbc.OracleDriver type: oracle.ucp.jdbc.PoolDataSource oracleucp: connection-factory-class-name: oracle.jdbc.pool.OracleDataSource connection-pool-name: AccountConnectionPool initial-pool-size: 15 min-pool-size: 10 max-pool-size: 30 ``` These parameters will be used by Spring Data JPA to automatically configure the data source and inject it into your application. This configuration uses [Oracle Universal Connection Pool](https://docs.oracle.com/en/database/oracle/oracle-database/21/jjucp/index.html) to improve performance and better utilize system resources. The settings in the `spring.jpa` section tell Spring Data JPA to use Oracle SQL syntax, and to show the SQL statements in the log, which is useful during development when you may wish to see what statements are being executed as your endpoints are called. Create the data model in the Spring Boot application\nCreate a new directory inside src/main/java/com/example/accounts called model and inside that new directory, create a new Java file called Account.java, when prompted for a type, choose class.\nIn this class you can define the fields that will make up the “account” object, as shown below. Also add a constructor for the non-generated fields.\npackage com.example.accounts.model; import java.util.Date; public class Account { private long accountId; private String accountName; private String accountType; private String accountCustomerId; private Date accountOpenedDate; private String accountOtherDetails; private long accountBalance; public Account(String accountName, String accountType, String accountOtherDetails, String accountCustomerId) { this.accountName = accountName; this.accountType = accountType; this.accountOtherDetails = accountOtherDetails; this.accountCustomerId = accountCustomerId; } }Now, you need to give Spring Data JPA some hints about how to map these fields to the underlying database objects. Spring Data JPA can actually automate creation of database objects for you, and that can be very helpful during development and testing. But in many real-world cases, the database objects will already exist, so in this module you will work with pre-existing database objects.\nBefore continuing, open the Maven POM (pom.xml) for the project and add this new dependency to the list. Lombok offers various annotations aimed at replacing Java code that is well known for being boilerplate, repetitive, or tedious to write. You’ll use it to avoid writing getters, setters, constructors and builders.\n\u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003eVisual Studio code will display a notification in the bottom right corner and ask if it should update the project based on the change you just made. You should select Yes or Always to this notification. Doing so will ensure that the auto-completion will have access to the classes in the new dependency that you just added.\nAdd the Data and NoArgsConstructor Lombok annotations to your Account class. @Data generates all the boilerplate that is normally associated with simple POJOs and beans: getters for all fields, setters for all non-final fields, and appropriate toString, equals and hashCode implementations that involve the fields of the class, and a constructor that initializes all final fields, as well as all non-final fields with no initializer that have been marked with @NonNull, in order to ensure the field is never null. The NoArgsConstructor creates a constructor with no arguments.\nAlso add the JPA Entity and Table annotations to the class and set the Table’s name property to accounts. These tell JPA that this object will be mapped to a table in the database called accounts. Your class should now look like this:\npackage com.example.accounts.model; import java.util.Date; import jakarta.persistence.Entity; import jakarta.persistence.Table; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @Entity @Table(name = \"ACCOUNTS\") public class Account { // ... }You also need to give some hints about the columns in the existing tables. You should add a Column annotation to each field and set its name property to the name of the database column. Some of the columns will need additional information.\nFirst, the accountId field is the primary key, so add the Id annotation to it, and its value is generated, so add the GeneratedValue annotation and set its strategy property to GenerationType.IDENTITY.\nNext, the accountOpenedDate field is special - it should not be able to be inserted or updated. So you will add the updatable and insertable properties to its Column annotation and set them both to false. Also add the Generated annotation and set it to GenerationTime.INSERT to tell Spring Data JPA that the value for this field should be generated at the time of the database insert operation.\nWith these additions, the fields in your class should now look like this, the extra imports are also shown:\nimport org.hibernate.annotations.Generated; import org.hibernate.annotations.GenerationTime; import jakarta.persistence.Column; import jakarta.persistence.GeneratedValue; import jakarta.persistence.GenerationType; import jakarta.persistence.Id; // ... @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"ACCOUNT_ID\") private long accountId; @Column(name = \"ACCOUNT_NAME\") private String accountName; @Column(name = \"ACCOUNT_TYPE\") private String accountType; @Column(name = \"CUSTOMER_ID\") private String accountCustomerId; @SuppressWarnings(\"deprecation\") @Generated(GenerationTime.INSERT) @Column(name = \"ACCOUNT_OPENED_DATE\", updatable = false, insertable = false) private Date accountOpenedDate; @Column(name = \"ACCOUNT_OTHER_DETAILS\") private String accountOtherDetails; @Column(name = \"ACCOUNT_BALANCE\") private long accountBalance; Create the JPA Repository definition\nCreate a new directory in src/main/java/com/example/accounts called repository and in the new directory, create a new Java file called AccountRepository.java. When prompted for the type, choose interface. Update the interface definition to extend JpaRepository with type parameters \u003cAccount, Long\u003e. Account is the model class you just created, and Long is the type of the primary key. Your interface should look like this:\npackage com.example.accounts.repository; import org.springframework.data.jpa.repository.JpaRepository; import com.example.account.model.Account; public interface AccountRepository extends JpaRepository\u003cAccount, Long\u003e { } By extending JpaRepository you will get a lot of convenient methods “for free”. You will use one of them now to create an endpoint to list all accounts.",
    "description": "Add Spring Data JPA to the Account service and configure it to access the database Spring Data JPA allows our Spring Boot application to easily use the database. It uses simple Java POJOs to represent the data model and provides a lot of out-of-the-box features which means there is a lot less boilerplate code to be written.\nTo add Spring Data JPA and the Oracle Database drivers to your project, open the Maven POM (pom.",
    "tags": [],
    "title": "Use Spring Data JPA",
    "uri": "/microservices-datadriven/cloudbank/account/jpa/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Deploy with the CLI",
    "content": " Verification of the services deployment\nVerify that the services are running properly by executing this command:\nkubectl get pods -n applicationThe output should be similar to this, all pods should have STATUS as Running. If not then you need to look at the logs for the pods/service to determine what is wrong for example kubectl logs -n application svc/customer.\nNAME READY STATUS RESTARTS AGE account-65cdc68dd7-k5ntz 1/1 Running 0 8m2s checks-78c988bdcf-n59qz 1/1 Running 0 42m creditscore-7b89d567cd-nm4p6 1/1 Running 0 38m customer-6f4dc67985-nf5kz 1/1 Running 0 41s testrunner-78d679575f-ch4k7 1/1 Running 0 33m transfer-869d796755-gn9lf 1/1 Running 0 27m Verify the all the Cloud Bank services deployed\nIn the next few commands, you need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column. In the example below the IP address is 100.20.30.40\nGet external IP Address\nYou can find the IP address using this command, you need the one listed in the EXTERNAL-IP column. In the example below the IP address is 100.20.30.40\n$ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13d Test the create account REST endpoint with this command, use the external IP address for your API Gateway. Make a note of the accountID in the output:\n$ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"accountName\": \"Sanjay''s Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOtherDetails\": \"Savings Account\"}' \\ http://API-ADDRESS-OF-API-GW/api/v1/account HTTP/1.1 201 Date: Wed, 01 Mar 2023 18:35:31 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"accountId\":24,\"accountName\":\"Sanjays Savings\",\"accountType\":\"SA\",\"accountCustomerId\":\"bkzLp8cozi\",\"accountOpenedDate\":null,\"accountOtherDetails\":\"Savings Account\",\"accountBalance\":0} Test the get account REST endpoint with this command, use the IP address for your API Gateway and the accountId that was returned in the previous command:\ncurl -s http://API-ADDRESS-OF-API-GW/api/v1/account/\u003caccountId\u003e | jq .Output should be similar to this:\n{ \"accountId\": 24, \"accountName\": \"Sanjay's Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": null, \"accountOtherDetails\": \"Savings Account\", \"accountBalance\": 1040 } Test on of the customer REST endpoints with this command, use the IP Address for your API Gateway.\ncurl -s http://API-ADDRESS-OF-API-GW/api/v1/customer | jqOutput should be similar to this:\n[ { \"customerId\": \"qwertysdwr\", \"customerName\": \"Andy\", \"customerEmail\": \"andy@andy.com\", \"dateBecameCustomer\": \"2023-11-06T20:06:19.000+00:00\", \"customerOtherDetails\": \"Somekind of Info\", \"customerPassword\": \"SuperSecret\" }, { \"customerId\": \"aerg45sffd\", \"customerName\": \"Sanjay\", \"customerEmail\": \"sanjay@sanjay.com\", \"dateBecameCustomer\": \"2023-11-06T20:06:19.000+00:00\", \"customerOtherDetails\": \"Information\", \"customerPassword\": \"Welcome\" }, { \"customerId\": \"bkzLp8cozi\", \"customerName\": \"Mark\", \"customerEmail\": \"mark@mark.com\", \"dateBecameCustomer\": \"2023-11-06T20:06:19.000+00:00\", \"customerOtherDetails\": \"Important Info\", \"customerPassword\": \"Secret\" } ] Test the creditscore REST endpoint with this command\ncurl -s http://API-ADDRESS-OF-API-GW/api/v1/creditscore | jqOutput should be similar to this:\n{ \"Date\": \"2023-11-06\", \"Credit Score\": \"686\" } Test the check service\nStart a tunnel to the testrunner service.\n$ kubectl -n application port-forward svc/testrunner 8084:8080 Forwarding from 127.0.0.1:8084 -\u003e 8080 Forwarding from [::1]:8084 -\u003e 8080 Deposit a check using the deposit REST endpoint\nRun this command to deposit a check, make sure you use the accountId from the account you created earlier.\n$ curl -i -X POST -H 'Content-Type: application/json' -d '{\"accountId\": 2, \"amount\": 256}' http://localhost:8084/api/v1/testrunner/deposit HTTP/1.1 201 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 02 Nov 2023 18:02:06 GMT {\"accountId\":2,\"amount\":256} Check the log of the check service\nExecute this command to check the log file of the check service:\nkubectl -n application logs svc/checksThe log file should contain something similar to this (with your accountId):\nReceived deposit \u003cCheckDeposit(accountId=2, amount=256)\u003e Check the Journal entries using the journal REST endpoint. Replace API-ADDRESS-OF-API-GW with your external IP Address.\ncurl -i http://API-ADDRESS-OF-API-GW/api/v1/account/2/journalThe output should be similar to this (with your AccountId). Note the journalId, you’re going to need it in the next step.\nHTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 02 Nov 2023 18:06:45 GMT [{\"journalId\":1,\"journalType\":\"PENDING\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":256}] Clearance of a check using the clear REST endpoint using your journalId:\ncurl -i -X POST -H 'Content-Type: application/json' -d '{\"journalId\": 1}' http://localhost:8084/api/v1/testrunner/clearHTTP/1.1 201 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 02 Nov 2023 18:09:17 GMT {\"journalId\":1} Check the logs of the checks service\nExecute this command to check the log file of the check service:\nkubectl -n application logs svc/checksThe log file should contain something similar to this (with your journalId):\nReceived clearance \u003cClearance(journalId=1)\u003e Check the journal REST endpoint\nExecute this command to check the Journal. Replace API-ADDRESS-OF-API-GW with your External IP Address and ACCOUNT-ID with your account id.\ncurl -i http://API-ADDRESS-OF-API-GW/api/v1/account/ACCOUNT-ID/journalThe output should look like this (with your accountId):\n`HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 02 Nov 2023 18:36:31 GMT [{\"journalId\":1,\"journalType\":\"DEPOSIT\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":256}]` Test Saga transactions across Microservices using the transfer service.\nStart a tunnel to the testrunner service.\n$ kubectl -n application port-forward svc/transfer 8085:8080 Forwarding from 127.0.0.1:8085 -\u003e 8080 Forwarding from [::1]:8085 -\u003e 8080 Check the account balances for two accounts, in this example the account numbers are 1 and 2. Replace API-ADDRESS-OF-API-GW with your External IP Address\ncurl -s http://API-ADDRESS-OF-API-GW/api/v1/account/1 | jq ; curl -s http://API-ADDRESS-OF-API-GW/api/v1/account/2 | jqThe output should be similar to this. Make a note of the accountBalance values.\n{ \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"qwertysdwr\", \"accountOpenedDate\": \"2023-11-06T19:58:58.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": -20 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-11-06T19:58:58.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 } Perform a transfer between the accounts (transfer $100 from account 2 to account 1)\n$ curl -X POST \"http://localhost:8085/transfer?fromAccount=2\u0026toAccount=1\u0026amount=100\" transfer status:withdraw succeeded deposit succeeded Check that the transfer has been made.\ncurl -s http://API-ADDRESS-OF-API-GW/api/v1/account/1 | jq ; curl -s http://API-ADDRESS-OF-API-GW/api/v1/account/2 | jqThe output should be similar to this. Make a note of the accountBalance values.\n{ \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"qwertysdwr\", \"accountOpenedDate\": \"2023-11-06T19:58:58.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": 80 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-11-06T19:58:58.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 900 } This concludes the module Deploy the full CloudBank Application using the oractl CLI interface.",
    "description": "Verification of the services deployment\nVerify that the services are running properly by executing this command:\nkubectl get pods -n applicationThe output should be similar to this, all pods should have STATUS as Running. If not then you need to look at the logs for the pods/service to determine what is wrong for example kubectl logs -n application svc/customer.\nNAME READY STATUS RESTARTS AGE account-65cdc68dd7-k5ntz 1/1 Running 0 8m2s checks-78c988bdcf-n59qz 1/1 Running 0 42m creditscore-7b89d567cd-nm4p6 1/1 Running 0 38m customer-6f4dc67985-nf5kz 1/1 Running 0 41s testrunner-78d679575f-ch4k7 1/1 Running 0 33m transfer-869d796755-gn9lf 1/1 Running 0 27m Verify the all the Cloud Bank services deployed",
    "tags": [],
    "title": "Verify the deployment",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/verify/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "At the end of the previous lab, during the verification of the installation, you looked at the end of the apply log and copied a command to obtain a Kubernetes configuration file to access your cluster. In that lab, you used OCI CLoud Shell to confirm you could access the cluster. Now, you need to configure similar access from your own development machine. You can run that same command on your local machine, we recommend that you choose a different location for the file, so it does not overwrite or interfere with any other Kubernetes configuration file you might already have on your machine.\nCreate the Kubernetes configuration file\nRun the command provided at the end of your installation log to obtain the Kubernetes configuration file. The command will be similar to this:\n$ oci ce cluster create-kubeconfig --cluster-id ocid1.cluster.oc1.phx.xxxx --file path/to/kubeconfig --region us-phoenix-1 --token-version 2.0.0 --kube-endpoint PUBLIC_ENDPOINT Configure kubectl to use the Kubernetes configuration file you just created\nSet the KUBECONFIG environment variable to point to the file you just created using this command (provide the path to where you created the file):\n$ export KUBECONFIG=/path/to/kubeconfig Verify access to the cluster\nCheck that you can access the cluster using this command:\n$ kubectl get pods -n obaas-admin NAME READY STATUS RESTARTS AGE obaas-admin-bf4cd5f55-z54pk 2/2 Running 2 (9d ago) 9dYour output will be slightly different, but you should see one pod listed in the output. This is enough to confirm that you have correctly configured access to the Kubernetes cluster.",
    "description": "At the end of the previous lab, during the verification of the installation, you looked at the end of the apply log and copied a command to obtain a Kubernetes configuration file to access your cluster. In that lab, you used OCI CLoud Shell to confirm you could access the cluster. Now, you need to configure similar access from your own development machine. You can run that same command on your local machine, we recommend that you choose a different location for the file, so it does not overwrite or interfere with any other Kubernetes configuration file you might already have on your machine.",
    "tags": [],
    "title": "Configure Kubectl",
    "uri": "/microservices-datadriven/cloudbank/devenv/kubectl-config/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "In this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using the CLI. If you prefer to use an IDE, skip this module and go to the next module instead.",
    "description": "In this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using the CLI. If you prefer to use an IDE, skip this module and go to the next module instead.",
    "tags": [],
    "title": "Deploy with the CLI",
    "uri": "/microservices-datadriven/cloudbank/deploy-cli/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "The Spring Config Server can be used to store configuration information for Spring Boot applications, so that the configuration can be injected at runtime. It organized the configuration into properties, which are essentially key/value pairs. Each property can be assigned to an application, a moduleel, and a profile. This allows a running application to be configured based on metadata which it will send to the Spring Config Server to obtain the right configuration data.\nThe configuration data is stored in a table in the Oracle Autonomous Database instance associated with the backend.\nLook at the configuration data\nExecute the query below by pasting it into the SQL worksheet in Database Actions (which you learned how to open in Task 2 above) and clicking on the green circle “play” icon. This query shows the externalized configuration data stored by the Spring Config Server.\nselect * from configserver.properties In this example you can see there is an application called fraud, which has two configuration properties for the profile kube and moduleel latest.",
    "description": "The Spring Config Server can be used to store configuration information for Spring Boot applications, so that the configuration can be injected at runtime. It organized the configuration into properties, which are essentially key/value pairs. Each property can be assigned to an application, a moduleel, and a profile. This allows a running application to be configured based on metadata which it will send to the Spring Config Server to obtain the right configuration data.",
    "tags": [],
    "title": "Explore Spring Config Server",
    "uri": "/microservices-datadriven/cloudbank/backend/config/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "In this secion, you will implement the deposit service’s business logic.\nThe deposit service will be responsible for depositing funds into accounts. It will be an LRA participant, and so it will need to implement the LRA lifecycle actions like complete, compensate, and so on. A significant amount of the logic will be shared with the withdrawal service, so you will also create a separate class for that shared logic, following the Data Access Object pattern, to keep the business layer separate from the persistence layer.\nImplement the business logic for the deposit method. This method should write a journal entry for the deposit, but should not update the account balance. Here is the code for this method:\n```java /** * Write journal entry re deposit amount. * Do not increase actual bank account amount */ @PostMapping @LRA(value = LRA.Type.MANDATORY, end = false) public ResponseEntity\u003cString\u003e deposit(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestParam(\"accountId\") long accountId, @RequestParam(\"amount\") long depositAmount) { log.info(\"...deposit \" + depositAmount + \" in account:\" + accountId + \" (lraId:\" + lraId + \") finished (in pending state)\"); Account account = AccountTransferDAO.instance().getAccountForAccountId(accountId); if (account == null) { log.info(\"deposit failed: account does not exist\"); AccountTransferDAO.instance().saveJournal( new Journal( DEPOSIT, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active) ) ); return ResponseEntity.ok(\"deposit failed: account does not exist\"); } AccountTransferDAO.instance().saveJournal( new Journal( DEPOSIT, accountId, depositAmount, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active) ) ); return ResponseEntity.ok(\"deposit succeeded\"); } ``` Implement the complete method This method should update the LRA status to completing, update the account balance, change the bank transaction (journal entry) status from pending to completed and the set the LRA status too completed. Here is the code for this method:\n```java /** * Increase balance amount as recorded in journal during deposit call. * Update LRA state to ParticipantStatus.Completed. */ @PutMapping(\"/complete\") @Complete public ResponseEntity\u003cString\u003e completeWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit complete called for LRA : \" + lraId); // get the journal and account... Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, DEPOSIT); Account account = AccountTransferDAO.instance().getAccountForJournal(journal); // set this LRA participant's status to completing... journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completing)); // update the account balance and journal entry... account.setAccountBalance(account.getAccountBalance() + journal.getJournalAmount()); AccountTransferDAO.instance().saveAccount(account); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completed)); AccountTransferDAO.instance().saveJournal(journal); // set this LRA participant's status to complete... return ResponseEntity.ok(ParticipantStatus.Completed.name()); } ``` Implement the compensate method This method should update both the deposit record in the journal and the LRA status too compensated. Here is the code for this method:\n```java /** * Update LRA state to ParticipantStatus.Compensated. */ @PutMapping(\"/compensate\") @Compensate public ResponseEntity\u003cString\u003e compensateWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"deposit compensate called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, DEPOSIT); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensated)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Compensated.name()); } ``` Implement the status method This method returns the LRA status. Here is the code for this method:\n```java /** * Return status. */ @GetMapping(value = \"/status\", produces = \"text/plain\") @Status public ResponseEntity\u003cParticipantStatus\u003e status(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestHeader(LRA_HTTP_PARENT_CONTEXT_HEADER) String parentLRA) throws Exception { log.info(\"status called for LRA : \" + lraId); return AccountTransferDAO.instance().status(lraId, DEPOSIT); } ``` Implement the after LRA method This method should perform any steps necessary to finalize or clean up after the LRA. In this case, all you need to do is update the status of the deposit entry in the journal. Here is the code for this method:\n```java /** * Delete journal entry for LRA. */ @PutMapping(value = \"/after\", consumes = \"text/plain\") @AfterLRA public ResponseEntity\u003cString\u003e afterLRA(@RequestHeader(LRA_HTTP_ENDED_CONTEXT_HEADER) String lraId, String status) throws Exception { log.info(\"After LRA Called : \" + lraId); AccountTransferDAO.instance().afterLRA(lraId, status, DEPOSIT); return ResponseEntity.ok(\"\"); } ``` That completes the implementation of the deposit service.",
    "description": "In this secion, you will implement the deposit service’s business logic.\nThe deposit service will be responsible for depositing funds into accounts. It will be an LRA participant, and so it will need to implement the LRA lifecycle actions like complete, compensate, and so on. A significant amount of the logic will be shared with the withdrawal service, so you will also create a separate class for that shared logic, following the Data Access Object pattern, to keep the business layer separate from the persistence layer.",
    "tags": [],
    "title": "Implement business logic",
    "uri": "/microservices-datadriven/cloudbank/saga/business-logic/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": " Create a service to list all accounts\nOpen your AccountsController.java file and add a final field in the class of type AccountRepository. And update the constructor to accept an argument of this type and set the field to that value. This tells Spring Boot to inject the JPA repository class we just created into this class. That will make it available to use in our services. The updated parts of your class should look like this:\nimport com.example.accounts.repository.AccountRepository; // ... final AccountRepository accountRepository; public AccountController(AccountRepository accountRepository) { this.accountRepository = accountRepository; }Now, add a method to get all the accounts from the database and return them. This method should respond to the HTTP GET method. You can use the built-in findAll method on JpaRepository to get the data. Your new additions to your class should look like this:\nimport java.util.List; import com.example.accounts.model.Account; // ... @GetMapping(\"/accounts\") public List\u003cAccount\u003e getAllAccounts() { return accountRepository.findAll(); } Rebuild and restart your application and test your new endpoint\nIf your application is still running, stop it with Ctrl+C (or equivalent) and then rebuild and restart it with this command:\n$ mvn spring-boot:runThis time, when it starts up you will see some new log messages that were not there before. These tell you that it connected to the database successfully.\n2023-02-25 15:58:16.852 INFO 29041 --- [ main] o.hibernate.jpa.internal.util.LogHelper : HHH000204: Processing PersistenceUnitInfo [name: default] 2023-02-25 15:58:16.872 INFO 29041 --- [ main] org.hibernate.Version : HHH000412: Hibernate ORM core version 5.6.15.Final 2023-02-25 15:58:16.936 INFO 29041 --- [ main] o.hibernate.annotations.common.Version : HCANN000001: Hibernate Commons Annotations {5.1.2.Final} 2023-02-25 15:58:17.658 INFO 29041 --- [ main] org.hibernate.dialect.Dialect : HHH000400: Using dialect: org.hibernate.dialect.Oracle12cDialect 2023-02-25 15:58:17.972 INFO 29041 --- [ main] o.h.e.t.j.p.i.JtaPlatformInitiator : HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform] 2023-02-25 15:58:17.977 INFO 29041 --- [ main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'Now you can test the new service with this command. It will not return any data as we haven’t loaded any data yet.\n$ curl http://localhost:8080/api/v1/accounts HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 25 Feb 2023 21:00:40 GMT [] Add data to ACCOUNTS table\nNotice that Spring Boot automatically set the Content-Type to application/json for us. The result is an empty JSON array [] as you might expect. Add some accounts to the database using these SQL statements (run these in your SQLcl terminal):\ninsert into account.accounts (account_name,account_type,customer_id,account_other_details,account_balance) values ('Andy''s checking','CH','abcDe7ged','Account Info',-20); insert into account.accounts (account_name,account_type,customer_id,account_other_details,account_balance) values ('Mark''s CCard','CC','bkzLp8cozi','Mastercard account',1000); commit; Test the /accounts service\nNow, test the service again. You may want to send the output to jq if you have it installed, so that it will be formatted for easier reading:\n$ curl -s http://localhost:8080/api/v1/accounts | jq . [ { \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"abcDe7ged\", \"accountOpenedDate\": \"2023-02-26T02:04:54.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": -20 }, { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-02-26T02:04:56.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 } ]Now that you can query accounts, it is time to create an API endpoint to create an account.\nCreate an endpoint to create a new account.\nNow we want to create an endpoint to create a new account. Open AccountController.java and add a new createAccount method. This method should return ResponseEntity\u003cAccount\u003e this will allow you to return the account object, but also gives you access to set headers, status code and so on. The method needs to take an Account as an argument. Add the RequestBody annotation to the argument to tell Spring Boot that the input data will be in the HTTP request’s body.\nInside the method, you should use the saveAndFlush method on the JPA Repository to save a new instance of Account in the database. The saveAndFlush method returns the created object. If the save was successful, return the created object and set the HTTP Status Code to 201 (Created). If there is an error, set the HTTP Status Code to 500 (Internal Server Error).\nHere’s what the new method (and imports) should look like:\nimport java.net.URI; ... ... import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.servlet.support.ServletUriComponentsBuilder; // ... @PostMapping(\"/account\") public ResponseEntity\u003cAccount\u003e createAccount(@RequestBody Account account) { try { Account newAccount = accountRepository.saveAndFlush(account); URI location = ServletUriComponentsBuilder .fromCurrentRequest() .path(\"/{id}\") .buildAndExpand(newAccount.getAccountId()) .toUri(); return ResponseEntity.created(location).build(); } catch (Exception e) { return new ResponseEntity\u003c\u003e(account, HttpStatus.INTERNAL_SERVER_ERROR); } } Test the /account endpoint\nRebuild and restart the application as you have previously. Then test the new endpoint. You will need to make an HTTP POST request, and you will need to set the Content-Type header to application/json. Pass the data in as JSON in the HTTP request body. Note that Spring Boot Web will handle mapping the JSON to the right fields in the type annotated with the RequestBody annotation. So a JSON field called accountName will map to the accountName field in the JSON, and so on.\nHere is an example request and the expected output (yours will be slightly different):\n$ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"accountName\": \"Dave\", \"accountType\": \"CH\", \"accountOtherDetail\": \"\", \"accountCustomerId\": \"abc123xyz\"}' \\ http://localhost:8080/api/v1/account HTTP/1.1 201 Location: http://localhost:8080/api/v1/account/3 Content-Length: 0 Date: Wed, 14 Feb 2024 21:33:17 GMTNotice the HTTP Status Code is 201 (Created). The service returns the URI for the account was created in the header.\nTest endpoint /account with bad data\nNow try a request with bad data that will not be able to be parsed and observe that the HTTP Status Code is 400 (Bad Request). If there happened to be an exception thrown during the save() method, you would get back a 500 (Internal Server Error):\n$ curl -i -X POST -H 'Content-Type: application/json' -d '{\"bad\": \"data\"}' http://localhost:8080/api/v1/account HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 25 Feb 2023 22:05:24 GMT Connection: close {\"timestamp\":\"2023-02-25T22:05:24.350+00:00\",\"status\":400,\"error\":\"Bad Request\",\"path\":\"/api/v1/account\"} Implement Get Account by Account ID endpoint\nAdd new method to your AccountController.java class that responds to the HTTP GET method. This method should accept the account ID as a path variable. To accept a path variable, you place the variable name in braces in the URL path in the @GetMapping annotation and then reference it in the method’s arguments using the @PathVariable annotation. This will map it to the annotated method argument. If an account is found, you should return that account and set the HTTP Status Code to 200 (OK). If an account is not found, return an empty body and set the HTTP Status Code to 404 (Not Found).\nHere is the code to implement this endpoint:\nimport org.springframework.http.HttpStatus; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PathVariable; import java.util.Optional; // ... @GetMapping(\"/account/{accountId}\") public ResponseEntity\u003cAccount\u003e getAccountById(@PathVariable(\"accountId\") long accountId) { Optional\u003cAccount\u003e accountData = accountRepository.findById(accountId); try { return accountData.map(account -\u003e new ResponseEntity\u003c\u003e(account, HttpStatus.OK)) .orElseGet(() -\u003e new ResponseEntity\u003c\u003e(HttpStatus.NOT_FOUND)); } catch (Exception e) { return new ResponseEntity\u003c\u003e(null, HttpStatus.INTERNAL_SERVER_ERROR); } } Restart and test /account/{accountId} endpoint\nRestart the application and test this new endpoint with this command (note that you created account with ID 2 earlier):\n$ curl -s http://localhost:8080/api/v1/account/2 | jq . { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-02-26T02:04:56.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 }That completes the basic endpoints. In the next task, you can add some additional endpoints if you wish. If you prefer, you can skip that task because you have the option to deploy the fully pre-built service in a later module (Deploy the full CloudBank Application) if you choose.",
    "description": "Create a service to list all accounts\nOpen your AccountsController.java file and add a final field in the class of type AccountRepository. And update the constructor to accept an argument of this type and set the field to that value. This tells Spring Boot to inject the JPA repository class we just created into this class. That will make it available to use in our services. The updated parts of your class should look like this:",
    "tags": [],
    "title": "Query and Create Accounts",
    "uri": "/microservices-datadriven/cloudbank/account/cr-accounts/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Check Processing",
    "content": "Now you can test the full end-to-end flow for the Check Processing scenario.\nSimulate a check deposit The Test Runner service is not exposed outside your Kubernetes cluster, so you must create a port-forwarding tunnel to access it. Create a tunnel using this command:\n```shell $ kubectl -n application port-forward svc/testrunner 8084:8080 ``` Simulate a check being deposited at the ATM using the Test Runner service:\n```shell $ curl -i -X POST -H 'Content-Type: application/json' -d '{\"accountId\": 2, \"amount\": 256}' http://localhost:8084/api/v1/testrunner/deposit HTTP/1.1 201 Date: Wed, 31 May 2023 15:11:55 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"accountId\":2,\"amount\":256} ``` Check the logs for the Check Processing service Check the logs for the Check Processing service using this command. You should see a log message indicating that the message was received and processed:\n```shell $ kubectl -n application logs svc/checks ( ... lines omitted ...) Received deposit \u003cCheckDeposit(accountId=2, amount=256)\u003e ( ... lines omitted ...) ``` Check the journal entries for this account In the next commands, you need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n```shell $ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13d ``` Use this command to retrieve the journal entries for this account. Your output may contain more entries. Find the entry corresponding to the deposit you just simulated (it was for $256) and note the journalId - you will need it in the next step:\n```shell $ curl -i http://[EXTERNAL-IP]/api/v1/account/2/journal HTTP/1.1 200 Date: Wed, 31 May 2023 13:03:22 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive [{\"journalId\":6,\"journalType\":\"PENDING\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":256}] ``` Simulate the Back Office clearance of that check Using the journalId you received in the output of the previous command (in this example it is 6), update and then run this command to simulate the Back Office clearing that check:\n```shell $ curl -i -X POST -H 'Content-Type: application/json' -d '{\"journalId\": 6}' http://localhost:8084/api/v1/testrunner/clear HTTP/1.1 201 Date: Wed, 31 May 2023 15:12:54 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"journalId\":6} ``` Check the logs for the Check Processing service Check the logs for the Check Processing service using this command. You should see a log message indicating that the message was received and processed:\n```shell $ kubectl -n application logs svc/checks ( ... lines omitted ...) Received clearance \u003cClearance(journalId=6)\u003e ( ... lines omitted ...) ``` Retrieve the journal entries again Retrieve the journal entries again to confirm the PENDING entry was updated to a DEPOSIT:\n```shell $ curl -i http://[EXTERNAL-IP]/api/v1/account/2/journal HTTP/1.1 200 Date: Wed, 31 May 2023 13:03:22 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive [{\"journalId\":6,\"journalType\":\"DEPOSIT\",\"accountId\":2,\"lraId\":\"0\",\"lraState\":null,\"journalAmount\":256}] ``` That completes this lab, congratulations, you learned how to use JMS to create loosely coupled services that process asynchronous messages, and also how to use service discovery with OpenFeign.",
    "description": "Now you can test the full end-to-end flow for the Check Processing scenario.\nSimulate a check deposit The Test Runner service is not exposed outside your Kubernetes cluster, so you must create a port-forwarding tunnel to access it. Create a tunnel using this command:\n```shell $ kubectl -n application port-forward svc/testrunner 8084:8080 ``` Simulate a check being deposited at the ATM using the Test Runner service:\n```shell $ curl -i -X POST -H 'Content-Type: application/json' -d '{\"accountId\": 2, \"amount\": 256}' http://localhost:8084/api/v1/testrunner/deposit HTTP/1.",
    "tags": [],
    "title": "Test the end-to-end flow",
    "uri": "/microservices-datadriven/cloudbank/check/test/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "Next, you need to implement the withdraw service, which will be the second participant in the transfer LRA.\nImplement the withdraw service Create a new Java file called WithdrawService.java in src/main/java/com/example/accounts/services. This service is very similar to the deposit service, and no new concepts are introduced here. Here is the code for this service:\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import com.oracle.microtx.springboot.lra.annotation.AfterLRA; import com.oracle.microtx.springboot.lra.annotation.Compensate; import com.oracle.microtx.springboot.lra.annotation.Complete; import com.oracle.microtx.springboot.lra.annotation.LRA; import com.oracle.microtx.springboot.lra.annotation.ParticipantStatus; import com.oracle.microtx.springboot.lra.annotation.Status; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.PutMapping; import org.springframework.web.bind.annotation.RequestHeader; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_ENDED_CONTEXT_HEADER; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_PARENT_CONTEXT_HEADER; @RestController @RequestMapping(\"/withdraw\") @Slf4j public class WithdrawService { public static final String WITHDRAW = \"WITHDRAW\"; /** * Reduce account balance by given amount and write journal entry re the same. * Both actions in same local tx */ @PostMapping @LRA(value = LRA.Type.MANDATORY, end = false) public ResponseEntity\u003cString\u003e withdraw(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestParam(\"accountId\") long accountId, @RequestParam(\"amount\") long withdrawAmount) { log.info(\"withdraw \" + withdrawAmount + \" in account:\" + accountId + \" (lraId:\" + lraId + \")...\"); Account account = AccountTransferDAO.instance().getAccountForAccountId(accountId); if (account == null) { log.info(\"withdraw failed: account does not exist\"); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw failed: account does not exist\"); } if (account.getAccountBalance() \u003c withdrawAmount) { log.info(\"withdraw failed: insufficient funds\"); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, 0, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw failed: insufficient funds\"); } log.info(\"withdraw current balance:\" + account.getAccountBalance() + \" new balance:\" + (account.getAccountBalance() - withdrawAmount)); account.setAccountBalance(account.getAccountBalance() - withdrawAmount); AccountTransferDAO.instance().saveAccount(account); AccountTransferDAO.instance().saveJournal( new Journal( WITHDRAW, accountId, withdrawAmount, lraId, AccountTransferDAO.getStatusString(ParticipantStatus.Active))); return ResponseEntity.ok(\"withdraw succeeded\"); } /** * Update LRA state. Do nothing else. */ @PutMapping(\"/complete\") @Complete public ResponseEntity\u003cString\u003e completeWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"withdraw complete called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, WITHDRAW); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Completed)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Completed.name()); } /** * Read the journal and increase the balance by the previous withdraw amount. * before the LRA */ @PutMapping(\"/compensate\") @Compensate public ResponseEntity\u003cString\u003e compensateWork(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) throws Exception { log.info(\"Account withdraw compensate() called for LRA : \" + lraId); Journal journal = AccountTransferDAO.instance().getJournalForLRAid(lraId, WITHDRAW); journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensating)); Account account = AccountTransferDAO.instance().getAccountForAccountId(journal.getAccountId()); if (account != null) { account.setAccountBalance(account.getAccountBalance() + journal.getJournalAmount()); AccountTransferDAO.instance().saveAccount(account); } journal.setLraState(AccountTransferDAO.getStatusString(ParticipantStatus.Compensated)); AccountTransferDAO.instance().saveJournal(journal); return ResponseEntity.ok(ParticipantStatus.Compensated.name()); } @Status public ResponseEntity\u003cParticipantStatus\u003e status(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId, @RequestHeader(LRA_HTTP_PARENT_CONTEXT_HEADER) String parentLRA) throws Exception { return AccountTransferDAO.instance().status(lraId, WITHDRAW); } /** * Delete journal entry for LRA. */ @PutMapping(value = \"/after\", consumes = \"text/plain\") @AfterLRA public ResponseEntity\u003cString\u003e afterLRA(@RequestHeader(LRA_HTTP_ENDED_CONTEXT_HEADER) String lraId, String status) throws Exception { log.info(\"After LRA Called : \" + lraId); AccountTransferDAO.instance().afterLRA(lraId, status, WITHDRAW); return ResponseEntity.ok(\"\"); } } ``` That completes the implementation of the deposit service, and with that you are also done with the modifications for the Account Spring Boot microservice application to allow it to participate int he LRA. Next, you will create the Transfer Spring Boot microservice application.",
    "description": "Next, you need to implement the withdraw service, which will be the second participant in the transfer LRA.\nImplement the withdraw service Create a new Java file called WithdrawService.java in src/main/java/com/example/accounts/services. This service is very similar to the deposit service, and no new concepts are introduced here. Here is the code for this service:\n```java package com.example.accounts.services; import com.example.accounts.model.Account; import com.example.accounts.model.Journal; import com.oracle.microtx.springboot.lra.annotation.AfterLRA; import com.oracle.microtx.springboot.lra.annotation.Compensate; import com.oracle.microtx.springboot.lra.annotation.Complete; import com.oracle.microtx.springboot.lra.annotation.LRA; import com.",
    "tags": [],
    "title": "Create the Withdrawal service",
    "uri": "/microservices-datadriven/cloudbank/saga/withdraw-service/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "In this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using one of the IDE plugins - for Visual Studio Code or IntelliJ.",
    "description": "In this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using one of the IDE plugins - for Visual Studio Code or IntelliJ.",
    "tags": [],
    "title": "Deploy with an IDE",
    "uri": "/microservices-datadriven/cloudbank/deploy-ide/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Grafana provides an easy way to access the metrics collected in the backend and to view them in dashboards. It can be used to monitor performance, as well as to identify and analyze problems and to create alerts.\nExplore the pre-installed Spring Boot Dashboard\nGet the password for the Grafana admin user using this command (your output will be different):\n$ kubectl -n grafana get secret grafana -o jsonpath='{.data.admin-password}' | base64 -d fusHDM7xdwJXyUM2bLmydmN1V6b3IyPVRUxDtqu7Start the tunnel using this command. You can run this in the background if you prefer.\n$ kubectl -n grafana port-forward svc/grafana 8080:80Open a web browser to http://localhost:8080/grafana/ to view the Grafana web user interface. It will appear similar to the image below. Log in with the username admin and the password you just got.\nAfter signing in you will get to the Grafana homepage.\nOn the left, click on Dashboards to set the list of pre-installed dashboards.\nclick on the link to Spring Boot 3.x Statistics to see Spring Boot information.\nThe Spring Boot Dashboard looks like the image below. Use the Instance selector at the top to choose which microservice you wish to view information for.\nFeel free to explore the other dashboards that are preinstalled.",
    "description": "Grafana provides an easy way to access the metrics collected in the backend and to view them in dashboards. It can be used to monitor performance, as well as to identify and analyze problems and to create alerts.\nExplore the pre-installed Spring Boot Dashboard\nGet the password for the Grafana admin user using this command (your output will be different):\n$ kubectl -n grafana get secret grafana -o jsonpath='{.data.admin-password}' | base64 -d fusHDM7xdwJXyUM2bLmydmN1V6b3IyPVRUxDtqu7Start the tunnel using this command.",
    "tags": [],
    "title": "Explore Grafana",
    "uri": "/microservices-datadriven/cloudbank/backend/grafana/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": "If you would like to learn more about endpoints and implement the remainder of the account-related endpoints, this task provides the necessary details.\nImplement Get Accounts for Customer ID endpoint\nAdd a new method to your AccountController.java class that responds to the HTTP GET method. This method should accept a customer ID as a path variable and return a list of accounts for that customer ID. If no accounts are found, return an empty body and set the HTTP Status Code to 204 (No Content).\nHere is the code to implement this endpoint:\nimport java.util.ArrayList; // ... @GetMapping(\"/account/getAccounts/{customerId}\") public ResponseEntity\u003cList\u003cAccount\u003e\u003e getAccountsByCustomerId(@PathVariable(\"customerId\") String customerId) { try { List\u003cAccount\u003e accountData = new ArrayList\u003cAccount\u003e(); accountData.addAll(accountRepository.findByAccountCustomerId(customerId)); if (accountData.isEmpty()) { return new ResponseEntity\u003c\u003e(HttpStatus.NO_CONTENT); } return new ResponseEntity\u003c\u003e(accountData, HttpStatus.OK); } catch (Exception e) { return new ResponseEntity\u003c\u003e(null, HttpStatus.INTERNAL_SERVER_ERROR); } }You will also need to update your AccountRepository.java class to add the extra find method you need for this endpoint.\nimport java.util.List; // ... public interface AccountRepository extends JpaRepository \u003cAccount, Long\u003e { List\u003cAccount\u003e findByAccountCustomerId(String customerId); } Test the /account/getAccounts/{customerId} endpoint\nRestart the application and test the new endpoint with this command (note that you created this account and customer ID earlier):\n$ curl -s http://localhost:8080/api/v1/account/getAccounts/bkzLp8cozi | jq . [ { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-02-26T02:04:56.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 } ] Implement a Delete Account API endpoint\nAdd a new method to your AccountController.java file that responds to the HTTP DELETE method and accepts an account ID as a path variable. You can use the @DeleteMapping annotation to respond to HTTP DELETE. This method should delete the account specified and return an empty body and HTTP Status Code 204 (No Content) which is generally accepted to mean the deletion was successful (some people also use 200 (OK) for this purpose).\nHere is the code to implement this endpoint:\nimport org.springframework.web.bind.annotation.DeleteMapping; // ... @DeleteMapping(\"/account/{accountId}\") public ResponseEntity\u003cHttpStatus\u003e deleteAccount(@PathVariable(\"accountId\") long accountId) { try { accountRepository.deleteById(accountId); return new ResponseEntity\u003c\u003e(HttpStatus.NO_CONTENT); } catch (Exception e) { return new ResponseEntity\u003c\u003e(HttpStatus.INTERNAL_SERVER_ERROR); } } Test the Delete /account/{accountId} endpoint\nRestart the application and test this new endpoint by creating and deleting an account. First create an account:\n$ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"accountName\": \"Bob\", \"accountType\": \"CH\", \"accountOtherDetail\": \"\", \"accountCustomerId\": \"bob808bob\"}' \\ http://localhost:8080/api/v1/account HTTP/1.1 201 Content-Type: application/json Transfer-Encoding: chunked Date: Wed, 01 Mar 2023 13:23:44 GMT {\"accountId\":42,\"accountName\":\"Bob\",\"accountType\":\"CH\",\"accountCustomerId\":\"bob808bob\",\"accountOpenedDate\":\"2023-03-01T18:23:44.000+00:00\",\"accountOtherDetails\":null,\"accountBalance\":0}Verify that account exists:\n$ curl -s http://localhost:8080/api/v1/account/getAccounts/bob808bob | jq . [ { \"accountId\": 42, \"accountName\": \"Bob\", \"accountType\": \"CH\", \"accountCustomerId\": \"bob808bob\", \"accountOpenedDate\": \"2023-03-01T18:23:44.000+00:00\", \"accountOtherDetails\": null, \"accountBalance\": 0 } ]Delete the account. Note that your account ID may be different, check the output from the previous command to get the right ID and replace 42 at the end of the URL with your ID:\n$ curl -i -X DELETE http://localhost:8080/api/v1/account/42 HTTP/1.1 204 Date: Wed, 01 Mar 2023 13:23:56 GMTVerify the account no longer exists:\n$ curl -s http://localhost:8080/api/v1/account/getAccounts/bob808bob | jq .That completes the account endpoints. Now it is time to deploy your service to the backend.",
    "description": "If you would like to learn more about endpoints and implement the remainder of the account-related endpoints, this task provides the necessary details.\nImplement Get Accounts for Customer ID endpoint\nAdd a new method to your AccountController.java class that responds to the HTTP GET method. This method should accept a customer ID as a path variable and return a list of accounts for that customer ID. If no accounts are found, return an empty body and set the HTTP Status Code to 204 (No Content).",
    "tags": [],
    "title": "Extra Account Endpoints",
    "uri": "/microservices-datadriven/cloudbank/account/extra-endpoints/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": " (Optional) Install SQLcl\nIf you do not already have a database client, Oracle SQL Developer Command Line (SQLcl) is a free command line interface for Oracle Database which includes great features like auto-completion and command history. All the Labs are using SQLcl as the database client.\nIf you choose to use SQLcl make sure it is in your PATH variable:\nexport PATH=/path/to/sqlcl:$PATH ",
    "description": " (Optional) Install SQLcl\nIf you do not already have a database client, Oracle SQL Developer Command Line (SQLcl) is a free command line interface for Oracle Database which includes great features like auto-completion and command history. All the Labs are using SQLcl as the database client.\nIf you choose to use SQLcl make sure it is in your PATH variable:\nexport PATH=/path/to/sqlcl:$PATH ",
    "tags": [],
    "title": "Install SQLcl",
    "uri": "/microservices-datadriven/cloudbank/devenv/sqlcl/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "Now, you will create another new Spring Boot microservice application and implement the Transfer Service. This service will initiate the LRA and act as the logical coordinator - it will call the deposit and withdraw services you just implemented to effect the transfer to process the Cloud Cash Payment.\nCreate a new Java Project for the transfer service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.\nSelect Spring Boot Project.\nSelect Maven Project.\nSpecify 3.3.1 as the Spring Boot version.\nUse com.example as the Group Id.\nEnter transfer as the Artifact Id.\nUse JAR as the Packaging Type.\nSelect Java version 21.\nSearch for Spring Web and press Enter\nPress Enter to continue and create the Java Project\nSelect the root location for your project e.g. side by side with the checks, testrunner and accounts projects.\nWhen the project opens click Add to Workspace\nAdd MicroTX and Lombok to the pom.xml file Open the pom.xml file in the transfer project. Add the following to the pom.xml:\n```xml \u003cdependency\u003e \u003cgroupId\u003ecom.oracle.microtx.lra\u003c/groupId\u003e \u003cartifactId\u003emicrotx-lra-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e23.4.2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e ``` Create the Spring Boot application configuration In the transfer project, rename the file called application.properties to application.yaml located in the src/main/resources. This will be the Spring Boot application configuration file. In this file you need to configure the endpoints for the LRA participants and coordinator.\n```yaml spring: application: name: transfer mvc: enforced-prefixes: - /actuator - /rest url-mappings: - \"/rest/*\" - \"/actuator/*\" - \"/error/*\" microtx: lra: coordinator-url: ${MP_LRA_COORDINATOR_URL} propagation-active: true headers-propagation-prefix: \"{x-b3-, oracle-tmm-, authorization, refresh-}\" account: deposit: url: http://account.application:8080/deposit withdraw: url: http://account.application:8080/withdraw transfer: cancel: url: http://transfer.application:8080/cancel process: url: http://transfer.application:8080/processcancel confirm: url: http://transfer.application:8080/confirm process: url: http://transfer.application:8080/processconfirm ``` Create the Transfer service You are now ready to implement the main logic for the Cloud Cash Payment/transfer LRA. You will implement this in a new Java file called TransferService.java in src/main/java/com/example/transfer. Here are the imports you will need for this class and the member variables. Note that this class has the @RestController and @RequestMapping annotations, as you saw previously in the Account project, to set up the URL context root for the service.\n```java package com.example.transfer; import java.net.URI; import com.oracle.microtx.springboot.lra.annotation.Compensate; import com.oracle.microtx.springboot.lra.annotation.Complete; import com.oracle.microtx.springboot.lra.annotation.LRA; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Value; import org.springframework.http.HttpEntity; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestHeader; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import org.springframework.web.util.UriComponentsBuilder; import static com.oracle.microtx.springboot.lra.annotation.LRA.LRA_HTTP_CONTEXT_HEADER; @RestController @RequestMapping(\"/\") @Slf4j public class TransferService { public static final String TRANSFER_ID = \"TRANSFER_ID\"; @Value(\"${account.withdraw.url}\") URI withdrawUri; @Value(\"${account.deposit.url}\") URI depositUri; @Value(\"${transfer.cancel.url}\") URI transferCancelUri; @Value(\"${transfer.cancel.process.url}\") URI transferProcessCancelUri; @Value(\"${transfer.confirm.url}\") URI transferConfirmUri; @Value(\"${transfer.confirm.process.url}\") URI transferProcessConfirmUri; } ``` Create the transfer endpoint This is the main entry point for the LRA. When a client calls this method, a new LRA will be started. The @LRA annotation with the value property set to LRA.Type.REQUIRES_NEW instructs the interceptors/filters to contact Oracle Transaction Manager for Microservices to start a new LRA instance and obtain the LRA ID, which will be injected into the LRA_HTTP_CONTEXT_HEADER HTTP header. Note that the end property is set to false which means there will be other actions and participants before the LRA is completed.\nThis method will accept three parameters from the caller, in JSON format in the HTTP body: fromAccount is the account from which the funds are to be withdrawn, toAccount is the account into which the funds are to be deposited, and amount is the amount to transfer.\nIn the method body, you should first check if the lraId was set. If it is null, that indicates that there was some error trying to create the new LRA instance, and you should return an error response and stop.\nAfter that, you want to perform the withdrawal, check if it worked, and if so, perform the deposit, and then check if that worked, and if so “complete” the LRA. If there were any failures, compensate the LRA.\n```java /** * Transfer amount between two accounts. * @param fromAccount From an account * @param toAccount To an account * @param amount Amount to transfer * @param lraId LRA Id * @return TO-DO */ @PostMapping(\"/transfer\") @LRA(value = LRA.Type.REQUIRES_NEW, end = false) public ResponseEntity\u003cString\u003e transfer(@RequestParam(\"fromAccount\") long fromAccount, @RequestParam(\"toAccount\") long toAccount, @RequestParam(\"amount\") long amount, @RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { if (lraId == null) { return new ResponseEntity\u003c\u003e(\"Failed to create LRA\", HttpStatus.INTERNAL_SERVER_ERROR); } log.info(\"Started new LRA/transfer Id: \" + lraId); boolean isCompensate = false; String returnString = \"\"; // perform the withdrawal returnString += withdraw(lraId, fromAccount, amount); log.info(returnString); if (returnString.contains(\"succeeded\")) { // if it worked, perform the deposit returnString += \" \" + deposit(lraId, toAccount, amount); log.info(returnString); if (returnString.contains(\"failed\")) { isCompensate = true; // deposit failed } } else { isCompensate = true; // withdraw failed } log.info(\"LRA/transfer action will be \" + (isCompensate ? \"cancel\" : \"confirm\")); // call complete or cancel based on outcome of previous actions RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(TRANSFER_ID, lraId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( (isCompensate ? transferCancelUri : transferConfirmUri).toString(), request, String.class); returnString += response.getBody(); // return status return ResponseEntity.ok(\"transfer status:\" + returnString); } ``` Create a method to perform the withdrawal This method should perform the withdrawal by calling the Withdraw service in the Account Spring Boot application. The lraId, accountId and amount need to be passed to the service, and you must set the LRA_HTTP_CONTEXT_HEADER to the LRA ID.\n```java private String withdraw(String lraId, long accountId, long amount) { log.info(\"withdraw accountId = \" + accountId + \", amount = \" + amount); log.info(\"withdraw lraId = \" + lraId); UriComponentsBuilder builder = UriComponentsBuilder.fromUri(withdrawUri) .queryParam(\"accountId\", accountId) .queryParam(\"amount\", amount); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, lraId.toString()); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( builder.buildAndExpand().toUri(), request, String.class); return response.getBody(); } ``` Create a method to perform the deposit This method is similar the previous one, no new concepts are introduced here.\n```java private String deposit(String lraId, long accountId, long amount) { log.info(\"deposit accountId = \" + accountId + \", amount = \" + amount); log.info(\"deposit lraId = \" + lraId); UriComponentsBuilder builder = UriComponentsBuilder.fromUri(depositUri) .queryParam(\"accountId\", accountId) .queryParam(\"amount\", amount); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, lraId.toString()); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( builder.buildAndExpand().toUri(), request, String.class); return response.getBody(); } ``` Create a method to process the confirm action for this participant This participant does not need to take any actions for the confirm action, so just return a successful response.\n```java @PostMapping(\"/processconfirm\") @LRA(value = LRA.Type.MANDATORY) public ResponseEntity\u003cString\u003e processconfirm(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { log.info(\"Process confirm for transfer : \" + lraId); return ResponseEntity.ok(\"\"); } ``` Create a method to process the cancel action for this participant This participant does not need to take any actions for the cancel action, so just return a successful response.\n```java @PostMapping(\"/processcancel\") @LRA(value = LRA.Type.MANDATORY, cancelOn = HttpStatus.OK) public ResponseEntity\u003cString\u003e processcancel(@RequestHeader(LRA_HTTP_CONTEXT_HEADER) String lraId) { log.info(\"Process cancel for transfer : \" + lraId); return ResponseEntity.ok(\"\"); } ``` Create the confirm and cancel methods The logic demonstrated in these two methods would probably be in a client in a real-life LRA, but is included here for instructional purposes and convenience.\nThe transfer method makes a REST call to confirm (or cancel) at the end of its processing. The confirm or cancel method suspends the LRA (using the NOT_SUPPORTED value in the @LRA annotation). Then the confirm or cancel method will make a REST call to processconfirm or processcancel which import the LRA with their MANDATORY annotation and then implicitly end the LRA accordingly upon returning.\n```java /** * Confirm a transfer. * @param transferId Transfer Id * @return TO-DO */ @PostMapping(\"/confirm\") @Complete @LRA(value = LRA.Type.NOT_SUPPORTED) public ResponseEntity\u003cString\u003e confirm(@RequestHeader(TRANSFER_ID) String transferId) { log.info(\"Received confirm for transfer : \" + transferId); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, transferId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( transferProcessConfirmUri, request, String.class); return ResponseEntity.ok(response.getBody()); } /** * Cancel a transfer. * @param transferId Transfer Id * @return TO-DO */ @PostMapping(\"/cancel\") @Compensate @LRA(value = LRA.Type.NOT_SUPPORTED, cancelOn = HttpStatus.OK) public ResponseEntity\u003cString\u003e cancel(@RequestHeader(TRANSFER_ID) String transferId) { log.info(\"Received cancel for transfer : \" + transferId); RestTemplate restTemplate = new RestTemplate(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); headers.set(LRA_HTTP_CONTEXT_HEADER, transferId); HttpEntity\u003cString\u003e request = new HttpEntity\u003cString\u003e(\"\", headers); ResponseEntity\u003cString\u003e response = restTemplate.postForEntity( transferProcessCancelUri, request, String.class); return ResponseEntity.ok(response.getBody()); } ``` That completes the Transfer service and application.",
    "description": "Now, you will create another new Spring Boot microservice application and implement the Transfer Service. This service will initiate the LRA and act as the logical coordinator - it will call the deposit and withdraw services you just implemented to effect the transfer to process the Cloud Cash Payment.\nCreate a new Java Project for the transfer service. In the Explorer of VS Code open Java Project and click the plus sign to add a Java Project to your workspace.",
    "tags": [],
    "title": "Create the Transfer service",
    "uri": "/microservices-datadriven/cloudbank/saga/transfer-service/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "The Oracle Backend for Spring Boot and Microservices includes an Oracle Database. An instance of an Oracle Autonomous Database (Shared) is created during installation.\nTo access the database from a local machine you need to download the wallet and configure SQLcl to use the downloaded wallet.\nDownload the Wallet Login into the OCI Console. Oracle Cloud\nNavigate to Autonomous Transaction Processing.\nMake sure that you have the right compartment selected and click on the database name. The database name is composed by the application name you gave during install with the suffix of DB. In the picture below the Application Name is CBANK so the database name is CBANKDB. If you didn’t provide an Application name, the database will name will be a random pet name with the suffix DB in the compartment you deployed application.\nClick Database Connection to retrieve the Wallet.\nClick Download Wallet to download the Wallet.\nYou will need to provide a password for the Wallet. Make a note of where the wallet is located you’ll be needing it when connection to the Database.\nClose the Database Connection Dialog Box\nAccess the Database using SQLcl and the Wallet Obtain the ADMIN password\nTo get the ADMIN password for the database you need to read a k8s secret. Replace the cbankdb with the Database name for you deployment in the command below. The name is composed by the Application Name you gave during deployment with the suffix DB. If you didn’t provide an Application name, the database will name will be a random pet name with the suffix DB in the compartment you deployed application. Get the password using this command:\n$ kubectl -n application get secret cbankdb-db-secrets -o jsonpath='{.data.db\\.password}' | base64 -d Start SQLcl and connect to the Database:\nStart SQLcl using the following command:\n$ sql /nolog SQLcl: Release 22.4 Production on Fri Mar 03 10:33:33 2023 Copyright (c) 1982, 2023, Oracle. All rights reserved. SQL\u003eRun the following command to load the wallet. Make sure you use the right location and name of the wallet\nSQL\u003e set cloudconfig /path/to/wallet/wallet_name.zipDisplay the TNS Entries by executing the following command. The TNS Entries will be different for your deployment.\nSQL\u003e show tns CLOUD CONFIG set to: /path/to/wallet/wallet_name.zip TNS Lookup Locations -------------------- TNS Locations Used ------------------ 1. /path/to/wallet/wallet_name.zip 2. /Users/atael Available TNS Entries --------------------- CBANKDB_HIGH CBANKDB_LOW CBANKDB_MEDIUM CBANKDB_TP CBANKDB_TPURGENT SQL\u003eConnect to the Database using this command. Replace the ADMIN-PASSWORD with the password obtained from the k8s secret and replace TNS-ENTRY with your database name followed by _TP. In this example it would be CBANKDB_TP\nSQL\u003e connect ADMIN/ADMIN-PASSWORD@TNS-ENTRY Connected.You can now close the connection or leave it open as you are going to need it in later Labs.",
    "description": "The Oracle Backend for Spring Boot and Microservices includes an Oracle Database. An instance of an Oracle Autonomous Database (Shared) is created during installation.\nTo access the database from a local machine you need to download the wallet and configure SQLcl to use the downloaded wallet.\nDownload the Wallet Login into the OCI Console. Oracle Cloud\nNavigate to Autonomous Transaction Processing.\nMake sure that you have the right compartment selected and click on the database name.",
    "tags": [],
    "title": "Database Access",
    "uri": "/microservices-datadriven/cloudbank/devenv/db-access/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": " Prepare the data source configuration for deployment\nUpdate the data source configuration in your src/main/resources/application.yaml as shown in the example below. This will cause the service to read the correct database details that will be injected into its pod by the Oracle Backend for Spring Boot and Microservices.\ndatasource: url: ${spring.datasource.url} username: ${spring.datasource.username} password: ${spring.datasource.password} Add the client and configuration for the Spring Eureka Service Registry\nWhen you deploy the application to the backend, you want it to register with the Eureka Service Registry so that it can be discovered by other services including the APISIX API Gateway, so that we can easily expose it outside the cluster.\nAdd the following line to the \u003cproperties\u003e to the Maven POM file:\n\u003cspring-cloud.version\u003e2023.0.0\u003c/spring-cloud.version\u003eAdd the dependency for the client to the Maven POM file:\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003eAdd the dependency management to the Maven POM file:\n\u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003eAdd the @EnableDiscoveryClient annotation to the AccountsApplication class to enable the service registry.\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient; // .. @SpringBootApplication @EnableDiscoveryClient public class AccountsApplication { Add the configuration to src/main/resources/application.yaml file.\neureka: instance: hostname: ${spring.application.name} preferIpAddress: true client: service-url: defaultZone: ${eureka.service-url} fetch-registry: true register-with-eureka: true enabled: true Build a JAR file for deployment\nRun the following command to build the JAR file (it will also remove any earlier builds). Note that you will need to skip tests now, since you updated the application.yaml and it no longer points to your local test database instance.\n$ mvn clean package -DskipTestsThe service is now ready to deploy to the backend.\nPrepare the backend for deployment\nThe Oracle Backend for Spring Boot and Microservices admin service is not exposed outside the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command in a new terminal window:\n$ kubectl -n obaas-admin port-forward svc/obaas-admin 8080Get the password for the obaas-admin user. The obaas-admin user is the equivalent of the admin or root user in the Oracle Backend for Spring Boot and Microservices backend.\n$ kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -dStart the Oracle Backend for Spring Boot and Microservices CLI (oractl) in a new terminal window using this command:\n$ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003eConnect to the Oracle Backend for Spring Boot and Microservices admin service using the connect command. Enter obaas-admin and the username and use the password you collected earlier.\noractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003eCreate a database “binding” by tunning this command. Enter the password (Welcome1234##) when prompted. This will create a Kubernetes secret in the application namespace called account-db-secrets which contains the username (account), password, and URL to connect to the Oracle Autonomous Database instance associated with the Oracle Backend for Spring Boot and Microservices.\noractl:\u003e bind --app-name application --service-name account Database/Service Password: ************* Schema {account} was successfully Not_Modified and Kubernetes Secret {application/account} was successfully Created. oractl:\u003eThis created a Kubernetes secret with the credentials to access the database using this Spring Boot microservice application’s username and password. When you deploy the application, its pods will have the keys in this secret injected as environment variables so the application can use them to authenticate to the database.\nDeploy the account service\nYou will now deploy your account service to the Oracle Backend for Spring Boot and Microservices using the CLI. You will deploy into the application namespace, and the service name will be account. Run this command to deploy your service, make sure you provide the correct path to your JAR file. Note that this command may take 1-3 minutes to complete:\noractl:\u003e deploy --app-name application --service-name account --artifact-path /path/to/accounts-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: /Users/atael/tmp/cloudbank/accounts/target/accounts-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... obaas-cli [deploy]: Application was successfully deployed NOTICE: service not accessible outside K8S oractl:\u003e What happens when you use the Oracle Backend for Spring Boot and Microservices CLI (oractl) deploy command? When you run the deploy command, the Oracle Backend for Spring Boot and Microservices CLI does several things for you:\nUploads the JAR file to server side Builds a container image and push it to the OCI Registry Inspects the JAR file and looks for bind resources (JMS) Create the microservices deployment descriptor (k8s) with the resources supplied Applies the k8s deployment and create k8s object service to microservice Verify account service\nYou can check if the account service is running properly by running the following command:\n$ kubectl logs -n application svc/accountThe command will return the logfile content for the account service. If everything is running properly you should see something like this:\n2023-06-01 20:44:24.882 INFO 1 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path '' 2023-06-01 20:44:24.883 INFO 1 --- [ main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8080 2023-06-01 20:44:24.903 INFO 1 --- [ main] c.example.accounts.AccountsApplication : Started AccountsApplication in 14.6 seconds (JVM running for 15.713) 2023-06-01 20:44:31.971 INFO 1 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet' 2023-06-01 20:44:31.971 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet' 2023-06-01 20:44:31.975 INFO 1 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 4 ms Check the Eureka Server\nCreate a tunnel to the Eureka server, so you can verify the ACCOUNTS application has registered with the server.\n$ kubectl -n eureka port-forward svc/eureka 8761Open a web browser to Eureka Dashboard to vew the Eureka Server dashboard web user interface. It will look similar to this. Note that the ACCOUNT application you have built has registered with Eureka.\nTask 8: Expose the account service using the APISIX API Gateway Now that the account service is deployed, you need to expose it through the API Gateway so that clients will be able to access it. This is done by creating a “route” in APISIX Dashboard.\nRetrieve the admin password for the APISIX API Gateway.\nExecute the following command to get the password for the admin user for the APISIX API Gateway:\n$ kubectl get secret -n apisix apisix-dashboard -o jsonpath='{.data.conf\\.yaml}' | base64 -d | grep 'password:' Access the APISIX Dashboard\nThe APISIX Dashboard isn’t exposed outside the cluster. You need to start a tunnel to be able to access APISIX Dashboard. Start the tunnel using this command in a new terminal window:\n$ kubectl -n apisix port-forward svc/apisix-dashboard 8090:80Open a web browser to APISIX Dashboard to view the APISIX Dashboard web user interface. It will appear similar to the image below.\nIf prompted to login, login with username admin and the password you retrieved earlier. Note that Oracle strongly recommends that you change the password, even though this interface is not accessible outside the cluster without a tunnel.\nOpen the routes page from the left hand side menu. You will not have any routes yet.\nCreate the route\nClick on the Create button to start creating a route. The Create route page will appear. Enter account in the Name field:\nScroll down to the Request Basic Define section. Set the Path to /api/v1/account*. This tells APISIX API Gateway that any incoming request for that URL path (on any host or just IP address) should use this route. In the HTTP Method select GET, POST, DELETE, and OPTIONS. The first three you will recall using directly in the implementation of the account service during this lab. User interfaces and other clients will often send an OPTIONS request before a “real” request to see if the service exists and check headers and so on, so it is a good practice to allow OPTIONS as well.\nClick on the Next button to move to the Define API Backend Server page. On this page you configure where to route requests to. In the Upstream Type field, select Service Discovery. Then in the Discovery Type field, select Eureka. In the Service Name field enter ACCOUNT. This tells APISIX to lookup the service in Spring Eureka Service Registry with the key ACCOUNT and route requests to that service using a Round Robin algorithm to distribute requests.\nClick on Next to go to the Plugin Config page. You will not add any plugins right now. You may wish to browse through the list of available plugins on this page. When you are ready, click on Next to go to the Preview page. Check the details and then click on Submit to create the route.\nWhen you return to the route list page, you will see your new account route in the list now.\nVerify the account service\nIn the next two commands, you need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n$ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13dTest the create account endpoint with this command, use the IP address (EXTERNAL-IP in the table above) for your API Gateway:\n$ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"accountName\": \"Sanjay''s Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOtherDetails\": \"Savings Account\"}' \\ http://\u003cEXTERNAL-IP\u003e/api/v1/account HTTP/1.1 201 Date: Wed, 01 Mar 2023 18:35:31 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"accountId\":24,\"accountName\":\"Sanjays Savings\",\"accountType\":\"SA\",\"accountCustomerId\":\"bkzLp8cozi\",\"accountOpenedDate\":null,\"accountOtherDetails\":\"Savings Account\",\"accountBalance\":0}Test the get account endpoint with this command, use the IP address for your API Gateway and the accountId that was returned in the previous command:\n$ curl -s http://\u003cEXTERNAL-IP\u003e/api/v1/account/24 | jq . { \"accountId\": 24, \"accountName\": \"Sanjay's Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": null, \"accountOtherDetails\": \"Savings Account\", \"accountBalance\": 1040 }Your service is deployed in the Oracle Backend for Spring Boot and Microservices environment and using the Oracle Autonomous Database instance associated with the backend.\nLearn More Oracle Backend for Spring Boot and Microservices Kubernetes Apache APISIX Oracle Cloud Infrastructure Acknowledgements Author - Andy Tael, Mark Nelson, Developer Evangelists, Oracle Database Contributors - Last Updated By/Date - Andy Tael, July 2024 ",
    "description": "Prepare the data source configuration for deployment\nUpdate the data source configuration in your src/main/resources/application.yaml as shown in the example below. This will cause the service to read the correct database details that will be injected into its pod by the Oracle Backend for Spring Boot and Microservices.\ndatasource: url: ${spring.datasource.url} username: ${spring.datasource.username} password: ${spring.datasource.password} Add the client and configuration for the Spring Eureka Service Registry\nWhen you deploy the application to the backend, you want it to register with the Eureka Service Registry so that it can be discovered by other services including the APISIX API Gateway, so that we can easily expose it outside the cluster.",
    "tags": [],
    "title": "Deploy Account Service",
    "uri": "/microservices-datadriven/cloudbank/account/deploy/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Explore the Backend",
    "content": "Jaeger provides a way to view the distributed tracing information that is automatically collected by the backend. This allows you to follow requests from the entry point of the platform (the API Gateway) through any number of microservices, including database and messaging operations those services may perform.\nView a trace\nStart the tunnel using this command. You can run this in the background if you prefer.\n$ kubectl -n observability port-forward svc/jaegertracing-query 16686Open a web browser to http://localhost:16686 to view the Jaeger web user interface. It will appear similar to the image below.\nSelect one of the Cloudbank services for example account and an operation for example http get /api/v1/account/{account}. Click on the Find traces button to find a trace, open any one and explore the details.\nClick on one of the traces to explore the trace.",
    "description": "Jaeger provides a way to view the distributed tracing information that is automatically collected by the backend. This allows you to follow requests from the entry point of the platform (the API Gateway) through any number of microservices, including database and messaging operations those services may perform.\nView a trace\nStart the tunnel using this command. You can run this in the background if you prefer.\n$ kubectl -n observability port-forward svc/jaegertracing-query 16686Open a web browser to http://localhost:16686 to view the Jaeger web user interface.",
    "tags": [],
    "title": "Explore Jaeger",
    "uri": "/microservices-datadriven/cloudbank/backend/jaeger/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module will take you on a guided tour through the Oracle Backend for Spring Boot and Microservices platform. You will learn about the platform services and observability tools that are provided out-of-the-box.",
    "description": "This module will take you on a guided tour through the Oracle Backend for Spring Boot and Microservices platform. You will learn about the platform services and observability tools that are provided out-of-the-box.",
    "tags": [],
    "title": "Explore the Backend",
    "uri": "/microservices-datadriven/cloudbank/backend/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "This module demonstrates how to clean up any resources created when you provisioned an instance of Oracle Backend for Spring Boot and Microservices on Oracle Cloud Infrastructure (OCI) or on your local machine in containers.",
    "description": "This module demonstrates how to clean up any resources created when you provisioned an instance of Oracle Backend for Spring Boot and Microservices on Oracle Cloud Infrastructure (OCI) or on your local machine in containers.",
    "tags": [],
    "title": "Cleanup",
    "uri": "/microservices-datadriven/cloudbank/cleanup/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "The services are now completed, and you are ready to deploy them to the Oracle Backend for Spring Boot and Microservices.\nNote: You already created the Kubernetes secrets necessary for the account service to access the Oracle Autonomous Database in a previous module, and the transfer service does not need access to the database. You also created the journal table that is needed by the update account application in the previous module.\nBuild the Account and Transfer applications into JAR files To build a JAR file from the Account application, issue this command in the account directory. Then issue the same command from the transfer directory to build the Transfer application into a JAR file too.\n```shell $ mvn clean package -DskipTests ``` You will now have a JAR file for each application, as can be seen with this command (the command needs to be executed in the parent directory for the Account and Transfer applications):\n```shell $ find . -name \\*SNAPSHOT.jar ./testrunner/target/testrunner-0.0.1-SNAPSHOT.jar ./checks/target/checks-0.0.1-SNAPSHOT.jar ./transfer/target/transfer-0.0.1-SNAPSHOT.jar ./accounts/target/accounts-0.0.1-SNAPSHOT.jar ``` Deploy the Account and Transfer applications You will now deploy your updated account application and new transfer application to the Oracle Backend for Spring Boot and Microservices using the CLI. You will deploy into the application namespace, and the service names will be account and transfer respectively.\nThe Oracle Backend for Spring Boot and Microservices admin service is not exposed outside of the Kubernetes cluster by default. Oracle recommends using a kubectl port forwarding tunnel to establish a secure connection to the admin service.\nStart a tunnel using this command:\n```shell $ kubectl -n obaas-admin port-forward svc/obaas-admin 8080:8080 ``` Start the Oracle Backend for Spring Boot and Microservices CLI (oractl) in the parent directory using this command:\n```shell $ oractl _ _ __ _ ___ / \\ |_) _. _. (_ / | | \\_/ |_) (_| (_| __) \\_ |_ _|_ ======================================================================================== Application Name: Oracle Backend Platform :: Command Line Interface Application Version: (1.2.0) :: Spring Boot (v3.3.0) :: Ask for help: - Slack: https://oracledevs.slack.com/archives/C03ALDSV272 - email: obaas_ww@oracle.com oractl:\u003e ``` Obtain the obaas-admin password by executing this command:\n```shell kubectl get secret -n azn-server oractl-passwords -o jsonpath='{.data.admin}' | base64 -d ``` Connect to the Oracle Backend for Spring Boot and Microservices admin service using this command. Use obaas-admin as the username and the password you obtained in the previous step.\n```shell oractl\u003e connect username: obaas-admin password: ************** Credentials successfully authenticated! obaas-admin -\u003e welcome to OBaaS CLI. oractl:\u003e ``` Run this command to deploy your account service, make sure you provide the correct path to your JAR files.\n```shell oractl:\u003e deploy --app-name application --service-name account --artifact-path /path/to/accounts-0.0.1-SNAPSHOT.jar --image-version 0.0.1 --liquibase-db admin uploading: account/target/accounts-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` Run this command to deploy the transfer service, make sure you provide the correct path to your JAR files.\n```shell oractl:\u003e deploy --app-name application --service-name transfer --artifact-path /path/to/transfer-0.0.1-SNAPSHOT.jar --image-version 0.0.1 uploading: transfer/target/transfer-0.0.1-SNAPSHOT.jar building and pushing image... creating deployment and service... successfully deployed oractl:\u003e ``` Your applications are now deployed in the backend.",
    "description": "The services are now completed, and you are ready to deploy them to the Oracle Backend for Spring Boot and Microservices.\nNote: You already created the Kubernetes secrets necessary for the account service to access the Oracle Autonomous Database in a previous module, and the transfer service does not need access to the database. You also created the journal table that is needed by the update account application in the previous module.",
    "tags": [],
    "title": "Deploy services",
    "uri": "/microservices-datadriven/cloudbank/saga/deploy/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Account Microservice",
    "content": "Now that the account service is deployed, you need to expose it through the API Gateway so that clients will be able to access it. This is done by creating a “route” in APISIX Dashboard.\nRetrieve the admin password for the APISIX API Gateway.\nExecute the following command to get the password for the admin user for the APISIX API Gateway:\n$ kubectl get secret -n apisix apisix-dashboard -o jsonpath='{.data.conf\\.yaml}' | base64 -d | grep 'password:' Access the APISIX Dashboard\nThe APISIX Dashboard isn’t exposed outside the cluster. You need to start a tunnel to be able to access APISIX Dashboard. Start the tunnel using this command in a new terminal window:\n$ kubectl -n apisix port-forward svc/apisix-dashboard 8090:80Open a web browser to APISIX Dashboard to view the APISIX Dashboard web user interface. It will appear similar to the image below.\nIf prompted to login, login with username admin and the password you retrieved earlier. Note that Oracle strongly recommends that you change the password, even though this interface is not accessible outside the cluster without a tunnel.\nOpen the routes page from the left hand side menu. You will not have any routes yet.\nCreate the route\nClick on the Create button to start creating a route. The Create route page will appear. Enter account in the Name field:\nScroll down to the Request Basic Define section. Set the Path to /api/v1/account*. This tells APISIX API Gateway that any incoming request for that URL path (on any host or just IP address) should use this route. In the HTTP Method select GET, POST, DELETE, and OPTIONS. The first three you will recall using directly in the implementation of the account service during this lab. User interfaces and other clients will often send an OPTIONS request before a “real” request to see if the service exists and check headers and so on, so it is a good practice to allow OPTIONS as well.\nClick on the Next button to move to the Define API Backend Server page. On this page you configure where to route requests to. In the Upstream Type field, select Service Discovery. Then in the Discovery Type field, select Eureka. In the Service Name field enter ACCOUNT. This tells APISIX to lookup the service in Spring Eureka Service Registry with the key ACCOUNT and route requests to that service using a Round Robin algorithm to distribute requests.\nClick on Next to go to the Plugin Config page. You will not add any plugins right now. You may wish to browse through the list of available plugins on this page. When you are ready, click on Next to go to the Preview page. Check the details and then click on Submit to create the route.\nWhen you return to the route list page, you will see your new account route in the list now.\nVerify the account service\nIn the next two commands, you need to provide the correct IP address for the API Gateway in your backend environment. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n$ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13dTest the create account endpoint with this command, use the IP address (EXTERNAL-IP in the table above) for your API Gateway:\n$ curl -i -X POST \\ -H 'Content-Type: application/json' \\ -d '{\"accountName\": \"Sanjay''s Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOtherDetails\": \"Savings Account\"}' \\ http://\u003cEXTERNAL-IP\u003e/api/v1/account HTTP/1.1 201 Date: Wed, 01 Mar 2023 18:35:31 GMT Content-Type: application/json Transfer-Encoding: chunked Connection: keep-alive {\"accountId\":24,\"accountName\":\"Sanjays Savings\",\"accountType\":\"SA\",\"accountCustomerId\":\"bkzLp8cozi\",\"accountOpenedDate\":null,\"accountOtherDetails\":\"Savings Account\",\"accountBalance\":0}Test the get account endpoint with this command, use the IP address for your API Gateway and the accountId that was returned in the previous command:\n$ curl -s http://\u003cEXTERNAL-IP\u003e/api/v1/account/24 | jq . { \"accountId\": 24, \"accountName\": \"Sanjay's Savings\", \"accountType\": \"SA\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": null, \"accountOtherDetails\": \"Savings Account\", \"accountBalance\": 1040 }Your service is deployed in the Oracle Backend for Spring Boot and Microservices environment and using the Oracle Autonomous Database instance associated with the backend.",
    "description": "Now that the account service is deployed, you need to expose it through the API Gateway so that clients will be able to access it. This is done by creating a “route” in APISIX Dashboard.\nRetrieve the admin password for the APISIX API Gateway.\nExecute the following command to get the password for the admin user for the APISIX API Gateway:\n$ kubectl get secret -n apisix apisix-dashboard -o jsonpath='{.data.conf\\.yaml}' | base64 -d | grep 'password:' Access the APISIX Dashboard",
    "tags": [],
    "title": "Expose using APISIX",
    "uri": "/microservices-datadriven/cloudbank/account/expose/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Developer Environment",
    "content": "Some modules contain optional parts which show you how to do deployments and configuration with the IDE plugins instead of using the CLI. If you plan to do those optional parts, you need to install the VS Code extension forOracle Backend for Spring Boot and Microservices. It is an extension to browse and deploy applications on the Oracle Backend for Spring Boot and Microservices platform. This plugin allows to inspect the content of an Oracle Backend for Spring Boot and Microservices deployment, in terms of applications, services and related configurations.\nDownload the plug-in from here.\nOn the VS Code right menu bar, click on Extensions item:\nFrom the up-right corner menu, choose Install from VSIX…:\nand upload plug-in binaries previously downloaded.\nRe-start VS Code to make fully operative the plugin, in command palette execute a window reload:\nIf you don’t see the plugin in the left bar, with the Oracle logo, as shown here:\nclick on Additional Views menu to select the Oracle Backend for Spring Boot and Microservices.",
    "description": "Some modules contain optional parts which show you how to do deployments and configuration with the IDE plugins instead of using the CLI. If you plan to do those optional parts, you need to install the VS Code extension forOracle Backend for Spring Boot and Microservices. It is an extension to browse and deploy applications on the Oracle Backend for Spring Boot and Microservices platform. This plugin allows to inspect the content of an Oracle Backend for Spring Boot and Microservices deployment, in terms of applications, services and related configurations.",
    "tags": [],
    "title": "Install IDE Plugin",
    "uri": "/microservices-datadriven/cloudbank/devenv/ide-plugin/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e Manage Sagas",
    "content": "Now you can test your LRA to verify it performs correctly under various circumstances.\nStart a tunnel to access the transfer service Since the transfer service is not exposed outside the Kubernetes cluster, you will need to start a kubectl port forwarding tunnel to access its endpoints.\n\u003e **Note**: If you prefer, you can create a route in the APISIX API Gateway to expose the service. The service will normally only be invoked from within the cluster, so you did not create a route for it. However, you have learned how to create routes, so you may do that if you prefer. Run this command to start the tunnel: ```shell $ kubectl -n application port-forward svc/transfer 7000:8080 ``` Now the transfer service will be accessible at http://localhost:7000/api/v1/transfer.\nCheck the starting account balances In several of the next few commands, you need to provide the correct IP address for the API Gateway in your backend environment. Not the ones that use localhost, just those where the example uses 100.20.30.40 as the address. You can find the IP address using this command, you need the one listed in the EXTERNAL-IP column:\n```shell $ kubectl -n ingress-nginx get service ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.123.10.127 100.20.30.40 80:30389/TCP,443:30458/TCP 13d ``` Before you start, check the balances of the two accounts that you will be transferring money between using this command (make sure you are using the EXTERNAL-IP of your environment). Note that these accounts were created in an earlier step.\n```shell $ curl -s http://100.20.30.40/api/v1/account/1 | jq ; curl -s http://100.20.30.40/api/v1/account/2 | jq { \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"abcDe7ged\", \"accountOpenedDate\": \"2023-03-06T13:56:43.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": -20 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-03-06T13:56:44.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 1000 } ``` Note that account 1 has -$20 in this example, and account 2 has $1,000. Your results may be different.\nPerform a transfer that should succeed Run this command to perform a transfer that should succeed. Note that both accounts exist and the amount of the transfer is less than the balance of the source account.\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=1\u0026amount=100\" transfer status:withdraw succeeded deposit succeeded ``` Check the two accounts again to confirm the transfer behaved as expected:\n```shell $ curl -s http://100.20.30.40/api/v1/account/1 | jq ; curl -s http://100.20.30.40/api/v1/account/2 | jq { \"accountId\": 1, \"accountName\": \"Andy's checking\", \"accountType\": \"CH\", \"accountCustomerId\": \"abcDe7ged\", \"accountOpenedDate\": \"2023-03-06T13:56:43.000+00:00\", \"accountOtherDetails\": \"Account Info\", \"accountBalance\": 80 } { \"accountId\": 2, \"accountName\": \"Mark's CCard\", \"accountType\": \"CC\", \"accountCustomerId\": \"bkzLp8cozi\", \"accountOpenedDate\": \"2023-03-06T13:56:44.000+00:00\", \"accountOtherDetails\": \"Mastercard account\", \"accountBalance\": 900 } ``` Notice that account 2 now has only $900 and account 1 has $80. So the $100 was successfully transferred as expected.\nPerform a transfer that should fail due to insufficient funds in the source account Run this command to attempt to transfer $100,000 from account 2 to account 1. This should fail because account 2 does not have enough funds.\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=1\u0026amount=100000\" transfer status:withdraw failed: insufficient funds ``` Perform a transfer that should fail due to the destination account not existing. Execute the following command to perform a failed transfer:\n```shell $ curl -X POST \"http://localhost:7000/transfer?fromAccount=2\u0026toAccount=6799999\u0026amount=100\" transfer status:withdraw succeeded deposit failed: account does not exist% ``` Access the applications logs to verify what happened in each case Access the Transfer application log with this command. Your output will be different:\n```shell $ kubectl -n application logs svc/transfer 2023-03-04 21:52:12.421 INFO 1 --- [nio-8080-exec-3] TransferService : Started new LRA/transfer Id: http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.422 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw accountId = 2, amount = 100 2023-03-04 21:52:12.426 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw lraId = http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.615 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw succeeded 2023-03-04 21:52:12.616 INFO 1 --- [nio-8080-exec-3] TransferService : deposit accountId = 6799999, amount = 100 2023-03-04 21:52:12.619 INFO 1 --- [nio-8080-exec-3] TransferService : deposit lraId = http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.726 INFO 1 --- [nio-8080-exec-3] TransferService : withdraw succeeded deposit failed: account does not exist 2023-03-04 21:52:12.726 INFO 1 --- [nio-8080-exec-3] TransferService : LRA/transfer action will be cancel 2023-03-04 21:52:12.757 INFO 1 --- [nio-8080-exec-1] TransferService : Received cancel for transfer : http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 2023-03-04 21:52:12.817 INFO 1 --- [nio-8080-exec-2] TransferService : Process cancel for transfer : http://otmm-tcs.otmm.svc.cluster.local:9000/api/v1/lra-coordinator/18a093ef-beb6-4065-bb6c-b9328c8bb3e5 ``` In the example output above you can see one what happened during that last test you ran a moment ago. Notice that the LRA started, the withdrawal succeeded, then the deposit failed because the account did not exist. Then you can see that the next action is cancel, and then the LRA being canceled/compensated.\nIn this module you have learned about the Saga pattern by implementing an account transfer scenarios. You did this by implementing the long running activity, including transfer and account services that connect to a coordinator, according to the Long Running Action specification.",
    "description": "Now you can test your LRA to verify it performs correctly under various circumstances.\nStart a tunnel to access the transfer service Since the transfer service is not exposed outside the Kubernetes cluster, you will need to start a kubectl port forwarding tunnel to access its endpoints.\n\u003e **Note**: If you prefer, you can create a route in the APISIX API Gateway to expose the service. The service will normally only be invoked from within the cluster, so you did not create a route for it.",
    "tags": [],
    "title": "Run LRA test cases",
    "uri": "/microservices-datadriven/cloudbank/saga/test/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/microservices-datadriven/cloudbank/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Welcome to CloudBank - an on-demand, self-paced learning resource you can use to learn about developing microservices with Spring Boot and deploying, running and managing them with Oracle Backend for Spring Boot and Microservices.\nYou can follow through from beginning to end, or you can start at any module that you are interested in.\nWhat you will need To complete the modules you will somewhere to run Oracle Backend for Spring Boot and Microservices. The instructions in the Module 1 provide three alternatives:\nLocally in a container - you will need a container platform like Docker Desktop, Rancher Desktop, Podman Desktop or similar. This option is recommended only if you have at least 64GB of RAM. With less memory this option will probably be too slow. In a compute instance in an Oracle Cloud Free Tier account. You can sign up for an Oracle Cloud Free Tier account here. This account will include enough free credits to run CloudBank. In a commercial Oracle Cloud tenancy. If you have a commercial tenancy with sufficient capacity and privileges, you can run the full production-sized installation. This can be installed from the OCI Marketplace using the instructions in Module 1. Check the instructions for a more detailed list of requirements. Regardless of which option you choose, the remainder of the modules will be virtually identical.\nYou will need a Java SDK and either Maven or Gradle to build your applicaitons. An IDE is not strictly required, but you will have a better overall experience if you use one. We recommend Visual Studio Code or IntelliJ.\nModules CloudBank contains the following modules:\nModule 1: Provision the Backend This module guides you through provisioning an instance of the backend using Oracle Cloud Infrastructure (OCI) or on your local machine using Docker Compose. Module 2: Preparing your Development Environment\nThis module guides you through setting up your development environment including and IDE and a toolchain to build and test your applications. Module 3: Build the Account Microservice\nThis module walks you through building your very first microservice using Spring Boot. It assumes no prior knowledge of Spring Boot, so its a great place to start if you have not used Spring Boot before. This module demonstrates how to build a service with a synchronous API implemented as REST endpoints using Spring Web MVC, and how to store data in Oracle Database using Spring Data JPA. Module 4: Build the Check Processing Microservices\nIn this module, you will build microservices that use asynchronous messaging to communicate using Spring JMS and Oracle Transactional Event Queues. It introduces service discovery using Eureka Service Registry (part of Spring Cloud Netflix) and Spring Cloud OpenFeign. Module 5: Manage Saga Transactions across Microservices\nThis module introduces the Saga pattern, a very important pattern that helps us manage data consistency across microservices. We will explore the Long Running Action specification, one implementation of the Saga pattern, and then build a Transfer microservice that will manage funds transfers using a saga. Module 6: Building the CloudBank AI Assistant using Spring AI This modules introduces Spring AI and explores how it can be used to build a CloudBank AI Assistant (chatbot) that will allow users to interact with CloudBank using a chat-based interface. In this module, you will learn about Retrieval Augmented Generation, Vector Database and AI Agents. Module 7: Deploying the full CloudBank Application using the CLI\nIn this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using the CLI. If you prefer to use an IDE, skip this module and go to module 6 instead. Module 8: Deploying the full CloudBank Application using the IDE plugins\nIn this module, you will learn how to deploy the full CloudBank application to Oracle Backend for Spring Boot and Microservices using one of the IDE plugins - for Visual Studio Code or IntelliJ. Module 9: Explore the Backend Platform\nThis module will take you on a guided tour through the Oracle Backend for Spring Boot and Microservices platform. You will learn about the platform services and observability tools that are provided out-of-the-box. Module 10: Cleanup This module demonstrates how to clean up any resources created when you provisioned an instance of Oracle Backend for Spring Boot and Microservices on Oracle Cloud Infrastructure (OCI) or on your local machine using Docker Compose. ",
    "description": "Welcome to CloudBank - an on-demand, self-paced learning resource you can use to learn about developing microservices with Spring Boot and deploying, running and managing them with Oracle Backend for Spring Boot and Microservices.\nYou can follow through from beginning to end, or you can start at any module that you are interested in.\nWhat you will need To complete the modules you will somewhere to run Oracle Backend for Spring Boot and Microservices.",
    "tags": [],
    "title": "CloudBank",
    "uri": "/microservices-datadriven/cloudbank/index.html"
  },
  {
    "breadcrumb": "CloudBank \u003e ",
    "content": "Contributors Thank you to the following contributors (listed in alphabetical order):\nCorrado De Bari, Developer Evangelist, Oracle Database Doug Drechsel, Developer Evangelist, Oracle Database John Lathouwers, Developer Evangelist, Oracle Database Mark Nelson, Developer Evangelist, Oracle Database Paul Parkinson, Developer Evangelist, Oracle Database Paulo Simoes, Developer Evangelist, Oracle Database Andy Tael, Developer Evangelist, Oracle Database ",
    "description": "Contributors Thank you to the following contributors (listed in alphabetical order):\nCorrado De Bari, Developer Evangelist, Oracle Database Doug Drechsel, Developer Evangelist, Oracle Database John Lathouwers, Developer Evangelist, Oracle Database Mark Nelson, Developer Evangelist, Oracle Database Paul Parkinson, Developer Evangelist, Oracle Database Paulo Simoes, Developer Evangelist, Oracle Database Andy Tael, Developer Evangelist, Oracle Database ",
    "tags": [],
    "title": "Credits",
    "uri": "/microservices-datadriven/cloudbank/more/credits/index.html"
  },
  {
    "breadcrumb": "CloudBank",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/microservices-datadriven/cloudbank/tags/index.html"
  }
]
