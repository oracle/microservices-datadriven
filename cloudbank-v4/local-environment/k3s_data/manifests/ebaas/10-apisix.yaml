apiVersion: v1
kind: Namespace
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-dashboard
  namespace: apisix
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: serviceaccount-apisix
  namespace: apisix
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-clusterrole
  namespace: apisix
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-clusterrolebinding
  namespace: apisix
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: apisix-clusterrole
subjects:
- kind: ServiceAccount
  name: serviceaccount-apisix
  namespace: apisix
---
apiVersion: v1
data:
  config.yaml: |-
    #
    # Licensed to the Apache Software Foundation (ASF) under one or more
    # contributor license agreements.  See the NOTICE file distributed with
    # this work for additional information regarding copyright ownership.
    # The ASF licenses this file to You under the Apache License, Version 2.0
    # (the "License"); you may not use this file except in compliance with
    # the License.  You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    #
    apisix:    # universal configurations
      node_listen:    # APISIX listening port
        - 9080
      enable_heartbeat: true
      enable_admin: true
      enable_admin_cors: true
      enable_debug: false

      enable_dev_mode: false                       # Sets nginx worker_processes to 1 if set to true
      enable_reuseport: true                       # Enable nginx SO_REUSEPORT switch if set to true.
      enable_ipv6: true # Enable nginx IPv6 resolver
      enable_http2: true
      enable_server_tokens: true # Whether the APISIX version number should be shown in Server header

      # proxy_protocol:                   # Proxy Protocol configuration
      #   listen_http_port: 9181          # The port with proxy protocol for http, it differs from node_listen and admin_listen.
      #                                   # This port can only receive http request with proxy protocol, but node_listen & admin_listen
      #                                   # can only receive http request. If you enable proxy protocol, you must use this port to
      #                                   # receive http request with proxy protocol
      #   listen_https_port: 9182         # The port with proxy protocol for https
      #   enable_tcp_pp: true             # Enable the proxy protocol for tcp proxy, it works for stream_proxy.tcp option
      #   enable_tcp_pp_to_upstream: true # Enables the proxy protocol to the upstream server

      proxy_cache:                         # Proxy Caching configuration
        cache_ttl: 10s                     # The default caching time if the upstream does not specify the cache time
        zones:                             # The parameters of a cache
        - name: disk_cache_one             # The name of the cache, administrator can be specify
                                           # which cache to use by name in the admin api
          memory_size: 50m                 # The size of shared memory, it's used to store the cache index
          disk_size: 1G                    # The size of disk, it's used to store the cache data
          disk_path: "/tmp/disk_cache_one" # The path to store the cache data
          cache_levels: "1:2"              # The hierarchy levels of a cache
      #  - name: disk_cache_two
      #    memory_size: 50m
      #    disk_size: 1G
      #    disk_path: "/tmp/disk_cache_two"
      #    cache_levels: "1:2"

      router:
        http: radixtree_uri  # radixtree_uri: match route by uri(base on radixtree)
                                    # radixtree_host_uri: match route by host + uri(base on radixtree)
                                    # radixtree_uri_with_parameter: match route by uri with parameters
        ssl: 'radixtree_sni'        # radixtree_sni: match route by SNI(base on radixtree)

      proxy_mode: http
      # dns_resolver:
      #
      #   - 127.0.0.1
      #
      #   - 172.20.0.10
      #
      #   - 114.114.114.114
      #
      #   - 223.5.5.5
      #
      #   - 1.1.1.1
      #
      #   - 8.8.8.8
      #
      dns_resolver_valid: 30
      resolver_timeout: 5
      ssl:
        enable: false
        listen:
          - port: 9443
            enable_http3: false
        ssl_protocols: "TLSv1.2 TLSv1.3"
        ssl_ciphers: "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA"

    nginx_config:    # config for render the template to genarate nginx.conf
      error_log: "/dev/stderr"
      error_log_level: "warn"    # warn,error
      worker_processes: "auto"
      enable_cpu_affinity: true
      worker_rlimit_nofile: 20480  # the number of files a worker process can open, should be larger than worker_connections
      event:
        worker_connections: 10620
      http:
        enable_access_log: true
        access_log: "/dev/stdout"
        access_log_format: '$remote_addr - $remote_user [$time_local] $http_host \"$request\" $status $body_bytes_sent $request_time \"$http_referer\" \"$http_user_agent\" $upstream_addr $upstream_status $upstream_response_time \"$upstream_scheme://$upstream_host$upstream_uri\"'
        access_log_format_escape: default
        keepalive_timeout: "60s"
        client_header_timeout: 60s     # timeout for reading client request header, then 408 (Request Time-out) error is returned to the client
        client_body_timeout: 60s       # timeout for reading client request body, then 408 (Request Time-out) error is returned to the client
        send_timeout: 10s              # timeout for transmitting a response to the client.then the connection is closed
        underscores_in_headers: "on"   # default enables the use of underscores in client request header fields
        real_ip_header: "X-Real-IP"    # http://nginx.org/en/docs/http/ngx_http_realip_module.html#real_ip_header
        real_ip_from:                  # http://nginx.org/en/docs/http/ngx_http_realip_module.html#set_real_ip_from
          - 127.0.0.1
          - 'unix:'
    discovery:
      eureka:
        fetch_interval: 30
        host:
        - http://eureka.eureka.svc.cluster.local:8761
        prefix: /eureka/
        timeout:
          connect: 2000
          read: 5000
          send: 2000
        weight: 100
      kubernetes:
        client:
          token_file: /run/secrets/kubernetes.io/serviceaccount/token
        service:
          host: ${KUBERNETES_SERVICE_HOST}
          port: ${KUBERNETES_SERVICE_PORT}
          schema: https
    plugins:    # plugin list
      - api-breaker
      - authz-keycloak
      - basic-auth
      - batch-requests
      - consumer-restriction
      - cors
      - echo
      - fault-injection
      - file-logger
      - grpc-transcode
      - hmac-auth
      - http-logger
      - ip-restriction
      - ua-restriction
      - jwt-auth
      - kafka-logger
      - key-auth
      - limit-conn
      - limit-count
      - limit-req
      - node-status
      - openid-connect
      - opentelemetry
      - authz-casbin
      - prometheus
      - proxy-cache
      - proxy-mirror
      - proxy-rewrite
      - redirect
      - referer-restriction
      - request-id
      - request-validation
      - response-rewrite
      - server-info
      - serverless-post-function
      - serverless-pre-function
      - sls-logger
      - syslog
      - tcp-logger
      - udp-logger
      - uri-blocker
      - wolf-rbac
      - zipkin
      - traffic-split
      - gzip
      - real-ip
      - ext-plugin-pre-req
      - ext-plugin-post-req
    stream_plugins:
      - mqtt-proxy
      - ip-restriction
      - limit-conn
    plugin_attr:
      opentelemetry:
        collector:
          address: http://open-telemetry-opentelemetry-collector.open-telemetry:4318
          request-timeout: 3
        resource:
          service.name: APISIX
        trace_id_source: x-request-id
      prometheus:
        export_addr:
          ip: 0.0.0.0
          port: 9091
        export_uri: /apisix/prometheus/metrics
        metric_prefix: apisix_
      server-info:
        report_ttl: 60

    deployment:
      role: traditional
      role_traditional:
        config_provider: etcd
      admin:
        allow_admin:    # http://nginx.org/en/docs/http/ngx_http_access_module.html#allow
          - 0.0.0.0/0
        #   - "::/64"
        admin_listen:
          ip: 0.0.0.0
          port: 9180
        # Default token when use API to call for Admin API.
        # *NOTE*: Highly recommended to modify this value to protect APISIX's Admin API.
        # Disabling this configuration item means that the Admin API does not
        # require any authentication.
        admin_key:
          # admin: can everything for configuration data
          - name: "admin"
            key: czUH5aRbHVhgapz9WkeJHKGU2DQKbIJVpxTyHq6i0Uln
            role: admin
          # viewer: only can view configuration data
          - name: "viewer"
            key: xP57IHTwojpDnqJAjF4G6U4sbSw4jnMQYYodm70D3Nlf
            role: viewer
      etcd:
        host:                          # it's possible to define multiple etcd hosts addresses of the same etcd cluster.
          - "http://apisix-etcd.apisix.svc.cluster.local:2379"
        prefix: "/apisix"    # configuration prefix in etcd
        timeout: 30    # 30 seconds
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix
  namespace: apisix
---
apiVersion: v1
data:
  url: http://eureka-0.eureka.eureka.svc.cluster.local:8761/eureka
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: eureka-server
  namespace: apisix
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-dashboard
  namespace: apisix
stringData:
  conf.yaml: |-
    conf:
      listen:
        host: 0.0.0.0
        port: 9000
      etcd:
        prefix: "/apisix"
        endpoints:
          - apisix-etcd:2379
      log:
        error_log:
          level: warn
          file_path: /dev/stderr
        access_log:
          file_path: /dev/stdout
    authentication:
      secret: dashboard-token
      expire_time: 3600
      users:
        - username: admin
          password: "Welcome-12345"
---
apiVersion: v1
data:
  jwt-token.pem: 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
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: etcd-9.7.3
    oracle/edition: 'COMMUNITY'
  name: apisix-etcd-jwt-token
  namespace: apisix
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/service: apisix-admin
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-admin
  namespace: apisix
spec:
  ports:
  - name: apisix-admin
    port: 9180
    protocol: TCP
    targetPort: 9180
  selector:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: apisix
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: dashboard
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-dashboard
  namespace: apisix
spec:
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: http
  selector:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: dashboard
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: etcd-9.7.3
    oracle/edition: 'COMMUNITY'
  name: apisix-etcd
  namespace: apisix
spec:
  ports:
  - name: client
    nodePort: null
    port: 2379
    targetPort: client
  - name: peer
    nodePort: null
    port: 2380
    targetPort: peer
  selector:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: etcd
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  labels:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: etcd-9.7.3
    oracle/edition: 'COMMUNITY'
  name: apisix-etcd-headless
  namespace: apisix
spec:
  clusterIP: None
  ports:
  - name: client
    port: 2379
    targetPort: client
  - name: peer
    port: 2380
    targetPort: peer
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: etcd
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/service: apisix-gateway
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-gateway
  namespace: apisix
spec:
  externalTrafficPolicy: Cluster
  ports:
  - name: apisix-gateway
    port: 80
    protocol: TCP
    targetPort: 9080
  selector:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: apisix
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/service: apisix-prometheus-metrics
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-prometheus-metrics
  namespace: apisix
spec:
  ports:
  - name: prometheus
    port: 9091
    protocol: TCP
    targetPort: 9091
  selector:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: apisix
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix
  namespace: apisix
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: apisix
      app.kubernetes.io/name: apisix
  template:
    metadata:
      annotations:
        checksum/config: f5847d272527195333f53c4f4204f65e5ec482652bc2efb2134b3aa4fb1c9b28
      labels:
        app.kubernetes.io/instance: apisix
        app.kubernetes.io/name: apisix
    spec:
      containers:
      - image: docker.io/apache/apisix:3.9.1-debian
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 30
        name: apisix
        ports:
        - containerPort: 9080
          name: http
          protocol: TCP
        - containerPort: 9443
          name: tls
          protocol: TCP
        - containerPort: 9180
          name: admin
          protocol: TCP
        - containerPort: 9091
          name: prometheus
          protocol: TCP
        readinessProbe:
          failureThreshold: 6
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 9080
          timeoutSeconds: 1
        resources:
          limits:
            cpu: 100m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - mountPath: /usr/local/apisix/conf/config.yaml
          name: apisix-config
          subPath: config.yaml
      hostNetwork: false
      initContainers:
      - command:
        - sh
        - -c
        - until nc -z apisix-etcd.apisix.svc.cluster.local 2379; do echo waiting for
          etcd `date`; sleep 2; done;
        image: docker.io/busybox:1.36
        name: wait-etcd
      serviceAccountName: serviceaccount-apisix
      volumes:
      - configMap:
          name: apisix
        name: apisix-config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "2"
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/name: dashboard
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix-dashboard
  namespace: apisix
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: apisix
      app.kubernetes.io/name: dashboard
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: apisix
        app.kubernetes.io/name: dashboard
    spec:
      containers:
      - image: docker.io/apache/apisix-dashboard:3.0.0-alpine
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: http
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: dashboard
        ports:
        - containerPort: 9000
          name: http
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: http
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /usr/local/apisix-dashboard/conf/conf.yaml
          name: apisix-dashboard-config
          subPath: conf.yaml
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      serviceAccount: apisix-dashboard
      serviceAccountName: apisix-dashboard
      terminationGracePeriodSeconds: 30
      volumes:
      - name: apisix-dashboard-config
        secret:
          defaultMode: 420
          secretName: apisix-dashboard
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: etcd-9.7.3
    oracle/edition: 'COMMUNITY'
  name: apisix-etcd
  namespace: apisix
spec:
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/component: etcd
      app.kubernetes.io/instance: apisix
      app.kubernetes.io/name: etcd
  serviceName: apisix-etcd-headless
  template:
    metadata:
      annotations:
        checksum/token-secret: 68aeb1839cdf9a27e9e206bb1d628d50cfece5d72c56f0880cf416127642d494
      labels:
        app.kubernetes.io/component: etcd
        app.kubernetes.io/instance: apisix
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: etcd
        app.kubernetes.io/version: 3.5.10
        helm.sh/chart: etcd-9.7.3
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: etcd
                  app.kubernetes.io/instance: apisix
                  app.kubernetes.io/name: etcd
              topologyKey: kubernetes.io/hostname
            weight: 1
      containers:
      - env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: MY_STS_NAME
          value: apisix-etcd
        - name: ETCDCTL_API
          value: "3"
        - name: ETCD_ON_K8S
          value: "yes"
        - name: ETCD_START_FROM_SNAPSHOT
          value: "no"
        - name: ETCD_DISASTER_RECOVERY
          value: "no"
        - name: ETCD_NAME
          value: $(MY_POD_NAME)
        - name: ETCD_DATA_DIR
          value: /bitnami/etcd/data
        - name: ETCD_LOG_LEVEL
          value: info
        - name: ALLOW_NONE_AUTHENTICATION
          value: "yes"
        - name: ETCD_AUTH_TOKEN
          value: jwt,priv-key=/opt/bitnami/etcd/certs/token/jwt-token.pem,sign-method=RS256,ttl=10m
        - name: ETCD_ADVERTISE_CLIENT_URLS
          value: http://$(MY_POD_NAME).apisix-etcd-headless.apisix.svc.cluster.local:2379,http://apisix-etcd.apisix.svc.cluster.local:2379
        - name: ETCD_LISTEN_CLIENT_URLS
          value: http://0.0.0.0:2379
        - name: ETCD_INITIAL_ADVERTISE_PEER_URLS
          value: http://$(MY_POD_NAME).apisix-etcd-headless.apisix.svc.cluster.local:2380
        - name: ETCD_LISTEN_PEER_URLS
          value: http://0.0.0.0:2380
        - name: ETCD_INITIAL_CLUSTER_TOKEN
          value: etcd-cluster-k8s
        - name: ETCD_INITIAL_CLUSTER_STATE
          value: new
        - name: ETCD_INITIAL_CLUSTER
          value: apisix-etcd-0=http://apisix-etcd-0.apisix-etcd-headless.apisix.svc.cluster.local:2380,apisix-etcd-1=http://apisix-etcd-1.apisix-etcd-headless.apisix.svc.cluster.local:2380,apisix-etcd-2=http://apisix-etcd-2.apisix-etcd-headless.apisix.svc.cluster.local:2380
        - name: ETCD_CLUSTER_DOMAIN
          value: apisix-etcd-headless.apisix.svc.cluster.local
        envFrom: null
        image: docker.io/bitnami/etcd:3.5.10-debian-11-r2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /opt/bitnami/scripts/etcd/healthcheck.sh
          failureThreshold: 5
          initialDelaySeconds: 60
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 5
        name: etcd
        ports:
        - containerPort: 2379
          name: client
          protocol: TCP
        - containerPort: 2380
          name: peer
          protocol: TCP
        readinessProbe:
          exec:
            command:
            - /opt/bitnami/scripts/etcd/healthcheck.sh
          failureThreshold: 5
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits: {}
          requests: {}
        volumeMounts:
        - mountPath: /bitnami/etcd
          name: data
        - mountPath: /opt/bitnami/etcd/certs/token/
          name: etcd-jwt-token
          readOnly: true
      securityContext:
        fsGroup: 1001
      serviceAccountName: default
      volumes:
      - name: etcd-jwt-token
        secret:
          defaultMode: 256
          secretName: apisix-etcd-jwt-token
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 2Gi
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: etcd
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: etcd-9.7.3
    oracle/edition: 'COMMUNITY'
  name: apisix-etcd
  namespace: apisix
spec:
  minAvailable: 51%
  selector:
    matchLabels:
      app.kubernetes.io/component: etcd
      app.kubernetes.io/instance: apisix
      app.kubernetes.io/name: etcd
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix
  namespace: apisix
spec:
  endpoints:
  - interval: 15s
    path: /apisix/prometheus/metrics
    scheme: http
    targetPort: prometheus
  namespaceSelector:
    matchNames:
    - apisix
  selector:
    matchLabels:
      app.kubernetes.io/instance: apisix
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: apisix
      app.kubernetes.io/service: apisix-prometheus-metrics
      app.kubernetes.io/version: 3.9.1
      helm.sh/chart: apisix-2.8.1
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  labels:
    app.kubernetes.io/instance: apisix
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: apisix
    app.kubernetes.io/part-of: ebaas
    app.kubernetes.io/version: 3.9.1
    helm-version: 2.8.1
    helm.sh/chart: apisix-2.8.1
    oracle/edition: 'COMMUNITY'
  name: apisix
  namespace: apisix
spec:
  ingressClassName: traefik
  rules:
  - host: ""
    http:
      paths:
      - backend:
          service:
            name: apisix-gateway
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
